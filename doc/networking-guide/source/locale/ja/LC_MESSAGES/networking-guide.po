# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2015, OpenStack contributors
# This file is distributed under the same license as the Networking Guide package.
#
# Translators:
# nao nishijima <nao.nishijima.xt@hitachi.com>, 2015
# Sasuke(Kyohei MORIYAMA) <>, 2015
# Tomoyuki KATO <tomo@dream.daynight.jp>, 2014-2015
# yfukuda <fukuda.yuko@jp.fujitsu.com>, 2014
# Yoshiteru Takizawa <funski2000@gmail.com>, 2015
# Akihiro Motoki <amotoki@gmail.com>, 2015. #zanata
# KATO Tomoyuki <kato.tomoyuki@jp.fujitsu.com>, 2015. #zanata
# OpenStack Infra <zanata@openstack.org>, 2015. #zanata
# Akihiro Motoki <amotoki@gmail.com>, 2016. #zanata
# KATO Tomoyuki <kato.tomoyuki@jp.fujitsu.com>, 2016. #zanata
# 小羽根 陸 <riku_kobane@adoc.co.jp>, 2016. #zanata
# KATO Tomoyuki <kato.tomoyuki@jp.fujitsu.com>, 2017. #zanata
msgid ""
msgstr ""
"Project-Id-Version: Networking Guide 0.9\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2017-03-23 05:16+0000\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"PO-Revision-Date: 2017-02-03 05:18+0000\n"
"Last-Translator: Akihiro Motoki <amotoki@gmail.com>\n"
"Language: ja\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Zanata 3.9.6\n"
"Language-Team: Japanese\n"

msgid "(Optional) FDB L2 agent extension"
msgstr "(オプション) FDB L2 エージェント拡張機能"

msgid "**HostA and HostB: DHCP agent**"
msgstr "**HostA、HostB: DHCP エージェント**"

msgid "**HostA and HostB: L2 agent**"
msgstr "**HostA、HostB: L2 エージェント**"

msgid "**controlnode: neutron server**"
msgstr "**controlnode: neutron サーバー**"

msgid "*Invalid combination.*"
msgstr "*無効な組み合わせ*"

msgid "*N/S*"
msgstr "*指定なし*"

msgid ""
"*Network Address Translation* (NAT) is a process for modifying the source or "
"destination addresses in the headers of an IP packet while the packet is in "
"transit. In general, the sender and receiver applications are not aware that "
"the IP packets are being manipulated."
msgstr ""
"*ネットワークアドレス変換* (NAT; Network Address Translation) は、 IP パケッ"
"トの転送中に IP パケットヘッダーの送信元アドレスや宛先アドレスを変更する処理"
"です。一般に、送信者、受信者のアプリケーションには、 IP パケットが途中で操作"
"されていることは分かりません。"

msgid ""
"*To: everybody (ff:ff:ff:ff:ff:ff). I am looking for the computer who has IP "
"address 192.168.1.7. Signed: MAC address fc:99:47:49:d4:a0*."
msgstr ""
"*宛先: 全員 (ff:ff:ff:ff:ff:ff)。私は IP アドレス 192.168.1.7 を持つコン"
"ピューターを探している。署名: MAC アドレス fc:99:47:49:d4:a0。*"

msgid ""
"*To: fc:99:47:49:d4:a0. I have IP address 192.168.1.7. Signed: MAC address "
"54:78:1a:86:00:a5.*"
msgstr ""
"*宛先: fc:99:47:49:d4:a0。私が IP アドレス 192.168.1.7 を持っています。署名: "
"MAC address 54:78:1a:86:00:a5。*"

msgid "0,1,1"
msgstr "0,1,1"

msgid "1,0,0"
msgstr "1,0,0"

msgid "1,0,1"
msgstr "1,0,1"

msgid ":ref:`search`"
msgstr ":ref:`search`"

msgid ""
"A BGP speaker requires association with a provider network to determine "
"eligible prefixes. The association builds a list of all virtual routers with "
"gateways on provider and self-service networks in the same address scope so "
"the BGP speaker can advertise self-service network prefixes with the "
"corresponding router as the next-hop IP address. Associate the BGP speaker "
"with the provider network."
msgstr ""
"有効なプレフィックスを判定するには、 BGP スピーカーはプロバイダーネットワーク"
"と関連付けられている必要があります。この関連付けにより、同じアドレススコープ"
"にあるプロバイダーネットワークとセルフサービスネットワークにゲートウェイがあ"
"る全仮想ルーターのリストを作成し、BGP スピーカーが、セルフサービスネットワー"
"クのプレフィックス、およびネクストホップ IP アドレスとして対応するルーターを"
"広告できるようにします。 BGP スピーカーをプロバイダーネットワークと関連付けま"
"す。"

msgid ""
"A TCP server is said to *listen* on a port. For example, an SSH server "
"typically listens on port 22. For a client to connect to a server using TCP, "
"the client must know both the IP address of a server's host and the server's "
"TCP port."
msgstr ""
"TCP サーバーは、ポートを *リッスン (listen)* します。例えば、 SSH サーバーは"
"通常ポート 22 をリッスンします。サーバーに TCP を使って接続するクライアント"
"は、サーバーホストの IP アドレスとサーバーでの TCP ポートの両方を知っている必"
"要があります。"

msgid ""
"A basic example of SFC involves routing packets from one location to another "
"through a firewall that lacks a \"next hop\" IP address from a conventional "
"routing perspective. A more complex example involves an ordered series of "
"service functions, each implemented using multiple instances (VMs). Packets "
"must flow through one instance and a hashing algorithm distributes flows "
"across multiple instances at each hop."
msgstr ""
"SFC の基本的な例としては、パケットをある場所から別の場所へ、従来のルーティン"
"グで言うところの「ネクストホップ」 IP アドレスを持たないファイアウォールを経"
"由して転送する例があります。もっと複雑な例としては、複数のサービス機能の列を"
"順番に通すケースで、それぞれのサービス機能は複数のインスタンス (VM) を使って"
"実装されているというものです。パケットは各ホップで必ず １ つのインスタンスを"
"経由し、複数のインスタンスがある場合は各ホップにおいてハッシュアルゴリズムを"
"使ってそれらのインスタンスに分散されます。"

msgid ""
"A combination of the source attributes defines the source of the flow. A "
"combination of the destination attributes defines the destination of the "
"flow. The ``l7_parameters`` attribute is a place holder that may be used to "
"support flow classification using layer 7 fields, such as a URL. If "
"unspecified, the ``logical_source_port`` and ``logical_destination_port`` "
"attributes default to ``none``, the ``ethertype`` attribute defaults to "
"``IPv4``, and all other attributes default to a wildcard value."
msgstr ""
"\"source\" 関連の属性の組み合わせで、フローの入力元が定義されます。 "
"\"destination\" 関連の属性の組み合わせで、フローの宛先が定義されます。 "
"``l7_parameters`` 属性は、URL などのレイヤー 7 のフィールドを使ったフロー分類"
"をサポートする際に使用するための予約場所です。 ``logical_source_port`` と "
"``logical_destination_port`` 属性は、指定されなかった場合はデフォルトで "
"``none``になります。 ``ethertype`` 属性のデフォルトは ``IPv4`` で、それ以外の"
"属性のデフォルト値はすべてワイルドカード値です。"

msgid ""
"A database management command-line tool uses the Alembic library to manage "
"the migration."
msgstr ""
"データベース移行コマンドラインツールは、Alembic ライブラリーを使って移行ルー"
"ルを管理しています。"

msgid ""
"A flow classifier can only belong to one port chain to prevent ambiguity as "
"to which chain should handle packets in the flow. A check prevents such "
"ambiguity. However, you can associate multiple flow classifiers with a port "
"chain because multiple flows can request the same service function path."
msgstr ""
"1 つの Flow Classifier が所属できるポートチェインは 1 つだけです。これは、フ"
"ローのパケットをどのチェインが処理するかを判定する際の曖昧さを避けるためで"
"す。チェック機構があり、このような曖昧さを防止できます。一方で、複数の Flow "
"Classifier を 1 つのポートチェインに関連付けできます。これは、複数のフローを"
"同じサービス機能パスを通すためです。"

msgid ""
"A flow classifier identifies a flow. A port chain can contain multiple flow "
"classifiers. Omitting the flow classifier effectively prevents steering of "
"traffic through the port chain."
msgstr ""
"Flow Classifier はフローを特定します。ポートチェインには複数の Flow "
"Classifier を含めることができます。 Flow Classifier を指定しなかった場合、そ"
"のポートチェインによるトラフィックのステアリング (steering) は実際には行われ"
"ません。"

msgid ""
"A host sending a packet to an IP address consults its *routing table* to "
"determine which machine on the local network(s) the packet should be sent "
"to. The routing table maintains a list of the subnets associated with each "
"local network that the host is directly connected to, as well as a list of "
"routers that are on these local networks."
msgstr ""
"ある IP アドレスにパケットを送信するホストは、 *ルーティングテーブル* に問い"
"合わせを行い、パケットをローカルネットワーク上のどのマシンに送信すべきかを決"
"定します。ルーティングテーブルは、サブネットと各ネットワークにおいて直接接続"
"されているホストの関連付けのリストであり、これらのローカルネットワークにいる"
"ルーターのリストでもあります。"

msgid ""
"A namespace is a way of scoping a particular set of identifiers. Using a "
"namespace, you can use the same identifier multiple times in different "
"namespaces. You can also restrict an identifier set visible to particular "
"processes."
msgstr ""
"名前空間は、特定の ID 集合に範囲を絞る方法です。名前空間を使うと、名前空間が"
"異なれば同じ ID を何回も使用できます。また、特定のプロセスに見える ID 集合を"
"限定することもできます。"

msgid ""
"A pool holds a list of members that serve content through the load balancer."
msgstr ""
"プールは、ロードバランサーを通じてコンテンツを提供するメンバーのリストを保持"
"します。"

msgid ""
"A port chain consists of a sequence of port pair groups. Each port pair "
"group is a hop in the port chain. A group of port pairs represents service "
"functions providing equivalent functionality. For example, a group of "
"firewall service functions."
msgstr ""
"ポートチェインは、ポートペアグループの列で構成されます。各ポートペアグループ"
"は、そのポートチェインでの各ホップに対応します。ポートペアのグループは、等価"
"な機能を提供するサービス機能を表現します。例えば、ファイアウォールのサービス"
"機能のグループなどです。"

msgid ""
"A port chain is a unidirectional service chain. The first port acts as the "
"head of the service function chain and the second port acts as the tail of "
"the service function chain. A bidirectional service function chain consists "
"of two unidirectional port chains."
msgstr ""
"ポートチェインは単方向のサービスチェインです。最初のポートはサービス機能チェ"
"インの先頭となり、2 つ目のポートはサービス機能チェインの末尾となります。双方"
"向のサービス機能チェインは 2 つの単方向のポートチェインで構成されます。"

msgid "A port chain, or service function path, consists of the following:"
msgstr "ポートチェイン、すなわちサービス機能パス、は以下から構成されます。"

msgid ""
"A port is a connection point for attaching a single device, such as the NIC "
"of a virtual server, to a virtual network. The port also describes the "
"associated network configuration, such as the MAC and IP addresses to be "
"used on that port."
msgstr ""
"ポートは、仮想サーバーの NIC などの 1 つのデバイスを、仮想ネットワークに接続"
"する接続点です。ポートは、そのポートで使用される MAC アドレスや IP アドレスな"
"どの関連するネットワーク設定の表現でもあります。"

msgid ""
"A port pair group may contain one or more port pairs. Multiple port pairs "
"enable load balancing/distribution over a set of functionally equivalent "
"service functions."
msgstr ""
"ポートペアグループには、ポートペアが 1 つ以上含まれます。複数のポートペアを指"
"定すると、機能的に等価なサービス機能集合間で負荷分散が行われます。"

msgid ""
"A port pair represents a service function instance that includes an ingress "
"and egress port. A service function containing a bidirectional port uses the "
"same ingress and egress port."
msgstr ""
"ポートペアは、入力ポートと出力ポートを持つサービス機能を表現します。入出力の"
"両方向のポートを持つサービス機能の場合は、入力ポートと出力ポートとして同じ"
"ポートを指定します。"

msgid ""
"A provider network using IP address range 203.0.113.0/24, and supporting "
"floating IP addresses 203.0.113.101, 203.0.113.102, and 203.0.113.103."
msgstr ""
"プロバイダーネットワークは IP アドレス範囲 203.0.113.0/24 を使用し、 "
"Floating IP アドレスとして 203.0.113.101, 203.0.113.102, 203.0.113.103 を使用"
"できる。"

msgid "A self-service network using IP address range 10.0.1.0/24."
msgstr "セルフサービスネットワークは IP アドレス範囲 10.0.1.0/24 を使用する。"

msgid ""
"A set of flow classifiers that specify the classified traffic flows entering "
"the chain."
msgstr "チェインに入るトラフィックフローを指定する Flow Classifier の集合。"

msgid "A set of ports that define the sequence of service functions."
msgstr "サービス機能の列を定義するポートの集合。"

msgid "A setting of ``-1`` disables the quota for a tenant."
msgstr "``-1`` を設定すると、テナントのクォータが上限なしになります。"

msgid ""
"A single network can be assigned to more than one DHCP agents and one DHCP "
"agent can host more than one network. You can add a network to a DHCP agent "
"and remove one from it."
msgstr ""
"1 つのネットワークを複数の DHCP エージェントに割り当てることもできますし、 1 "
"つの DHCP エージェントで複数のネットワークを担当することもできます。ネット"
"ワークを DHCP エージェントに追加したり、DHCP エージェントから削除したりできま"
"す。"

msgid ""
"A subnet pool manages a pool of addresses from which subnets can be "
"allocated. It ensures that there is no overlap between any two subnets "
"allocated from the same pool."
msgstr ""
"サブネットプールはアドレスのプールを管理し、そこからサブネットを割り当てでき"
"ます。同じサブネットプールから割り当てられた任意のサブネット間で重複がないこ"
"とが保証されます。"

msgid ""
"A switchport that is configured to pass frames from all VLANs and tag them "
"with the VLAN IDs is called a *trunk port*. IEEE 802.1Q is the network "
"standard that describes how VLAN tags are encoded in Ethernet frames when "
"trunking is being used."
msgstr ""
"スイッチポートがすべての VLAN からのフレームを転送し、それらに VLAN ID のタグ"
"を付ける場合、そのポートは *トランクポート* と呼ばれます。 IEEE 802.1Q は、 "
"トランクポートを使う際に VLAN タグをどのように Ethernet フレームに入れるかを"
"規程したネットワーク標準です。"

msgid "A, AAAA and PTR records will be created in the DNS service."
msgstr ""
"A レコード、AAAA レコード、PTR レコードが DNS サービスにより作成されます。"

msgid "API server"
msgstr "API サーバー"

msgid "Ability to leverage tags by deployment tools."
msgstr "デプロイメントツールがタグを利用する。"

msgid ""
"Ability to map IDs from different management/orchestration systems to "
"OpenStack networks in mixed environments. For example, in the Kuryr project, "
"the Docker network ID is mapped to the Neutron network ID."
msgstr ""
"混在環境で、別の管理システムやオーケストレーションシステムが割り当てた ID を "
"OpenStack ネットワークにマッピングする。例えば、 Kuryr プロジェクトでは、 "
"Docker のネットワーク ID が Neutron ネットワーク ID にマッピングされます。"

msgid ""
"Ability to map different networks in different OpenStack locations to one "
"logically same network (for multi-site OpenStack)."
msgstr ""
"別の場所にある OpenStack 上の別々のネットワークを論理的な 1 つのネットワーク"
"にマッピングする (マルチサイト OpenStack 用)。"

msgid ""
"Ability to tag information about provider networks (for example, high-"
"bandwidth, low-latency, and so on)."
msgstr ""
"プロバイダーネットワークに関する情報をタグ付けする (例えば、広帯域、低遅延な"
"ど)。"

msgid "Abstract"
msgstr "概要"

msgid ""
"Accepts and routes RPC requests between agents to complete API operations. "
"Message queue is used in the ML2 plug-in for RPC between the neutron server "
"and neutron agents that run on each hypervisor, in the ML2 mechanism drivers "
"for :term:`Open vSwitch` and :term:`Linux bridge`."
msgstr ""
"API 操作を完了するためにエージェント間でやり取りされる RPC 要求を受信し宛先に"
"届けます。 ML2 プラグインで :term:`Open vSwitch` や :term:`Linux bridge` の "
"ML2 メカニズムドライバーを使う場合、 neutron サーバーと各ハイパーバイザー上で"
"動作する neutron エージェント間の RPC にメッセージキューが使用されます。"

msgid "Access"
msgstr "アクセス"

msgid ""
"Access to addresses in a scope are managed through subnet pools. Subnet "
"pools can either be created in an address scope, or updated to belong to an "
"address scope."
msgstr ""
"スコープ内のアドレスへのアクセスはサブネットプールを通じて管理されます。サブ"
"ネットプールをアドレススコープ内に作成することも、サブネットプールを更新して"
"アドレススコープに所属させることもできます。"

msgid "Accessing address scopes"
msgstr "アドレススコープの利用"

msgid "Achieving high availability with availability zone"
msgstr "アベイラビリティーゾーンを使った高可用性の実現"

msgid "Add LBaaS panels to Dashboard"
msgstr "ダッシュボードへの LBaaS パネルの追加"

msgid ""
"Add ``dns`` to ``extension_drivers`` in the ``[ml2]`` section of ``/etc/"
"neutron/plugins/ml2/ml2_conf.ini``. The following is an example:"
msgstr ""
"``/etc/neutron/plugins/ml2/ml2_conf.ini`` の ``[ml2]`` セクションの "
"``extension_drivers`` に ``dns`` を追加します。以下は例です。"

msgid "Add ``macvtap`` to mechanism drivers."
msgstr "``macvtap`` をメカニズムドライバーに追加します。"

msgid ""
"Add ``sriovnicswitch`` as mechanism driver. Edit the ``ml2_conf.ini`` file "
"on each controller:"
msgstr ""
"``sriovnicswitch`` をメカニズムドライバーとして追加します。各コントローラー"
"で  ``ml2_conf.ini`` ファイルを編集します。"

msgid "Add a BGP peer to the BGP speaker."
msgstr "BGP ピアを BPG スピーカーに追加します。"

msgid "Add a tag to a resource:"
msgstr "リソースにタグを付与します。"

msgid ""
"Add the FDB section and the ``shared_physical_device_mappings`` parameter. "
"This parameter maps each physical port to its physical network name. Each "
"physical network can be mapped to several ports:"
msgstr ""
"FDB セクションを追加し、 ``shared_physical_device_mappings`` パラメーターを設"
"定します。このパラメーターは、各物理ポートと物理ネットワーク名のマッピングを"
"行います。 1 つの物理ネットワークを複数の物理ポートにマッピングできます。"

msgid ""
"Add the LBaaS v2 service plug-in to the ``service_plugins`` configuration "
"directive in ``/etc/neutron/neutron.conf``. The plug-in list is comma-"
"separated:"
msgstr ""
"LBaaS v2 サービスプラグインを ``/etc/neutron/neutron.conf`` の "
"``service_plugins`` 設定項目に追加します。プラグインリストはコンマ区切りで"
"す。"

msgid ""
"Add the LBaaS v2 service provider to the ``service_provider`` configuration "
"directive within the ``[service_providers]`` section in ``/etc/neutron/"
"neutron_lbaas.conf``:"
msgstr ""
"``/etc/neutron/neutron_lbaas.conf`` の ``[service_providers]`` セクションの "
"``service_provider`` 設定項目に LBaaS v2 サービスプロバイダーを追加します。"

msgid ""
"Add the Octavia service provider to the ``service_provider`` configuration "
"directive within the ``[service_providers]`` section in ``/etc/neutron/"
"neutron_lbaas.conf``:"
msgstr ""
"``/etc/neutron/neutron_lbaas.conf`` の ``[service_providers]`` セクションの "
"``service_provider`` 設定項目に Octavia サービスプロバイダーを追加します。"

msgid ""
"Add the QoS service to the ``service_plugins`` setting in ``/etc/neutron/"
"neutron.conf``. For example:"
msgstr ""
"``/etc/neutron/neutron.conf`` の ``service_plugins`` 設定に QoS サービスを追"
"加します。例:"

msgid ""
"Add the ``ml2_conf_sriov.ini`` file as parameter to the ``neutron-server`` "
"service. Edit the appropriate initialization script to configure the "
"``neutron-server`` service to load the SR-IOV configuration file:"
msgstr ""
"``ml2_conf_sriov.ini`` ファイルを ``neutron-server`` サービスのパラメーターと"
"して追加します。適切な初期化スクリプトを編集して、 ``neutron-server`` サービ"
"スが SR-IOV 設定ファイルを読みこむように設定します。"

msgid "Add the following to ``/etc/neutron/neutron.conf``:"
msgstr "``/etc/neutron/neutron.conf`` に以下を追加します。"

msgid "Add the following to ``/etc/neutron/plugins/ml2/ml2_conf.ini``:"
msgstr "``/etc/neutron/plugins/ml2/ml2_conf.ini`` に以下を追加します。"

msgid "Add the provider network as a gateway on each router."
msgstr "各ルーターのゲートウェイとしてプロバイダーネットワークを追加します。"

msgid "Add the provider network as a gateway on the router."
msgstr "プロバイダーネットワークをルーターのゲートウェイとして追加します。"

msgid "Add the provider network as the gateway on the router."
msgstr "プロバイダーネットワークをルーターのゲートウェイとして追加します。"

msgid "Adding an HTTP listener"
msgstr "HTTP リスナーの追加"

msgid "Adding an HTTPS listener"
msgstr "HTTPS リスナーの追加"

msgid ""
"Address are assigned using EUI-64, and OpenStack Networking provides routing."
msgstr ""
"アドレスは EUI-64 を使って割り当てられます。ルーティング情報も OpenStack "
"Networking が提供します。"

msgid "Address configuration and optional information using DHCPv6."
msgstr "DHCPv6 を使ってアドレス設定と追加の情報を通知する方法"

msgid "Address configuration using RA and optional information using DHCPv6."
msgstr "RA を使ってアドレス設定を行い、DHCPv6 を使って追加の情報を通知する方法"

msgid "Address configuration using Router Advertisement (RA)."
msgstr "ルーター広告 (Router Advertisement; RA) を使ったアドレス設定"

msgid "Address modes for ports"
msgstr "ポートのアドレスモード"

msgid "Address scopes"
msgstr "アドレススコープ"

msgid ""
"Address scopes build from subnet pools. While subnet pools provide a "
"mechanism for controlling the allocation of addresses to subnets, address "
"scopes show where addresses can be routed between networks, preventing the "
"use of overlapping addresses in any two subnets. Because all addresses "
"allocated in the address scope do not overlap, neutron routers do not NAT "
"between your projects' network and your external network. As long as the "
"addresses within an address scope match, the Networking service performs "
"simple routing between networks."
msgstr ""
"アドレススコープは、サブネットプールを利用して作成されます。サブネットプール"
"はサブネットへのアドレス割り当てを制御する仕組みを提供するのに対して、アドレ"
"ススコープはどのアドレスがネットワーク間でルーティング可能かを示します。 1 つ"
"のアドレススコープ内で割り当てられたアドレスはすべて重複しないため、 neutron "
"ルーターはプロジェクトのネットワーク間や外部ネットワークとの間で NAT を行いま"
"せん。アドレスのアドレススコープが一致する限り、 Networking サービスはネット"
"ワーク間では通常のルーティングを行います。"

msgid "Addresses and optional information are assigned using DHCPv6."
msgstr "アドレスと追加の情報は DHCPv6 を使って割り当てられます。"

msgid ""
"Addresses are assigned using EUI-64, and an external router will be used for "
"routing."
msgstr ""
"アドレスは EUI-64 を使って割り当てられます。ルーティング情報は外部ルーターに"
"より提供されます。"

msgid "Addresses for subnets"
msgstr "サブネットのアドレス"

msgid "Adjust security groups to allow pings and SSH (both IPv4 and IPv6):"
msgstr ""
"ping と SSH を許可するようにセキュリティーグループを調整します (IPv4 と IPv6 "
"の両方)。"

msgid ""
"Admin role is required to use the agent management and scheduler extensions. "
"Ensure you run the following commands under a project with an admin role."
msgstr ""
"エージェント管理およびスケジューラー拡張機能を使用するには管理ロールが必要で"
"す。以下のコマンドは管理ロールを持つプロジェクトで実行してください。"

msgid "Administrator enforcement"
msgstr "管理者による強制適用"

msgid "Advanced services"
msgstr "ネットワークサービス"

msgid ""
"Advertisement of a floating IP address requires satisfying the following "
"conditions:"
msgstr ""
"Floating IP アドレスが広告されるには、以下の条件が成立する必要があります。"

msgid ""
"Advertisement of a self-service network requires satisfying the following "
"conditions:"
msgstr ""
"セルフサービスネットワークが広告されるには、以下の条件が成立する必要がありま"
"す。"

msgid ""
"After creating a peering session, you cannot change the local or remote "
"autonomous system numbers."
msgstr ""
"ピアリングセッションを作成した後で、ローカルやリモートの AS 番号を変更するこ"
"とはできません。"

msgid ""
"After deletion, if you restart the DHCP agent, it appears on the agent list "
"again."
msgstr ""
"削除した後で、 DHCP エージェントを再起動すると、そのエージェントは再びエー"
"ジェント一覧に登場します。"

msgid "After installing Dibbler, edit the ``/etc/dibbler/server.conf`` file:"
msgstr ""
"Dibbler をインストールしたら、 ``/etc/dibbler/server.conf`` ファイルを編集し"
"ます。"

msgid ""
"After installing a new version of the Neutron server, upgrade the database "
"using the following command:"
msgstr ""
"新しいバージョンの neutron サーバーのインストール後は、以下のコマンドを使って"
"データベースをアップグレードします。"

msgid ""
"After re-starting the ``neutron-server``, users will be able to assign a "
"``dns_name`` attribute to their ports."
msgstr ""
"``neutron-server`` を再起動すると、ユーザーはポートの ``dns_name`` 属性を設定"
"できるようになります。"

msgid ""
"After the agent is disabled, you can safely remove the agent. Even after "
"disabling the agent, resources on the agent are kept assigned. Ensure you "
"remove the resources on the agent before you delete the agent."
msgstr ""
"エージェントを無効にした後、そのエージェントは安全に削除できます。エージェン"
"トを無効化した後も、そのエージェント上のリソースは割り当てられたままです。"
"エージェントを削除する前に、エージェント上のリソースを削除してください。"

msgid ""
"After you stop the DHCP agent on HostA, you can delete it by the following "
"command:"
msgstr ""
"HostA の DHCP エージェントを停止した後で、以下のコマンドでエージェントを削除"
"できます。"

msgid "Agent nodes"
msgstr "エージェントノード"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_service.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Agents"
msgstr "エージェント"

msgid ""
"All InfiniBand networks must have a subnet manager running for the network "
"to function. This is true even when doing a simple network of two machines "
"with no switch and the cards are plugged in back-to-back. A subnet manager "
"is required for the link on the cards to come up. It is possible to have "
"more than one subnet manager. In this case, one of them will act as the "
"master, and any other will act as a slave that will take over when the "
"master subnet manager fails."
msgstr ""
"どの InfiniBand ネットワークでも、そのネットワークが機能するためにはサブネッ"
"トマネージャーが実行されている必要があります。スイッチなしの 2 台のホストしか"
"ない単純なネットワークで、カードどうしが直結されている場合であっても変わりま"
"せん。カードのリンクがアップするために、サブネットマネージャーは必須です。サ"
"ブネットマネージャーを複数台にすることもできます。この場合は、いずれか 1 台が"
"マスターとして動作し、それ以外はスレーブとして動作し、マスターのサブネットマ"
"ネージャーが故障した際に切り替わります。"

msgid ""
"All OpenStack Networking services and OpenStack Compute instances connect to "
"a virtual network via ports making it possible to create a traffic steering "
"model for service chaining using only ports. Including these ports in a port "
"chain enables steering of traffic through one or more instances providing "
"service functions."
msgstr ""
"すべての OpenStack Networking サービスと OpenStack Compute インスタンスは、"
"ポートを経由して仮想ネットワークに接続されます。このため、ポートだけを使って"
"サービスチェイニング用のトラフィックステアリングのモデルを作成できます。ポー"
"トチェインにこれらのポートを含めることで、サービス機能を提供する 1 つ以上のイ"
"ンスタンスを経由するようにトラフィックをステアリングできます。"

msgid ""
"All instances reside on the same network, which can also be shared with the "
"hosts. No VLAN tagging or other network segregation takes place."
msgstr ""
"すべてのインスタンスが同じネットワークにあります。これは、ホストとも共有でき"
"ます。VLAN タギングや他のネットワーク分割が行われません。"

msgid "Allowing a network to be used as an external network"
msgstr "ネットワークの外部ネットワークとしての使用の許可"

msgid ""
"Alternatively the ``pci_passthrough_whitelist`` parameter also supports "
"whitelisting by:"
msgstr ""
"代わりに、 ``pci_passthrough_whitelist`` パラメーターを使ったホワイトリストの"
"設定もできます。"

msgid ""
"Alternatively, you can create VFs by passing the ``max_vfs`` to the kernel "
"module of your network interface. However, the ``max_vfs`` parameter has "
"been deprecated, so the PCI SYS interface is the preferred method."
msgstr ""
"別の方法として、 お使いのネットワークインターフェースのカーネルモジュールに "
"``max_vfs`` を渡して VF を作成することもできます。 ``max_vfs`` パラメーターは"
"廃止予定になっているので、 PCI SYS インターフェースを使うことを推奨します。"

msgid ""
"Alternatively, you can launch each instance with one network interface and "
"attach additional ports later."
msgstr ""
"ネットワークインターフェース 1 つで各インスタンスを起動し、後で追加のポートを"
"接続することもできます。"

msgid ""
"Although OpenStack does not make use of libvirt's networking, this "
"networking will not interfere with OpenStack's behavior, and can be safely "
"left enabled. However, libvirt's networking can be a nuisance when debugging "
"OpenStack networking issues. Because libvirt creates an additional bridge, "
"dnsmasq process, and iptables ruleset, these may distract an operator "
"engaged in network troubleshooting. Unless you need to start up virtual "
"machines using libvirt directly, you can safely disable libvirt's network."
msgstr ""
"OpenStack は libvirt のネットワークを使用しませんが、このネットワークは "
"OpenStack の動作には干渉せず、そのまま有効にしておくこともできます。しかし、 "
"OpenStack ネットワークの問題をデバッグする際に、 libvirt のネットワークはじゃ"
"まになりえます。 libvirt は追加のブリッジ、 dnsmasq プロセス、 iptables ルー"
"ルセットを作成するため、ネットワークの問題切り分けを行うオペレーターの注意を"
"そらすこともあります。 libvirt を使って仮想マシンを直接起動する必要がない場合"
"には、 libvirt のネットワークは安全に無効にすることができます。"

msgid ""
"Although self-service networks generally use private IP address ranges "
"(RFC1918) for IPv4 subnets, BGP dynamic routing can advertise any IPv4 "
"address ranges."
msgstr ""
"セルフサービスネットワークの IPv4 サブネットでは一般的にはプライベート IP ア"
"ドレス範囲 (RFC1918) が使用されますが、 BGP 動的ルーティングはどのような "
"IPv4 アドレス範囲でも広告できます。"

msgid ""
"Although, the Networking service provides high availability for routers and "
"high availability and fault tolerance for networks' DHCP services, "
"availability zones provide an extra layer of protection by segmenting a "
"Networking service deployment in isolated failure domains. By deploying HA "
"nodes across different availability zones, it is guaranteed that network "
"services remain available in face of zone-wide failures that affect the "
"deployment."
msgstr ""
"Networking サービスは、ルーターに対する高可用性と、ネットワークの DHCP サービ"
"スに対する高可用性と耐障害性を持ちますが、アベイラビリティーゾーンはこれとは"
"異なる保護レイヤーを提供し、 Networking サービスのデプロイメントを別々の故障"
"ドメインに区分けするものです。異なるアベイラビリティーゾーンにまたがって HA "
"ノードをデプロイすることで、ゾーン全体に渡る障害が発生した場合でも、ネット"
"ワークサービスが利用可能な状態になることを保証できます。"

msgid ""
"An L2 agent serves layer 2 (Ethernet) network connectivity to OpenStack "
"resources. It typically runs on each Network Node and on each Compute Node."
msgstr ""
"L2 エージェントは、OpenStack リソースに対してレイヤー 2 (Ethernet) ネットワー"
"クの接続性を提供します。通常は、ネットワークノードとコンピュートノードで実行"
"されます。"

msgid ""
"An administrator can mark a pool as default. Only one pool from each address "
"family can be marked default."
msgstr ""
"管理者は、サブネットプールにデフォルトであるというマークをつけることができま"
"す。各アドレスファミリーにつき 1 つのプールをデフォルトとして指定できます。"

msgid ""
"An administrator might want to disable an agent if a system hardware or "
"software upgrade is planned. Some agents that support scheduling also "
"support disabling and enabling agents, such as L3 and DHCP agents. After the "
"agent is disabled, the scheduler does not schedule new resources to the "
"agent."
msgstr ""
"管理者は、システムのハードウェアやソフトウェアのアップグレードを計画している"
"場合、エージェントを無効化したいことでしょう。 L3 エージェントや DHCP エー"
"ジェントなど、スケジューリングに対応しているエージェントのいくつかでは、エー"
"ジェントの有効化、無効化ができます。エージェントを無効にすると、スケジュー"
"ラーはそれ以降はそのエージェントに新たにリソースをスケジューリングしません。"

msgid ""
"An availability zone groups network nodes that run services like DHCP, L3, "
"FW, and others. It is defined as an agent's attribute on the network node. "
"This allows users to associate an availability zone with their resources so "
"that the resources get high availability."
msgstr ""
"アベイラビリティーゾーンを使うと、DHCP、 L3、ファイアウォールなどのサービスを"
"実行するネットワークノードをグルーピングできます。アベイラビリティーゾーン"
"は、ネットワークノード上のエージェントの属性として定義されます。ユーザーはリ"
"ソースをアベイラビリティーゾーンに関連付けることで、リソースの可用性を高める"
"ことができます。"

msgid ""
"An availability zone is used to make network resources highly available. The "
"operators group the nodes that are attached to different power sources under "
"separate availability zones and configure scheduling for resources with high "
"availability so that they are scheduled on different availability zones."
msgstr ""
"アベイラビリティーゾーンはネットワークリソースの可用性を高めるために使用され"
"ます。オペレーターは、異なる電源供給源に接続されたネットワークノードを別々の"
"アベイラビリティーゾーンにグルーピングし、可用性を確保しながらリソースの割り"
"当てを行うように設定します。これにより、ネットワークリソースは異なるアベイラ"
"ビリティーゾーンに割り当てられます。"

msgid ""
"Any given Linux process runs in a particular network namespace. By default "
"this is inherited from its parent process, but a process with the right "
"capabilities can switch itself into a different namespace; in practice this "
"is mostly done using the :command:`ip netns exec NETNS COMMAND...` "
"invocation, which starts ``COMMAND`` running in the namespace named "
"``NETNS``. Suppose such a process sends out a message to IP address A.B.C.D, "
"the effect of the namespace is that A.B.C.D will be looked up in that "
"namespace's routing table, and that will determine the network device that "
"the message is transmitted through."
msgstr ""
"任意の Linux プロセスを特定のネットワーク名前空間で実行できます。デフォルトで"
"は、実行される名前空間は親プロセスから継承されますが、適切な権限を持ったプロ"
"セスであれば自分自身を別の名前空間に切り替えることができます。実際のところ"
"は、 :command:`ip netns exec NETNS COMMAND...` によるプロセス起動を使うのがほ"
"とんどです。このコマンドは ``NETNS`` という名前の名前空間で ``COMMAND`` を実"
"行します。このようなプロセスが IP アドレス A.B.C.D にメッセージを送信したとす"
"ると、名前空間の影響で A.B.C.D は名前空間内のルーティングテーブルを対象に検索"
"が行われ、そのメッセージが送信されるネットワークデバイスが決定されます。"

msgid ""
"Any plug-in or ml2 mechanism driver can claim support for some QoS rule "
"types by providing a plug-in/driver class property called "
"``supported_qos_rule_types`` that returns a list of strings that correspond "
"to `QoS rule types <https://git.openstack.org/cgit/openstack/neutron/tree/"
"neutron/services/qos/qos_consts.py>`_."
msgstr ""
"プラグインや ML2 メカニズムドライバーは、対応している QoS ルール種別を、 "
"``supported_qos_rule_types`` という名前のプロパティーを設定することで宣言でき"
"ます。 ``supported_qos_rule_types`` は `QoS ルール種別 <https://git."
"openstack.org/cgit/openstack/neutron/tree/neutron/services/qos/qos_consts."
"py>`_ を指定します。"

msgid ""
"Anyone with access to the Networking service can create their own address "
"scopes. However, network administrators can create shared address scopes, "
"allowing other projects to create networks within that address scope."
msgstr ""
"Networking サービスにアクセスできるユーザーは誰でも自分のアドレススコープを作"
"成できます。一方、ネットワーク管理者は共有のアドレススコープを作成できます。"
"共有のアドレススコープを使うと、他のプロジェクトがそのアドレススコープ内に"
"ネットワークを作成できます。"

msgid "Appendix"
msgstr "付録"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  config_server.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Architecture"
msgstr "アーキテクチャー"

msgid "Arp Spoofing Prevention"
msgstr "ARP 詐称防止"

msgid ""
"As a regular project in an OpenStack cloud, you can create a subnet pool of "
"your own and use it to manage your own pool of addresses. This does not "
"require any admin privileges. Your pool will not be visible to any other "
"project."
msgstr ""
"OpenStack クラウドの通常プロジェクトは、自分用のサブネットプールを作成し、こ"
"れを使って自分用のアドレスプールを管理できます。これを行うのに、管理者権限は"
"全く不要です。あなたのプールは他のプロジェクトには一切見えません。"

msgid ""
"As introduced in other guide entries, neutron provides a means of making an "
"object (``network``, ``qos-policy``) available to every project. This is "
"accomplished using the ``shared`` flag on the supported object:"
msgstr ""
"他の箇所に説明があるように、 neutron ではオブジェクト (``network``, ``qos-"
"policy``) をすべてのプロジェクトと共有する方法が提供されています。これを行う"
"には、オブジェクトの ``shared`` フラグを使います。"

msgid ""
"As mentioned earlier, modern Ethernet networks use switches to interconnect "
"the network hosts. A switch is a box of networking hardware with a large "
"number of ports that forward Ethernet frames from one connected host to "
"another. When hosts first send frames over the switch, the switch doesn’t "
"know which MAC address is associated with which port. If an Ethernet frame "
"is destined for an unknown MAC address, the switch broadcasts the frame to "
"all ports. The switch learns which MAC addresses are at which ports by "
"observing the traffic. Once it knows which MAC address is associated with a "
"port, it can send Ethernet frames to the correct port instead of "
"broadcasting. The switch maintains the mappings of MAC addresses to switch "
"ports in a table called a *forwarding table* or *forwarding information "
"base* (FIB). Switches can be daisy-chained together, and the resulting "
"connection of switches and hosts behaves like a single network."
msgstr ""
"上で述べたように、最近の Ethernet ネットワークはネットワーク間を接続するのに"
"スイッチを使用します。スイッチは、多数のポートを持つネットワークハードウェア"
"の箱で、スイッチに接続されたあるホストから別のホストに Ethernet フレームを転"
"送します。ホストが最初にフレームをそのスイッチ経由で送信する際には、スイッチ"
"はどの MAC アドレスがどのポートに関連付いているかを知りません。 Ethernet フ"
"レームの宛先が知らない MAC アドレスの場合、スイッチはすべてのポートにそのフ"
"レームをブロードキャストします。スイッチはどの MAC アドレスがどのポートにいる"
"かを、トラフィックを観測して学習します。いったんどの MAC アドレスがどのポート"
"に関連付いているかを学習すると、その後はスイッチは Ethernet フレームをブロー"
"ドキャストせずに正しいポートに送信できます。スイッチは MAC アドレスからスイッ"
"チポートへの対応関係をテーブルで管理します。このテーブルは  *forwarding "
"table (転送テーブル)* や *forwarding information base* (FIB) と呼ばれます。ス"
"イッチは数珠つなぎ (daisy-chain) にすることができ、その結果、スイッチとホスト"
"の接続は 1 つのネットワークの場合と同様の動作をします。"

msgid ""
"As of Juno, the OpenStack Networking service (neutron) provides two new "
"attributes to the subnet object, which allows users of the API to configure "
"IPv6 subnets."
msgstr ""
"Juno 時点では、 OpenStack Networking サービス (neutron) のサブネットオブジェ"
"クトには 2 つの属性があり、この属性により API ユーザーは IPv6 サブネットの設"
"定が可能です。"

msgid ""
"As of today it is not used in the Linux bridge agent. The Linux bridge agent "
"has its own agent specific configuration option. Please see the following "
"bug for more details: https://bugs.launchpad.net/neutron/+bug/1523614"
msgstr ""
"現時点では、この設定が Linux ブリッジエージェントでは使用されていません。 "
"Linux ブリッジエージェントには、エージェント固有の設定項目があります。詳細は "
"https://bugs.launchpad.net/neutron/+bug/1523614 を参照してください。"

msgid "Assign a network to a given DHCP agent."
msgstr "ネットワークを指定した DHCP エージェントに割り当てます。"

msgid ""
"Assign a valid domain name to the network's ``dns_domain`` attribute. This "
"name must end with a period (``.``)."
msgstr ""
"ネットワークの ``dns_domain`` 属性に有効なドメイン名を割り当てます。このドメ"
"イン名の末尾はピリオド (``.``) でなければいけません。"

msgid "Associating a floating IP address"
msgstr "Floating IP アドレスの割り当て"

msgid ""
"At this moment the Networking DB is the source of truth, but nova-api is the "
"only public read-write API."
msgstr ""
"この時点で、Networking DB が真の情報源になりますが、 nova-api は唯一の公開さ"
"れた読み書き可能な API です。"

msgid ""
"At this point, all compute nodes have been migrated, but they are still "
"using the nova-api API and Compute gateways. Finally, enable OpenStack "
"Networking by following these steps:"
msgstr ""
"この時点で、すべてのコンピュートノードの移行が完了しましたが、依然として "
"nova-api と Compute ゲートウェイが使用されています。最後に、以下の手順を行い "
"OpenStack Networking を有効にします。"

msgid "Attaching router gateways to networks (since Mitaka)."
msgstr "ルーターのゲートウェイをネットワークに接続する許可 (Mitaka 以降)"

msgid "Attribute name"
msgstr "属性名"

msgid "Auto Configuration Flag = 1"
msgstr "Auto Configuration Flag = 1"

msgid "Automatic allocation of network topologies"
msgstr "ネットワークトポロジーの自動割り当て"

msgid "Availability zone aware scheduler"
msgstr "アベイラビリティーゾーン対応スケジューラー"

msgid ""
"Availability zone is selected from ``default_availability_zones`` in ``/etc/"
"neutron/neutron.conf`` if a resource is created without "
"``availability_zone_hints``:"
msgstr ""
"リソースが ``availability_zone_hints`` を指定せずに作成された場合は、アベイラ"
"ビリティーゾーンは ``/etc/neutron/neutron.conf`` の "
"``default_availability_zones`` から選択されます。"

msgid "Availability zone of agents"
msgstr "エージェントのアベイラビリティーゾーン"

msgid "Availability zone related attributes"
msgstr "アベイラビリティーゾーン関連の属性"

msgid "Availability zones"
msgstr "アベイラビリティーゾーン"

msgid "BGP dynamic routing"
msgstr "BGP 動的ルーティング"

msgid ""
"BGP dynamic routing advertises prefixes for self-service networks and host "
"routes for floating IP addresses."
msgstr ""
"BGP 動的ルーティングは、セルフサービスネットワークのプレフィックスや "
"Floating IP アドレスへのホストルートを広告します。"

msgid ""
"BGP dynamic routing consists of a service plug-in and an agent. The service "
"plug-in implements the Networking service extension and the agent manages "
"BGP peering sessions. A cloud administrator creates and configures a BGP "
"speaker using the CLI or API and manually schedules it to one or more hosts "
"running the agent. Agents can reside on hosts with or without other "
"Networking service agents. Prefix advertisement depends on the binding of "
"external networks to a BGP speaker and the address scope of external and "
"internal IP address ranges or subnets."
msgstr ""
"BGP 動的ルーティングは、サービスプラグインとエージェントで構成されます。サー"
"ビスプラグインは Networking サービスの API 拡張を実装し、エージェントは BGP "
"ピアリングセッションの管理を行います。クラウド管理者は CLI や API を使って "
"BGP スピーカーを作成、設定し、手動で BGP スピーカーを 1 つ以上のエージェント"
"が動作するホストに割り当てます。エージェントは他の Networking サービスのエー"
"ジェントと同じホストに置くことも別のホストに置くこともできます。プレフィック"
"ス広告 (prefix advertisement) は、BGP スピーカーが関連付けられた外部ネット"
"ワーク、および外部と内部の IP アドレス範囲やサブネットのアドレススコープに基"
"いて行われます。"

msgid ""
"BGP dynamic routing enables advertisement of self-service (private) network "
"prefixes to physical network devices that support BGP such as routers, thus "
"removing the conventional dependency on static routes. The feature relies "
"on :ref:`address scopes <config-address-scopes>` and requires knowledge of "
"their operation for proper deployment."
msgstr ""
"BGP 動的ルーティングを使うと、セルフサービス (プライベート) ネットワークの"
"ネットワークプレフィックスを、ルーターなどの BGP に対応した物理ネットワークデ"
"バイスに広告できるようになります。これにより、従来からの静的経路による方法に"
"依存する必要がなくなります。この機能は :ref:`アドレススコープ <config-"
"address-scopes>` に依存しており、また、適切なデプロイメントを運用するだけの知"
"識も必要です。"

msgid ""
"BGP dynamic routing supports peering via IPv6 and advertising IPv6 prefixes."
msgstr ""
"BGP 動的ルーティングは、 IPv6 経由のピアリングと IPv6 プレフィックスの広告に"
"対応しています。"

msgid ""
"BGP dynamic routing supports scheduling a BGP speaker to multiple agents "
"which effectively multiplies prefix advertisements to the same peer. If an "
"agent fails, the peer continues to receive advertisements from one or more "
"operational agents."
msgstr ""
"BGP 動的ルーティングでは、 BGP スピーカーを複数のエージェントにスケジューリン"
"グすることもできます。この場合、実際には同じピアに対してプレフィックス広告が"
"複数送られることになります。あるエージェントが故障しても、ピアは残りの動作し"
"ているエージェントから広告を受信し続けます。"

msgid ""
"BGP routing can be used to automatically set up a static route for your "
"instances."
msgstr ""
"BGP ルーティングを使うと、インスタンスへの静的経路を自動的に設定できます。"

msgid "Backwards compatibility"
msgstr "後方互換性"

msgid "Backwards compatibility with pre-Juno IPv6 behavior."
msgstr "Juno より前の IPv6 動作と後方互換性があります。"

msgid "Basic networking"
msgstr "ネットワークの基本"

msgid ""
"Because a network host may have multiple TCP-based applications running, TCP "
"uses an addressing scheme called *ports* to uniquely identify TCP-based "
"applications. A TCP port is associated with a number in the range 1-65535, "
"and only one application on a host can be associated with a TCP port at a "
"time, a restriction that is enforced by the operating system."
msgstr ""
"ネットワークホストでは TCP を使ったアプリケーションが複数動作する場合があるた"
"め、 TCP は *ポート* と呼ばれる番号付け機構を使い、 TCP を使うアプリケーショ"
"ンを一意に特定します。 TCP ポートは 1-65535 の範囲の数値に関連付けられ、ある"
"ホストにおいてはある時点では 1 つの TCP ポートに関連付けられるのは 1 つのアプ"
"リケーションだけで、この制約はオペレーティングシステムにより適用されます。"

msgid ""
"Because the NAT router modifies ports as well as IP addresses, this form of "
"SNAT is sometimes referred to as *Port Address Translation* (PAT). It is "
"also sometimes referred to as *NAT overload*."
msgstr ""
"NAT ルーターは IP アドレスだけでなくポートも変更するので、この形態の NAT は *"
"ポートアドレス変換* (PAT) と呼ばれることもあります。 *NAT オーバーロード "
"(overload)* と呼ばれることもあります。"

msgid ""
"Before Kilo, Networking had no automation around the addresses used to "
"create a subnet. To create one, you had to come up with the addresses on "
"your own without any help from the system. There are valid use cases for "
"this but if you are interested in the following capabilities, then subnet "
"pools might be for you."
msgstr ""
"Kilo より前では、 Networking にはサブネット作成時に使用するアドレスを自動的に"
"割り当てる方法がありませんでした。サブネットを作るためには、自分のアドレスを"
"システムの助けなしに指定する必要がありました。この方法が意味のあるユースケー"
"スもありますが、以下のあげるような機能が求められる場合には、サブネットプール"
"は役にたつことでしょう。"

msgid ""
"Before executing any of the use cases, the user must create in the DNS "
"service under his project a DNS zone where the A and AAAA records will be "
"created. For the description of the use cases below, it is assumed the zone "
"``example.org.`` was created previously."
msgstr ""
"ユースケースを開始する前に、ユーザーは DNS サービスの自分のプロジェクト下に "
"DNS ゾーンを作成しておかなければいけません。この DNS ゾーンに A レコードと "
"AAAA レコードが作成されます。以下のユースケースの説明では、ゾーン ``example."
"org`` がすでに作成されているものとします。"

msgid ""
"Before the end-user can use the auto-allocation feature, the operator must "
"create the resources that will be used for the auto-allocated network "
"topology creation. To perform this task, proceed with the following steps:"
msgstr ""
"エンドユーザーが自動割り当て機能を利用できるようになる前に、オペレーターは自"
"動割り当てネットワークトポロジーの作成に使用されるリソースを作成しなければい"
"けません。このためには、以下の手順を実行します。"

msgid ""
"Beginning with Mitaka, a subnet pool can be marked as the default. This is "
"handled with a new extension."
msgstr ""
"Mitaka リリースから、デフォルトのサブネットプールを指定できるようになりまし"
"た。この機能は新しい機能拡張により提供されます。"

msgid "Binding QoS policies permissions to networks or ports (since Mitaka)."
msgstr "ネットワークやポートに QoS ポリシーを割り当てる許可 (Mitaka 以降)"

msgid ""
"Boot a VM on ``net2``. Let both DHCP agents host ``net2``. Fail the agents "
"in turn to see if the VM can still get the desired IP."
msgstr ""
"``net2`` に VM を起動して、両方の DHCP エージェントに ``net2`` を担当させま"
"す。これらのエージェントを順番に故障させて、 エージェントが故障した場合でも "
"VM が所望の IP アドレスを取得できることを確認します。"

msgid "Boot a VM on ``net2``:"
msgstr "VM を ``net2`` 上に起動します。"

msgid ""
"Boot an instance or alternatively, create a port specifying a valid value to "
"its ``dns_name`` attribute. If the port is going to be used for an instance "
"boot, the value assigned to ``dns_name`` must be equal to the ``hostname`` "
"that the Compute service will assign to the instance. Otherwise, the boot "
"will fail."
msgstr ""
"インスタンスを起動するか、 ``dns_name`` 属性に有効な値を指定してポートを作成"
"します。このポートをインスタンス起動時に使用する場合には、 ``dns_name`` に割"
"り当てる値は Compute サービスがインスタンスに割り当てる ``hostname`` と同じで"
"なければいけません。さもないと、起動に失敗します。"

msgid ""
"Boot an instance specifying the externally accessible network. "
"Alternatively, create a port on the externally accessible network specifying "
"a valid value to its ``dns_name`` attribute. If the port is going to be used "
"for an instance boot, the value assigned to ``dns_name`` must be equal to "
"the ``hostname`` that the Compute service will assign to the instance. "
"Otherwise, the boot will fail."
msgstr ""
"外部からアクセス可能なネットワークを指定してインスタンスを起動します。別の方"
"法としては、 ``dns_name`` 属性に有効な値を指定して、外部からアクセス可能な"
"ネットワーク上にポートを作成します。このポートをインスタンス起動時に使用する"
"場合には、 ``dns_name`` に割り当てる値は Compute サービスがインスタンスに割り"
"当てる ``hostname`` と同じでなければいけません。さもないと、起動に失敗しま"
"す。"

msgid "Both DHCP agents host the ``net2`` network."
msgstr "両方の DHCP エージェントが ``net2`` ネットワークを担当しています。"

msgid ""
"Both the Linux bridge and the Open vSwitch dataplane modules support "
"forwarding IPv6 packets amongst the guests and router ports. Similar to "
"IPv4, there is no special configuration or setup required to enable the "
"dataplane to properly forward packets from the source to the destination "
"using IPv6. Note that these dataplanes will forward Link-local Address (LLA) "
"packets between hosts on the same network just fine without any "
"participation or setup by OpenStack components after the ports are all "
"connected and MAC addresses learned."
msgstr ""
"Linux ブリッジと Open vSwitch のデータプレーンモジュールは両方とも、ゲスト同"
"士やルーターポートとの間の IPv6 パケットの転送をサポートしています。 IPv4 と"
"同様に、送信元から宛先へ IPv6 を使ってパケットをデータプレーンが適切に転送で"
"きるようにするように特別な設定や構成は必要ありません。また、ポートがすべて接"
"続され、MAC アドレスのラーニングが行われた後は、同じネットワーク上のホスト間"
"のリンクローカルアドレス (LLA) パケットの転送も、OpenStack コンポーネントによ"
"る特別な関与や設定なしに、正しく行われます。"

msgid ""
"Bring up the Networking (l3) nodes. The new routers will have identical MAC"
"+IPs as old Compute gateways so some sort of immediate cutover is possible, "
"except for stateful connections issues such as NAT."
msgstr ""
"Networking ノード (L3 ノード) を立ち上げます。新しいルーターは Compute ゲート"
"ウェイと同じ MAC+IP を持つので、ある程度の即時の切り替えが可能です。ただし、"
"NAT などの状態管理が必要なコネクションはこの限りではありません。"

msgid "Building an LBaaS v2 load balancer"
msgstr "LBaaS v2 ロードバランサーの作成"

msgid "Buying guide"
msgstr "どれを選べばよいか？"

msgid ""
"By creating subnets from scoped subnet pools, the network is associated with "
"the address scope."
msgstr ""
"アドレススコープに関連付けられたサブネットプールからサブネットを作成すること"
"で、そのネットワークはアドレススコープと関連付けられます。"

msgid ""
"By default, libvirt creates a network named *default*. The details of this "
"network may vary by distribution; on Ubuntu this network involves:"
msgstr ""
"デフォルトでは、 libvirt は *default* という名前のネットワークを作成します。"
"このネットワークの詳細はディストリビューション毎に異なります。 Ubuntu では、"
"このネットワークは以下が含まれます。"

msgid ""
"By default, libvirt's networking functionality is enabled, and libvirt "
"creates a network when the system boots. To implement this network, libvirt "
"leverages some of the same technologies that OpenStack Network does. In "
"particular, libvirt uses:"
msgstr ""
"デフォルトでは、 libvirt のネットワーク機能は有効になっており、 libvirt はシ"
"ステム起動時にネットワークを作成します。このネットワークを作るため、libvirt "
"は OpenStack Networking が使っているのと同じ技術をいくつか活用しています。特"
"に以下を使います。"

msgid ""
"Can be used for instance network attachments as well as for attachments of "
"other network resources like routers, DHCP, and so on."
msgstr ""
"インスタンスのネットワーク接続にも、ルーターや DHCP などの他のネットワークリ"
"ソースの接続にも使用できます。"

msgid ""
"Can only be used for instance network attachments (device_owner = compute) "
"and not for attachment of other resources like routers, DHCP, and so on."
msgstr ""
"インスタンスのネットワーク接続 (device_owner = compute) のみに使用でき、ルー"
"ターや DHCP などの他のネットワークリソースの接続には使用できません。"

msgid ""
"Can only be used for instance network attachments (device_owner = compute)."
msgstr ""
"インスタンスのネットワーク接続 (device_owner = compute) のみに使用できます。"

msgid "Case 1"
msgstr "ケース 1"

msgid "Case 1: Each virtual network uses unique DNS resolver(s)"
msgstr "ケース 1: 仮想ネットワークごとに独自の DNS レゾルバーを使用する場合"

msgid "Case 2"
msgstr "ケース 2"

msgid "Case 2: All virtual networks use same DNS resolver(s)"
msgstr "ケース 2: すべての仮想ネットワークが同じ DNS レゾルバーを使用する場合"

msgid "Case 3"
msgstr "ケース 3"

msgid "Case 3: All virtual networks use DNS resolver(s) on the host"
msgstr ""
"ケース 3: すべての仮想ネットワークがホストの DNS レゾルバーを使用する場合"

msgid ""
"Check that ``ebrctl`` is listed somewhere in ``/etc/nova/rootwrap.d/*``:"
msgstr ""
"``/etc/nova/rootwrap.d/*`` のいずれかのファイルに ``ebrctl`` が入っていること"
"を確認します。"

msgid ""
"Check the instance status. The ``Networks`` field contains an IP address "
"from the subnet having the ``compute:nova`` service type."
msgstr ""
"インスタンスの状態を確認します。 ``Networks`` フィールドを見ると、 ``compute:"
"nova`` サービスタイプを持つサブネットの IP アドレスが割り当てられています。"

msgid "Checking connectivity"
msgstr "接続性の確認"

msgid "Clear tags from a resource:"
msgstr "リソースのタグをクリアします。"

msgid "Client and server exchange data."
msgstr "クライアントとサーバーがデータを交換します。"

msgid "Client connects to server."
msgstr "クライアントがサーバーに接続します。"

msgid "Client or server disconnects."
msgstr "クライアントかサーバーが接続を終了します。"

msgid ""
"Clone the `neutron-lbaas-dashboard repository <https://git.openstack.org/"
"cgit/openstack/neutron-lbaas-dashboard/>`__ and check out the release branch "
"that matches the installed version of Dashboard:"
msgstr ""
"`neutron-lbaas-dashboard リポジトリー <https://git.openstack.org/cgit/"
"openstack/neutron-lbaas-dashboard/>`__ をクローンし、インストールされている"
"ダッシュボードのバージョンに合致するリリースブランチをチェックアウトします。"

msgid "Complex queries may have contradictory parameters. Example::"
msgstr ""
"複雑な問い合わせでは、矛盾するパラメーターを指定することもできます。例::"

msgid ""
"Compute needs a per-hypervisor \"has_transitioned\" boolean change in the "
"data model to be used during the migration process. This flag is no longer "
"required once the process is complete."
msgstr ""
"Compute では、データモデルにハイパーバイザー単位にブール値の "
"\"has_transitioned\" フラグが必要で、このフラグは移行作業中に使用されます。移"
"行手順が一度完了すると、このフラグはそれ以降は必要ありません。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Compute nodes"
msgstr "コンピュートノード"

msgid "Concepts"
msgstr "概念"

msgid ""
"Conceptually, you can think of an Ethernet network as a single bus that each "
"of the network hosts connects to. In early implementations, an Ethernet "
"network consisted of a single coaxial cable that hosts would tap into to "
"connect to the network. However, network hosts in modern Ethernet networks "
"connect directly to a network device called a *switch*. Still, this "
"conceptual model is useful, and in network diagrams (including those "
"generated by the OpenStack dashboard) an Ethernet network is often depicted "
"as if it was a single bus. You'll sometimes hear an Ethernet network "
"referred to as a *layer 2 segment*."
msgstr ""
"概念としては、 Ethernet ネットワークはそのネットワークのすべてのホストが接続"
"する 1 本のバスとみなせます。初期の実装では、 Ethernet ネットワークは、ネット"
"ワークに接続するためにホストがつなぎ込む 1 本の同軸ケーブルで構成されていまし"
"た。しかしながら、最近の Ethernet ネットワークでは *スイッチ* と呼ばれるネッ"
"トワークデバイスに直接接続します。依然として、この概念モデルは有用で、ネット"
"ワーク図ではしばしば Ethernet ネットワークは 1 本のバスであるかのように描かれ"
"ます (OpenStack ダッシュボードが生成するネットワーク図もそうです)。時として "
"Ethernet ネットワークは *レイヤー 2 セグメント* と呼ばれることもあります。"

msgid "Configuration"
msgstr "設定"

msgid "Configuration example"
msgstr "設定例"

msgid ""
"Configuration for the DHCP agent is typically done in the ``dhcp_agent.ini`` "
"configuration file. Make sure that on agent start you pass this "
"configuration file as argument."
msgstr ""
"DHCP エージェントの設定は通常 ``dhcp_agent.ini`` 設定ファイルで行われます。"
"エージェント開始時にこの設定ファイルを引数として指定してください。"

msgid ""
"Configuration for the L3 agent is typically done in the ``l3_agent.ini`` "
"configuration file. Make sure that on agent start you pass this "
"configuration file as argument."
msgstr ""
"L3 エージェントの設定は通常 ``l3_agent.ini`` 設定ファイルで行われます。エー"
"ジェント開始時にこの設定ファイルを引数として指定してください。"

msgid ""
"Configuration for the L3 metering agent is typically done in the "
"``metering_agent.ini`` configuration file. Make sure that on agent start you "
"pass this configuration file as argument."
msgstr ""
"メータリングエージェントの設定は通常 ``metering_agent.ini`` 設定ファイルで行"
"われます。エージェント開始時にこの設定ファイルを引数として指定してください。"

msgid ""
"Configuration for the Linux bridge agent is typically done in the "
"``linuxbridge_agent.ini`` configuration file. Make sure that on agent start "
"you pass this configuration file as argument."
msgstr ""
"Linux ブリッジエージェントの設定は通常 ``linuxbridge_agent.ini`` 設定ファイル"
"で行われます。エージェント開始時にこの設定ファイルを引数として指定してくださ"
"い。"

msgid ""
"Configuration for the MacVTap agent is typically done in the ``macvtap_agent."
"ini`` configuration file. Make sure that on agent start you pass this "
"configuration file as argument."
msgstr ""
"MacVTap エージェントの設定は通常 ``macvtap_agent.ini`` 設定ファイルで行われま"
"す。エージェント開始時にこの設定ファイルを引数として指定してください。"

msgid ""
"Configuration for the Metadata agent is typically done in the "
"``metadata_agent.ini`` configuration file. Make sure that on agent start you "
"pass this configuration file as argument."
msgstr ""
"メタデータエージェントの設定は通常 ``metadata_agent.ini`` 設定ファイルで行わ"
"れます。エージェント開始時にこの設定ファイルを引数として指定してください。"

msgid ""
"Configuration for the Open vSwitch agent is typically done in the "
"``openvswitch_agent.ini`` configuration file. Make sure that on agent start "
"you pass this configuration file as argument."
msgstr ""
"Open vSwitch エージェントの設定は通常 ``openvswitch_agent.ini`` 設定ファイル"
"で行われます。エージェント開始時にこの設定ファイルを引数として指定してくださ"
"い。"

msgid ""
"Configuration for the SRIOV nic switch agent is typically done in the "
"``sriov_agent.ini`` configuration file. Make sure that on agent start you "
"pass this configuration file as argument."
msgstr ""
"SRIOV NIC スイッチエージェントの設定は通常 ``sriov_agent.ini`` 設定ファイルで"
"行われます。エージェント開始時にこの設定ファイルを引数として指定してくださ"
"い。"

msgid "Configuration of the externally accessible network for use case 1"
msgstr "ユースケース 1 での外部からアクセス可能なネットワークの設定"

msgid "Configuration of those drivers is not part of this document."
msgstr "これらのドライバーの設定はこのドキュメントの対象外です。"

msgid "Configurations"
msgstr "設定"

msgid "Configure a DNS resolver on an existing subnet."
msgstr "既存のサブネットの DNS レゾルバーを設定します。"

msgid "Configure a DNS resolver when creating a subnet."
msgstr "サブネット作成時に DNS レゾルバーを設定します。"

msgid ""
"Configure an external DNS driver. The Networking service provides a driver "
"reference implementation based on the OpenStack DNS service. It is expected "
"that third party vendors will provide other implementations in the future. "
"For detailed configuration instructions, see :ref:`config-dns-int-ext-serv`."
msgstr ""
"外部 DNS ドライバーを設定します。 Networking サービスには、 OpenStack DNS "
"サービスを利用する参照実装のドライバーがあります。将来的には、 third party ベ"
"ンダーが他の実装を提供することが期待されています。詳細な設定手順は :ref:"
"`config-dns-int-ext-serv` を参照してください。"

msgid "Configure common options:"
msgstr "共通のオプションを設定します。"

msgid "Configure drivers and network types:"
msgstr "ドライバーとネットワークタイプを設定します。"

msgid "Configure network mappings."
msgstr "ネットワークマッピングを設定します。"

msgid "Configure network mappings:"
msgstr "ネットワークマッピングを設定します。"

msgid "Configure neutron-server (Controller)"
msgstr "neutron-server の設定 (コントローラーノード)"

msgid "Configure nova-scheduler (Controller)"
msgstr "nova-scheduler の設定 (コントローラーノード)"

msgid ""
"Configure the L3 agent. Add the following to ``/etc/neutron/l3_agent.ini``:"
msgstr ""
"L3 エージェントを設定します。 ``/etc/neutron/l3_agent.ini`` に以下を追加しま"
"す。"

msgid ""
"Configure the Open vSwitch agent. Add the following to ``/etc/neutron/"
"plugins/ml2/ml2_conf.ini``:"
msgstr ""
"Open vSwitch エージェントを設定します。 ``/etc/neutron/plugins/ml2/ml2_conf."
"ini`` に以下を追加します。"

msgid "Configure the driver."
msgstr "ドライバーを設定します。"

msgid "Configure the router ID."
msgstr "ルーター ID を設定します。"

msgid ""
"Configure which PCI devices the ``nova-compute`` service may use. Edit the "
"``nova.conf`` file:"
msgstr ""
"``nova-compute`` サービスがどの PCI デバイスを使用できるかを設定します。 "
"``nova.conf`` ファイルを編集します。"

msgid "Configured in the *L2 agent* configuration."
msgstr "*L2 エージェント* 設定により決まります。"

msgid "Configuring LBaaS v2 with Octavia"
msgstr "Octavia を用いた LBaaS v2 の設定"

msgid "Configuring LBaaS v2 with an agent"
msgstr "エージェントを用いた LBaaS v2 の設定"

msgid ""
"Configuring OpenStack Networking for integration with an external DNS service"
msgstr "OpenStack Networking の外部 DNS サービスとの連携の設定"

msgid "Configuring OpenStack Networking for prefix delegation"
msgstr "prefix delegation 用の OpenStack Networking の設定"

msgid "Configuring interfaces of the guest"
msgstr "ゲストのインターフェース設定"

msgid "Configuring the Dibbler server"
msgstr "Dibbler サーバーの設定"

msgid ""
"Configuring the proper burst value is very important. If the burst value is "
"set too low, bandwidth usage will be throttled even with a proper bandwidth "
"limit setting. This issue is discussed in various documentation sources, for "
"example in `Juniper's documentation <http://www.juniper.net/documentation/"
"en_US/junos12.3/topics/concept/policer-mx-m120-m320-burstsize-determining."
"html>`_. Burst value for TCP traffic can be set as 80% of desired bandwidth "
"limit value. For example, if the bandwidth limit is set to 1000kbps then "
"enough burst value will be 800kbit. If the configured burst value is too "
"low, achieved bandwidth limit will be lower than expected. If the configured "
"burst value is too high, too few packets could be limited and achieved "
"bandwidth limit would be higher than expected."
msgstr ""
"適切なバースト値を設定するのは非常に重要です。バースト値が小さすぎると、帯域"
"制限設定が適切であったとしても帯域の使用量が低く制限されてしまいます。この問"
"題は様々なドキュメントで議論されています。例えば、 `Juniper のドキュメント "
"<http://www.juniper.net/documentation/en_US/junos12.3/topics/concept/policer-"
"mx-m120-m320-burstsize-determining.html>`_ があります。 TCP トラフィックの"
"バースト値は、所望の帯域制限値の 80% に設定します。例えば、帯域制限を "
"1000kbps に設定した場合、十分なバースト値は 800kbit になるでしょう。設定した"
"バースト値が小さすぎると、実際の制限帯域は期待する帯域よりも低くなります。設"
"定したバースト値が大きすぎると、制限がかかるパケットが少なくなりすぎ、実際の"
"制限帯域が期待する帯域よりも大きくなることでしょう。"

msgid ""
"Connect a router to each of the project subnets that have been created, for "
"example, using a router called ``router1``:"
msgstr ""
"作成したそれぞれのサブネットをルーターに接続します。例えば、 ``router1`` とい"
"う名前のルーターを使用します。"

msgid "Connection to the OpenStack APIs via an IPv6 transport network"
msgstr "IPv6 ネットワーク経由での OpenStack API への接続"

msgid ""
"Consider an IP address of 192.168.1.5, where the first 24 bits of the "
"address are the network number. In dotted quad notation, the netmask would "
"be written as ``255.255.255.0``. CIDR notation includes both the IP address "
"and netmask, and this example would be written as ``192.168.1.5/24``."
msgstr ""
"192.168.1.5 という IP アドレスで、アドレスの最初の 24 ビットがネットワーク番"
"号であるとしましょう。ドット区切りの 4 つの数字の書式の場合、ネットワークは "
"``255.255.255.0`` と書けます。 CIDR 表記では IP アドレスとネットマスクの両方"
"が含まれ、この例の場合は ``192.168.1.5/24`` と書けます。"

msgid "Contents"
msgstr "内容"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Controller node"
msgstr "コントローラーノード"

msgid "Controller node configuration"
msgstr "コントローラーノードの設定"

msgid ""
"Copy the ``_1481_project_ng_loadbalancersv2_panel.py`` file from the "
"``neutron-lbaas-dashboard/enabled`` directory into the Dashboard "
"``openstack_dashboard/local/enabled`` directory."
msgstr ""
"``neutron-lbaas-dashboard/enabled`` ディレクトリーの "
"``_1481_project_ng_loadbalancersv2_panel.py`` ファイルをダッシュボードの "
"``openstack_dashboard/local/enabled`` ディレクトリーにコピーします。"

msgid "Create IPv6 and IPv4 address scopes:"
msgstr "IPv6 と IPv4 のアドレススコープを作成します。"

msgid "Create Virtual Functions (Compute)"
msgstr "Virtual Function の作成 (コンピュートノード)"

msgid "Create a BGP peer."
msgstr "BGP ピアを作成します。"

msgid "Create a IPv4 subnet on the provider network."
msgstr "プロバイダーネットワークのIPv4サブネットを作成します。"

msgid "Create a IPv6 subnet on the provider network."
msgstr "プロバイダーネットワークのIPv6サブネットを作成します。"

msgid "Create a QoS policy to share:"
msgstr "共有する QoS ポリシーを作成します。"

msgid "Create a couple of networks to host subnets:"
msgstr "サブネットを収容するネットワークを作成します。"

msgid "Create a flat network."
msgstr "フラットネットワークを作成します。"

msgid "Create a floating IP and associate it to the port."
msgstr "Floating IP を作成し、ポートに関連付けします。"

msgid "Create a network that you want to be available as an external network:"
msgstr "外部ネットワークとして利用できるようにするネットワークを作成します。"

msgid "Create a network to share:"
msgstr "共有するネットワークを作成します。"

msgid "Create a network."
msgstr "ネットワークを作成します。"

msgid "Create a port chain"
msgstr "ポートチェインの作成"

msgid ""
"Create a security group and rules to allow TCP port 80, TCP port 443, and "
"all ICMP traffic:"
msgstr ""
"セキュリティーグループを作成し、 TCP ポート 80、 TCP ポート 443 とすべての "
"ICMP トラフィックを許可するルールを作成します。"

msgid "Create a subnet not associated with a subnet pool or an address scope:"
msgstr ""
"サブネットプールにもアドレススコープにも関連付けられないサブネットを作成しま"
"す。"

msgid ""
"Create a subnet on the first two self-service networks using an IP address "
"range from the self-service subnet pool."
msgstr ""
"最初の 2 つのセルフサービスネットワークは、セルフサービスサブネットプールの "
"IP アドレス範囲を使って作成します。"

msgid ""
"Create a subnet on the last self-service network using an IP address range "
"outside of the address scope."
msgstr ""
"最後のセルフサービスネットワークは、アドレススコープに属さない IP アドレス範"
"囲を使って作成します。"

msgid ""
"Create a subnet on the network with one or more service types. For example, "
"the ``compute:nova`` service type enables instances to use this subnet."
msgstr ""
"サービスタイプを 1 つ以上指定して、ネットワークにサブネットを作成します。例え"
"ば、 ``compute:nova`` サービスタイプを指定すると、インスタンスがこのサブネッ"
"トを使うようにできます。"

msgid ""
"Create a subnet on the provider network using an IP address range from the "
"provider subnet pool."
msgstr ""
"プロバイダーサブネットプール内の IP アドレス範囲を使って、プロバイダーネット"
"ワーク上にサブネットを作成します。"

msgid ""
"Create an address scope. The provider (external) and self-service networks "
"must belong to the same address scope for the agent to advertise those self-"
"service network prefixes."
msgstr ""
"アドレススコープを作成します。プロバイダー (外部) ネットワークとセルフサービ"
"スネットワークは同じアドレススコープに属していなければいけません。これは、"
"エージェントはセルフサービスサービスネットワークのプレフィックスを広告するた"
"めに必要です。"

msgid ""
"Create and add ``vhost-user`` network interfaces to instances in the same "
"fashion as conventional interfaces. These interfaces can use the kernel "
"``virtio-net`` driver or a DPDK-compatible driver in the guest"
msgstr ""
"通常と同じ方法で ``vhost-user`` ネットワークインターフェースを作成し、インス"
"タンスに接続できます。これらのインターフェースでは、ゲスト側では、カーネルの "
"``vhost-net`` ドライバー、もしくは DPDK 互換のドライバーを使用できます。"

msgid "Create and configure the BGP speaker"
msgstr "BGP スピーカーの作成と設定"

msgid "Create and configure the routers"
msgstr "ルーターの作成と設定"

msgid "Create default subnetpools"
msgstr "デフォルトのサブネットプールを作成します。"

msgid ""
"Create flow classifier ``FC1`` that matches the appropriate packet headers."
msgstr ""
"必要なパケットヘッダーに一致する Flow Classifier ``FC1`` を作成します。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Create initial networks"
msgstr "初期ネットワークの作成"

msgid ""
"Create port chain ``PC1`` with port pair groups ``PPG1`` and ``PPG2`` and "
"flow classifier ``FC1``."
msgstr ""
"ポートペアグループ ``PPG1``, ``PPG2`` と Flow Classifier ``FC1`` を使って、"
"ポートチェイン ``PC1`` を作成します。"

msgid ""
"Create port pair ``PP1`` with ports ``p1`` and ``p2``, ``PP2`` with ports "
"``p3`` and ``p4``, and ``PP3`` with ports ``p5`` and ``p6``."
msgstr ""
"ポート ``p1`` と ``p2`` でポートペア ``PP1`` を作成します。同様に、ポート "
"``p3`` と ``p4`` でポートペア ``PP2`` を、ポート ``p5`` と ``p6`` でポートペ"
"ア ``PP3`` を作成します。"

msgid ""
"Create port pair group ``PPG1`` with port pair ``PP1`` and ``PP2`` and "
"``PPG2`` with port pair ``PP3``."
msgstr ""
"ポートペア ``PP1`` と ``PP2`` でポートペアグループ ``PPG1`` を作成します。ま"
"た、ポートペア ``PP3`` でポートペアグループ ``PPG2`` を作成します。"

msgid "Create ports on network ``net1`` and record the UUID values."
msgstr ""
"ネットワーク ``net1`` にポートを作成し、その UUID 値を記録しておきます。"

msgid "Create shared address scopes as an administrative user"
msgstr "管理者での共有アドレススコープの作成"

msgid ""
"Create subnet pools specifying the name (or UUID) of the address scope that "
"the subnet pool belongs to. If you have existing subnet pools, use the :"
"command:`openstack subnet pool set` command to put them in a new address "
"scope:"
msgstr ""
"サブネットプールが所属するアドレススコープの名前 (または UUID) を指定してサブ"
"ネットプールを作成します。既存のサブネットプールがある場合、 :command:"
"`openstack subnet pool set` コマンドを使って、既存のサブネットプールを新しい"
"アドレススコープに所属させることもできます。"

msgid ""
"Create subnet pools. The provider and self-service networks use different "
"pools."
msgstr ""
"サブネットプールを作成します。プロバイダーネットワークとセルフサービスネット"
"ワークは異なるプールを使用します。"

msgid "Create the BGP speaker."
msgstr "BGP スピーカーを作成します。"

msgid ""
"Create the SR-IOV port. ``vnic_type=direct`` is used here, but other options "
"include ``normal``, ``direct-physical``, and ``macvtap``:"
msgstr ""
"SR-IOV ポートを作成します。ここでは ``vnic_type=direct`` を指定していますが、"
"他の有効な値としては ``normal``, ``direct-physical``, ``macvtap`` がありま"
"す。"

msgid ""
"Create the VFs for the network interface that will be used for SR-IOV. We "
"use ``eth3`` as PF, which is also used as the interface for the VLAN "
"provider network and has access to the private networks of all machines."
msgstr ""
"SR-IOV 用に使用予定のネットワークインターフェースで VF を作成します。ここで"
"は ``eth3`` を PF として使用します。 ``eth3`` は VLAN プロバイダーネットワー"
"クに接続するインターフェースとしても使用され、すべてのインスタンスのプライ"
"ベートネットワークにも到達性があります。"

msgid "Create the address scope and subnet pools"
msgstr "アドレススコープとサブネットプールの作成"

msgid ""
"Create the instance. Specify the SR-IOV port created in step two for the NIC:"
msgstr ""
"インスタンスを作成します。 2 番目の手順で作成した SR-IOV ポートを NIC に指定"
"します。"

msgid "Create the provider and self-service networks"
msgstr "プロバイダーネットワークとセルフサービスネットワークの作成"

msgid "Create the provider network pool."
msgstr "プロバイダーネットワーク用のプールを作成します。"

msgid "Create the provider network."
msgstr "プロバイダーネットワークを作成します。"

msgid "Create the routers."
msgstr "ルーターを作成します。"

msgid "Create the self-service network pool."
msgstr "セルフサービスネットワーク用のプールを作成します。"

msgid "Create the self-service networks."
msgstr "セルフサービスネットワークを作成します。"

msgid ""
"Creating CIDR subnets including a multicast address or a loopback address "
"cannot be used in an OpenStack environment. For example, creating a subnet "
"using ``224.0.0.0/16`` or ``127.0.1.0/24`` is not supported."
msgstr ""
"マルチキャストアドレスやループバックアドレスを含む CIDR サブネットを作ると、"
"OpenStack 環境では使用できません。例えば、 ``224.0.0.0/16`` や "
"``127.0.1.0/24`` を使うサブネットの作成はサポートされません。"

msgid ""
"Creating a subnet with a service type requires administrative privileges."
msgstr ""
"サービスタイプを指定してサブネットを作成するには、管理者権限が必要です。"

msgid ""
"Creating or updating a port with a specific subnet skips this selection "
"process and explicitly uses the given subnet."
msgstr ""
"特定のサブネットを指定してポートの作成や更新を行った場合は、この選択処理はス"
"キップされ、指定されたサブネットが明示的に使用されます。"

msgid "Currently, SFC lacks support for multi-project service functions."
msgstr ""
"現時点では、 SFC は、複数のプロジェクトに属するサービス機能を扱うことはできま"
"せん。"

msgid ""
"Currently, no migration path exists between v1 and v2 load balancers. If you "
"choose to switch from v1 to v2, you must recreate all load balancers, pools, "
"and health monitors."
msgstr ""
"現在のところ、 v1 と v2 のロードバランサー間での移行方法は存在しません。 v1 "
"から v2 に切り替える場合には、すべてのロードバランサー、プール、ヘルスモニ"
"ターを作り直す必要があります。"

msgid ""
"Currently, the ``shared`` flag is just a mapping to the underlying RBAC "
"policies for a network. Setting the flag to ``True`` on a network creates a "
"wildcard RBAC entry. Setting it to ``False`` removes the wildcard entry."
msgstr ""
"現時点では、 ``shared`` フラグは単にネットワークの RBAC ポリシーにマッピング"
"されているだけです。ネットワークの ``shared`` フラグを ``True`` に設定する"
"と、ワイルドカードの RBAC エントリーが作成されます。 フラグを ``False`` に設"
"定すると、ワイルドカードエントリーは削除されます。"

msgid ""
"Currently, the access that can be granted using this feature is supported by:"
msgstr "現在のところ、この機能を使ってアクセスを許可できるのは以下の操作です。"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_basic_networking.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_service.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "DHCP"
msgstr "DHCP"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "DHCP agent"
msgstr "DHCP エージェント"

msgid ""
"DHCP clients locate the DHCP server by sending a UDP_ packet from port 68 to "
"address ``255.255.255.255`` on port 67. Address ``255.255.255.255`` is the "
"local network broadcast address: all hosts on the local network see the UDP "
"packets sent to this address. However, such packets are not forwarded to "
"other networks. Consequently, the DHCP server must be on the same local "
"network as the client, or the server will not receive the broadcast. The "
"DHCP server responds by sending a UDP packet from port 67 to port 68 on the "
"client. The exchange looks like this:"
msgstr ""
"DHCP クライアントは、ポート番号 68 からアドレス ``255.255.255.255`` のポート"
"番号 67 に対して UDP_ パケットを送信して、 DHCP サーバーを探します。 "
"``255.255.255.255`` はローカルネットワークのブロードキャストアドレスです。"
"ローカルネットワークのすべてのホストで、このアドレスに送信された UDP パケット"
"が見えます。しかし、このパケットは他のネットワークには転送されません。した"
"がって、 DHCP サーバーはクライアントと同じローカルネットワークに存在しなけれ"
"ばならないということです。さもないと、サーバーはブロードキャストを受信できま"
"せん。 DHCP サーバーは、ポート番号 67 からクライアントのポート番号 68 に UDP "
"パケットを送信して、応答を行います。やり取りは以下のようになります。"

msgid "DHCP high availability"
msgstr "DHCP の高可用性"

msgid ""
"DHCP services are created on availability zones you selected when creating "
"the network."
msgstr ""
"DHCP サービスは、ネットワーク作成時に指定したアベイラビリティーゾーンに作成さ"
"れます。"

msgid ""
"DHCP_, the Domain Name System (DNS), the Network Time Protocol (NTP), and :"
"ref:`VXLAN` are examples of UDP-based protocols used in OpenStack "
"deployments."
msgstr ""
"DHCP_、Domain Name System (DNS)、Network Time Protocol (NTP)、:ref:`VXLAN` "
"が、OpenStack 環境で使用される UDP 系のプロトコルの例です。"

msgid "DHCPv6"
msgstr "DHCPv6"

msgid "DHCPv6-stateful"
msgstr "DHCPv6-stateful"

msgid "DHCPv6-stateless"
msgstr "DHCPv6-stateless"

msgid "DNAT"
msgstr "DNAT"

msgid "DNS integration"
msgstr "DNS 連携"

msgid "DPDK 2.0"
msgstr "DPDK 2.0"

msgid "DPDK 2.2"
msgstr "DPDK 2.2"

msgid ""
"DVR lacks support for routing directly to a fixed IP address via the "
"floating IP agent gateway port and thus prevents the BGP speaker from "
"advertising fixed IP addresses."
msgstr ""
"DVR は、 Floating IP エージェントのゲートウェイポート経由での Fixed IP アドレ"
"スへの直接のルーティングに対応していません。そのため、 BGP スピーカーは "
"Fixed IP アドレスを広告できません。"

msgid "DVR with IPv6 functions similarly to DVR with IPv4."
msgstr "IPv6 での DVR 機能は IPv4 での DVR を同様です。"

msgid "Database"
msgstr "データベース"

msgid "Database downgrade is not supported."
msgstr "データベースのダウングレードはサポートされていません。"

msgid "Database management command-line tool"
msgstr "データベース管理コマンドラインツール"

msgid "Dataplane"
msgstr "データプレーン"

msgid ""
"Deactivating the network will remove the ``virbr0`` bridge, terminate the "
"dnsmasq process, and remove the iptables rules."
msgstr ""
"このネットワークを非活性化すると、 ``virbr0`` ブリッジは削除され、 dnsmasq プ"
"ロセスは終了され、 iptables ルールセットは削除されます。"

msgid "Default scheduling."
msgstr "デフォルトのスケジューリング。"

msgid "Default subnet pools"
msgstr "デフォルトサブネットプール"

msgid "Define how an OpenStack network is technically realized. Example: VXLAN"
msgstr ""
"OpenStack ネットワークがどの技術で実現されているかを定義します。例: VXLAN"

msgid ""
"Define one or more service types for one or more subnets on a particular "
"network. Each service type must correspond to a valid device owner within "
"the port model in order for it to be used."
msgstr ""
"あるネットワークの 1 つ以上のサブネットにサービスタイプを 1 つ以上定義しま"
"す。サービスタイプを使用するには、サービスタイプがポートモデルの有効な "
"device_owner に対応する必要があります。"

msgid ""
"Define the mechanism to access an OpenStack network of a certain type. "
"Example: Open vSwitch mechanism driver."
msgstr ""
"あるタイプの OpenStack ネットワークを実現する仕組みを定義します。例: Open "
"vSwitch メカニズムドライバー。"

msgid "Definition"
msgstr "定義"

msgid "Delete the network resources for a particular project."
msgstr "特定のプロジェクトのネットワークリソースを削除します。"

msgid ""
"Deleting the router interface causes the subnet to be reverted to the "
"temporary CIDR, and all ports have their IPs updated. Prefix leases are "
"released and renewed automatically as necessary."
msgstr ""
"ルーターインターフェースを削除すると、サブネットは仮の CIDR に戻り、すべての"
"ポートの IP アドレスが更新されます。移譲されていたプレフィックスは解放され、"
"必要に応じて自動的に新たに使用されます。"

msgid "Demo"
msgstr "デモ"

msgid "Demo setup"
msgstr "デモ環境の構成"

msgid "Description"
msgstr "説明"

msgid ""
"Different types of agents show different details. The following output shows "
"information for a Linux bridge agent:"
msgstr ""
"別の種類のエージェントでは別の詳細が表示されます。以下は Linux ブリッジエー"
"ジェントの情報を表示したものです。"

msgid "Direct assignment during subnet creation via command line or Horizon"
msgstr "サブネット作成時にコマンドラインや Horizon で直接指定する"

msgid "Direct port and normal port instances reside on the same compute node."
msgstr ""
"SR-IOV ポートを持つインスタンスと通常ポートのインスタンスを同じコンピュート"
"ノード上に配置する"

msgid ""
"Direct port instance that uses floating IP address and network node are "
"located on the same host."
msgstr ""
"Floating IP アドレスを使用する SR-IOV ポートを持つインスタンスとネットワーク"
"ノードを同じホストに配置する"

msgid "Disable libvirt networking"
msgstr "libvirt ネットワークの無効化"

msgid "Disable nova-compute."
msgstr "nova-compute を無効にします。"

msgid "Disable the DHCP agent on HostA before you stop it:"
msgstr "HostA のエージェントを停止する前に無効化します。"

msgid ""
"Disable the hypervisor. This would be a good time to live migrate or "
"evacuate the compute node, if supported."
msgstr ""
"ハイパーバイザーを無効にします。サポートされている場合は、対象のコンピュート"
"ノードからライブマイグレーションや退避 (evacuate) を行うよいタイミングでしょ"
"う。"

msgid "Disabling and removing an agent"
msgstr "エージェントの無効化と削除"

msgid "Distributed Virtual Routing with VRRP"
msgstr "分散仮想ルーティングと VRRP の組み合わせ"

msgid ""
"Do essentially the same thing for IPv6 and there are now two subnet pools. "
"Regular projects can see them. (the output is trimmed a bit for display)"
msgstr ""
"IPv6 についても全く同じことを行うと、 2 つのサブネットプールができます。これ"
"らのサブネットプールは通常のプロジェクトから参照できます (この出力は見やすく"
"するため少し省略しています)。"

msgid ""
"Drivers other than the default one may require extra configuration, please "
"refer to :ref:`extra-driver-conf`"
msgstr ""
"デフォルト以外のドライバーの場合、追加の設定が必要な場合があります。 :ref:"
"`extra-driver-conf` を参照してください。"

msgid ""
"Due to direct connection, some features are not available when using SRIOV. "
"For example, DVR, security groups, migration."
msgstr ""
"直接アクセスを行うため、 SRIOV を使う場合、利用できない機能があります。例え"
"ば、 DVR、セキュリティーグループ、マイグレーションなどです。"

msgid ""
"Due to the direct connection, some features are not available when using it "
"on the compute node. For example, DVR, security groups and arp-spoofing "
"protection."
msgstr ""
"直接アクセスを行うため、コンピュートノードで macvtap を使う場合、利用できない"
"機能があります。例えば、 DVR、セキュリティーグループ、 ARP 詐称防止などです。"

msgid ""
"During IP allocation, the :ref:`IPAM <config-ipam>` driver returns an "
"address from a subnet with a service type matching the port device owner. If "
"no subnets match, or all matching subnets lack available IP addresses, the "
"IPAM driver attempts to use a subnet without any service types to preserve "
"compatibility. If all subnets on a network have a service type, the IPAM "
"driver cannot preserve compatibility. However, this feature enables strict "
"IP allocation from subnets with a matching device owner. If multiple subnets "
"contain the same service type, or a subnet without a service type exists, "
"the IPAM driver selects the first subnet with a matching service type. For "
"example, a floating IP agent gateway port uses the following selection "
"process:"
msgstr ""
"IP 割り当ての際、 :ref:`IPAM <config-ipam>` ドライバーは、ポートの "
"device_owner に一致するサービスタイプを持つサブネットからアドレスを返します。"
"一致するサブネットがない場合や、一致するすべてのサブネットに利用可能な IP ア"
"ドレスが不足している場合、 IPAM ドライバーは、これまでと同じ動作をするよう、"
"サービスタイプが指定されていないサブネットを使って IP アドレスを割り当てよう"
"とします。ネットワーク上のすべてのサブネットにサービスタイプが指定されている"
"場合には、 IPAM ドライバーはこれまでと同じ動作を保つことはできません。一方"
"で、この機能を使うと、 device owner にマッチするサブネットから厳密に IP 割り"
"当てができます。同じサービスタイプを持つサブネットが複数ある場合や、サービス"
"タイプが指定されていないサブネットが存在する場合、 IPAM ドライバーはサービス"
"タイプに一致した最初のサブネットを選択します。例えば、 Floating IP エージェン"
"トゲートウェイは以下の順番で選択を行います。"

msgid ""
"During normal operation, the master router periodically transmits "
"*heartbeat* packets over a hidden project network that connects all HA "
"routers for a particular project."
msgstr ""
"通常動作中は、マスタールーターは定期的に *heartbeat* パケットを、隠しプロジェ"
"クトネットワーク経由で送信します。隠しプロジェクトネットワークには、1 つのプ"
"ロジェクトのすべての HA ルーターが接続されます。"

msgid ""
"During the migration, nova-network API calls will go through an additional "
"internal conversion to Networking calls. This will have different and likely "
"poorer performance characteristics compared with either the pre-migration or "
"post-migration APIs."
msgstr ""
"移行の途中では、 nova-network API 呼び出しは内部で Networking の呼び出しに変"
"換されます。そのため、移行前や移行後の API と比べると、違った、性能特性、おそ"
"らく低い性能性能になることでしょう。"

msgid ""
"Each available network type is managed by an ML2 type driver. Type drivers "
"maintain any needed type-specific network state. They validate the type "
"specific information for provider networks and are responsible for the "
"allocation of a free segment in project networks."
msgstr ""
"利用可能なネットワークタイプはそれぞれ ML2 タイプドライバーにより管理されま"
"す。タイプドライバーはネットワークタイプ固有の必要な情報を管理します。プロバ"
"イダーネットワークではタイプ固有の情報の検証を行い、プロジェクトのネットワー"
"クの場合は空きセグメントの割り当てを行います。"

msgid ""
"Each network namespace also has its own routing table, and in fact this is "
"the main reason for namespaces to exist. A routing table is keyed by "
"destination IP address, so network namespaces are what you need if you want "
"the same destination IP address to mean different things at different times "
"- which is something that OpenStack Networking requires for its feature of "
"providing overlapping IP addresses in different virtual networks."
msgstr ""
"各々のネットワーク名前空間は独自のルーティングテーブルも持ちます。実際のとこ"
"ろ、これが名前空間が存在する主要な理由です。ルーティングテーブルは宛先 IP ア"
"ドレスをキーとして検索が行われるので、ネットワーク名前空間は、同じ宛先 IP ア"
"ドレスに時と場合に応じて異なる意味を持たせたい場合に必要となります。これは、"
"OpenStack Networking が異なる仮想ネットワークで IP アドレス重複を許容する機能"
"を実現する際に必要となる機能なのです。"

msgid ""
"Each network namespace also has its own set of iptables (for both IPv4 and "
"IPv6). So, you can apply different security to flows with the same IP "
"addressing in different namespaces, as well as different routing."
msgstr ""
"各々のネットワーク名前空間は独自の iptables 集合 (IPv4 と IPv6 の両方) を持ち"
"ます。したがって、別の名前空間では、異なるルーティングだけでなく、同じ IP ア"
"ドレスのフローに対して異なるセキュリティーを適用できます。"

msgid ""
"Each router interface is associated with an address scope by looking at "
"subnets connected to the network. When a router connects to an external "
"network with matching address scopes, network traffic routes between without "
"Network address translation (NAT). The router marks all traffic connections "
"originating from each interface with its corresponding address scope. If "
"traffic leaves an interface in the wrong scope, the router blocks the "
"traffic."
msgstr ""
"各ルーターインターフェースは、そのインターフェースが接続されたネットワークの"
"サブネットを参照し、アドレススコープと関連付けされます。ルーターをアドレスス"
"コープが一致する外部ネットワークに接続した場合、ネットワークトラフィックは "
"NAT (ネットワークアドレス変換) なしでルーティングされます。ルーターは、内部で"
"は、各インターフェースからのすべてのトラフィック接続を対応するアドレススコー"
"プと関連付けます。トラフィックが間違ったスコープのインターフェースからやって"
"来た場合は、ルーターはそのトラフィックをブロックします。"

msgid ""
"Edit the ``/etc/neutron/neutron.conf`` file and assign a value different to "
"``openstacklocal`` (its default value) to the ``dns_domain`` parameter in "
"the ``[default]`` section. As an example:"
msgstr ""
"``/etc/neutron/neutron.conf`` ファイルを編集し、 ``[default]`` セクションの "
"``dns_domain`` パラメーターに (デフォルト値の)  ``openstacklocal`` 以外の値を"
"割り当てます"

msgid ""
"Edit the ``[default]`` section of ``/etc/neutron/neutron.conf`` and specify "
"the external DNS service driver to be used in parameter "
"``external_dns_driver``. The valid options are defined in namespace "
"``neutron.services.external_dns_drivers``. The following example shows how "
"to set up the driver for the OpenStack DNS service:"
msgstr ""
"``/etc/neutron/neutron.conf`` の ``[default]`` セクションを編集し、使用する外"
"部 DNS サービスを  ``external_dns_driver`` パラメーターで指定します。指定でき"
"る値は ``neutron.services.external_dns_drivers`` 名前空間に定義されています。"
"以下の例では OpenStack DNS サービス用のドライバーの設定方法を説明します。"

msgid ""
"Edit the ``ovs_agent.ini`` or ``linuxbridge_agent.ini`` file on each compute "
"node. For example:"
msgstr ""
"各コンピュートノードで ``ovs_agent.ini`` または ``linuxbridge_agent.ini`` を"
"編集します。"

msgid "Edit the ``sriov_agent.ini`` file on each compute node. For example:"
msgstr "各コンピュートノードで ``sriov_agent.ini`` ファイルを編集します。例:"

msgid ""
"Effectively the ``ipv6_gateway`` flag takes precedence over an RA that is "
"received from the upstream router. If it is desired to use a GUA next hop "
"that is accomplished by allocating a subnet to the external router port and "
"assigning the upstream routers GUA address as the gateway for the subnet."
msgstr ""
"実際には、 ``ipv6_gateway`` フラグが上流ルーターから受信する RA よりも優先さ"
"れます。 GUA のネクストホップを使いたい場合は、外部ルーターポートにサブネット"
"を確保して、そのサブネットのゲートウェイとして上流ルーターの GUA アドレスを割"
"り当てることで実現できます。"

msgid ""
"Enable IOMMU in Linux by adding ``intel_iommu=on`` to the kernel parameters, "
"for example, using GRUB."
msgstr ""
"Linux で IOMMU を有効にするには、 GRUB などを使って、カーネルパラメーターに "
"``intel_iommu=on`` を追加します。"

msgid ""
"Enable a nova-api proxy that recreates internal Compute objects from "
"Networking information (via the Networking REST API)."
msgstr ""
"nova-api プロキシーを有効にします。nova-api プロキシーは、(Networking REST "
"API 経由で) Networking の情報から Compute の内部オブジェクトを再作成します。"

msgid "Enable neutron sriov-agent (Compute)"
msgstr "neutron sriov-agent の有効化 (コンピュートノード)"

msgid "Enable the Networking agent."
msgstr "Networking エージェントを有効にします。"

msgid ""
"Enable the functionality described in :ref:`config-dns-int-dns-resolution`."
msgstr ""
":ref:`config-dns-int-dns-resolution` で説明されている機能を有効にします。"

msgid "Enable the native OVS firewall driver"
msgstr "ネイティブ OVS ファイアウォールドライバーの有効化"

msgid "Enable the neutron sriov-agent service."
msgstr "neutron sriov-agent を有効にします。"

msgid ""
"Enable the plug-in in Dashboard by editing the ``local_settings.py`` file "
"and setting ``enable_lb`` to ``True`` in the ``OPENSTACK_NEUTRON_NETWORK`` "
"dictionary."
msgstr ""
"``local_settings.py`` ファイルを編集し、 ``OPENSTACK_NEUTRON_NETWORK`` の "
"``enable_lb`` を ``True`` にすることで、ダッシュボードでこのプラグインを有効"
"化します。"

msgid "Enabling DHCP high availability by default"
msgstr "デフォルトで DHCP の高可用性を有効にする"

msgid "Enabling the deployment for auto-allocation"
msgstr "デプロイメントで自動割り当てを有効にする"

msgid "Ensure SR-IOV and VT-d are enabled in BIOS."
msgstr "BIOS で SR-IOV と VT-d を有効にしてください。"

msgid ""
"Ensure that the LBaaS v1 and v2 service providers are removed from the "
"``[service_providers]`` section. They are not used with Octavia. **Verify "
"that all LBaaS agents are stopped.**"
msgstr ""
"LBaaS v1 と v2 のサービスプロバイダーは ``[service_provider]`` セクションから"
"必ず削除してください。これらは Octavia の場合には使用されません。 **すべての "
"LBaaS エージェントが停止していることを確認してください。**"

msgid "Ensure the neutron sriov-agent runs successfully:"
msgstr "neutron sriov-agent が正常に実行できることを確認します。"

msgid "Ethernet"
msgstr "Ethernet"

msgid ""
"Ethernet is a networking protocol, specified by the IEEE 802.3 standard. "
"Most wired network interface cards (NICs) communicate using Ethernet."
msgstr ""
"Ethernet は IEEE 802.3 標準で規程されたネットワークプロトコルです。ほとんどの"
"有線のネットワークインターフェースカード (NIC) は Ethernet を使って通信しま"
"す。"

msgid ""
"Every agent that supports these extensions will register itself with the "
"neutron server when it starts up."
msgstr ""
"これらの拡張機能に対応した全エージェントは、開始時に neutron サーバーに自身を"
"登録します。"

msgid "Example configuration"
msgstr "設定例"

msgid ""
"Expect performance degradation of services using tap devices: these devices "
"do not support DPDK. Example services include DVR, FWaaS, or LBaaS."
msgstr ""
"tap デバイスを使用するサービスでは性能の劣化が見込まれます。 tap デバイスは "
"DPDK には対応していません。このようなサービスとしては、 DVR、 FWaaS、 LBaaS "
"などがあります。"

msgid "Experimental feature or incomplete documentation."
msgstr "実験的な機能で、ドキュメントも不十分です。"

msgid "Extensions"
msgstr "API 拡張"

msgid "External Router A,M,O"
msgstr "External Router A,M,O"

msgid ""
"External mechanism drivers from various vendors exist as well as the neutron "
"integrated reference implementations."
msgstr ""
"neutron 組み込みの参照実装以外に、様々なベンダーからメカニズムドライバーが提"
"供されています。"

msgid ""
"External open source mechanism drivers exist as well as the neutron "
"integrated reference implementations. Configuration of those drivers is not "
"part of this document. For example:"
msgstr ""
"neutron 組み込みの参照実装以外にも、オープンソースドライバーがあります。これ"
"らのドライバーの設定はこのドキュメントの対象外です。例:"

msgid "Extra configuration"
msgstr "追加の設定"

# #-#-#-#-#  adv_config_FwaaS.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  adv_config_ipv6.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "FWaaS"
msgstr "FWaaS"

msgid "FWaaS allows creation of IPv6 based rules."
msgstr "FWaaS では、IPv6 を使ったルールを作成できます。"

msgid ""
"Filtering resources with a tag whose name contains a comma is not supported. "
"Thus, do not put such a tag name to resources."
msgstr ""
"名前にコンマが入ったタグによるリソースのフィルタリングには対応していません。"
"したがって、コンマが入ったタグ名をリソースに付与しないでください。"

msgid "Filtering with tags"
msgstr "タグによるフィルタリング"

msgid "Firewalls"
msgstr "ファイアウォール"

msgid ""
"Firewalls are used to regulate traffic to and from a host or a network. A "
"firewall can be either a specialized device connecting two networks or a "
"software-based filtering mechanism implemented on an operating system. "
"Firewalls are used to restrict traffic to a host based on the rules defined "
"on the host. They can filter packets based on several criteria such as "
"source IP address, destination IP address, port numbers, connection state, "
"and so on. It is primarily used to protect the hosts from unauthorized "
"access and malicious attacks. Linux-based operating systems implement "
"firewalls through ``iptables``."
msgstr ""
"ファイアウォールは、ホストやネットワークへのトラフィックを制御をするのに使用"
"されます。ファイアウォールは、 2 つのネットワークに接続された特別なデバイスの"
"場合もありますし、オペレーティング・システム上に実装されたソフトウェアベース"
"のフィルタリング機構の場合もあります。ファイアウォールは、そのホストで定義さ"
"れたルールに基いてホストへのトラフィックを制限します。送信元 IP アドレス、宛"
"先 IP アドレス、ポート番号、コネクションの状態、などの様々な基準に基いてパ"
"ケットのフィルタリングを行います。主に、ホストを許可されていないアクセスや悪"
"意のある攻撃から保護するために使用されます。 Linux ベースのオペレーティングシ"
"ステムでは、ファイアウォールは ``iptables`` として実装されています。"

msgid "First, as admin, create a shared subnet pool:"
msgstr "まず、管理者で、共有サブネットプールを作成します。"

msgid "First, create a QoS policy and its bandwidth limit rule:"
msgstr "最初に、 QoS ポリシーと帯域制限ルールを作成します。"

msgid "First, create a network and IPv6 subnet:"
msgstr "最初に、ネットワークと IPv6 サブネットを作成します。"

msgid ""
"First, would not it be nice if you could turn your pool of addresses over to "
"Neutron to take care of?  When you need to create a subnet, you just ask for "
"addresses to be allocated from the pool. You do not have to worry about what "
"you have already used and what addresses are in your pool. Subnet pools can "
"do this."
msgstr ""
"まず、あなたが使用するアドレスプールを Neutron の管理に任せてしまうと、いいと"
"は思いませんか？サブネットを作る必要がある際に、プールからアドレスを割り当て"
"てもらうように依頼するだけです。どのアドレスプールをすでに使用しているか、ど"
"のアドレスがあなたが使用できるアドレスプールに含まれているか、といったことを"
"気にかける必要はありません。サブネットプールがこうしたことをやってくれます。"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_overview.pot (Networking Guide 0.9)
# #-#-#-#-#
msgid "Flat"
msgstr "Flat"

msgid "Floating IP addresses"
msgstr "Floating IP アドレス"

msgid "Floating IPs"
msgstr "Floating IP"

msgid "Flow classifier"
msgstr "Flow Classifier"

msgid ""
"Following are the PTR records created for this example. Note that for IPv4, "
"the value of ipv4_ptr_zone_prefix_size is 24. For more details, see :ref:"
"`config-dns-int-ext-serv`:"
msgstr ""
"以下は、この例で作成された PTR レコードです。 IPv4 の場合は "
"ipv4_ptr_zone_prefix_size の値が 24 です。詳細は :ref:`config-dns-int-ext-"
"serv` を参照してください。"

msgid ""
"Following are the PTR records created for this example. Note that for IPv4, "
"the value of ipv4_ptr_zone_prefix_size is 24. In the case of IPv6, the value "
"of ipv6_ptr_zone_prefix_size is 116. For more details, see :ref:`config-dns-"
"int-ext-serv`:"
msgstr ""
"以下は、この例で作成された PTR レコードです。 IPv4 の場合は "
"ipv4_ptr_zone_prefix_size の値が 24 で、 IPv6 の場合は "
"ipv6_ptr_zone_prefix_size の値が 116 です。詳細は :ref:`config-dns-int-ext-"
"serv` を参照してください。"

msgid "Following is an example of these steps:"
msgstr "以下は実行例です。"

msgid ""
"For additional information describing the problem, refer to: `Virtual "
"switching technologies and Linux bridge. <http://events.linuxfoundation.org/"
"sites/events/files/slides/LinuxConJapan2014_makita_0.pdf>`_"
msgstr ""
"この問題の詳しい情報は、  `Virtual switching technologies and Linux bridge. "
"<http://events.linuxfoundation.org/sites/events/files/slides/"
"LinuxConJapan2014_makita_0.pdf>`_ を参照してください。"

msgid ""
"For an ml2 plug-in, the list of supported QoS rule types is defined as a "
"common subset of rules supported by all active mechanism drivers."
msgstr ""
"ML2 プラグインの場合、サポートされる QoS ルール種別のリストは、有効になってい"
"る全メカニズムドライバーでサポートされているルールの共通のサブセットになりま"
"す。"

msgid ""
"For each router, add one self-service subnet as an interface on the router."
msgstr ""
"それぞれのルーターで、セルフサービスサブネットをルーターのインターフェースと"
"して追加します。"

msgid ""
"For example, Linux provides namespaces for networking and processes, among "
"other things. If a process is running within a process namespace, it can "
"only see and communicate with other processes in the same namespace. So, if "
"a shell in a particular process namespace ran :command:`ps waux`, it would "
"only show the other processes in the same namespace."
msgstr ""
"例えば、 Linux は、他にもありますが、ネットワークとプロセスの名前空間を提供し"
"ています。プロセスがプロセス名前空間内で実行されている場合、そのプロセスには"
"同じ名前空間内の他のプロセスだけが見え、通信できるのも名前空間内のプロセスだ"
"けです。そのため、あるプロセス名前空間内のシェルで :command:`ps waux` を実行"
"すると、同じ名前空間内の他のプロセスだけが表示されます。"

msgid "For example, add flow classifier ``FC2`` to port chain ``PC1``:"
msgstr ""
"例えば、 Flow Classifier ``FC2`` をポートチェイン ``PC1`` に追加します。"

msgid "For example, add port pair group ``PPG3`` to port chain ``PC1``:"
msgstr ""
"例えば、ポートペアグループ ``PPG3`` をポートチェイン ``PC1`` に追加します。"

msgid "For example, consider the following components:"
msgstr "例えば、以下の構成要素がある場合を考えます。"

msgid ""
"For example, referencing a 4000-byte MTU for ``provider2``, a 1500-byte MTU "
"for ``provider3``, and a 9000-byte MTU for other networks using the Open "
"vSwitch agent:"
msgstr ""
"例えば、Open vSwitch エージェントを使う場合で、 ``provider2`` の MTU は 4000 "
"バイト、 ``provider3`` の MTU は 1500 バイト、それ以外のネットワークの MTU "
"は 9000 バイトの場合には、以下のように設定します。"

msgid ""
"For example, referencing a 4000-byte MTU for overlay networks and a 9000-"
"byte MTU for other networks:"
msgstr ""
"例えば、オーバーレイネットワーク側の MTU が 4000 バイトで、他のネットワーク"
"の MTU が 9000 バイトの場合には、以下のように設定します。"

msgid ""
"For example, referencing an underlying physical network with a 9000-byte MTU:"
msgstr ""
"例えば、アンダーレイ物理ネットワークの MTU が 9000 バイトの場合には、以下のよ"
"うに設定します。"

msgid "For example, to match any domain, bus 0a, slot 00, and all functions:"
msgstr ""
"例えば、任意のドメイン、バス 0a、スロット 00 のすべての PCI ファンクションに"
"マッチするようにするには以下のようにします。"

msgid "For more information see the :ref:`config-sriov`."
msgstr "詳しい情報は :ref:`config-sriov` を参照してください。"

msgid ""
"For network types VLAN, GRE, VXLAN or GENEVE, the segmentation ID must be "
"outside the ranges assigned to tenant networks."
msgstr ""
"ネットワーク種別が VLAN, GRE, VXLAN, GENEVE の場合、セグメンテーション ID は"
"テナントネットワークへの割り当て範囲外でなければいけません。"

msgid ""
"For networked software applications to communicate over an IP network, they "
"must use a protocol layered atop IP. These protocols occupy the fourth layer "
"of the OSI model known as the *transport layer* or *layer 4*. See the "
"`Protocol Numbers <http://www.iana.org/assignments/protocol-numbers/protocol-"
"numbers.xhtml>`_ web page maintained by the Internet Assigned Numbers "
"Authority (IANA) for a list of protocols that layer atop IP and their "
"associated numbers."
msgstr ""
"IP ネットワーク上で通信するネットワークソフトウェア・アプリケーションは、 IP "
"の上位層のプロトコルを使用する必要があります。これらのプロトコルは OSI モデル"
"の第 4 層にあたり、 *トランスポート層* や *レイヤー 4* とも呼ばれます。 "
"Internet Assigned Numbers Authority (IANA) が管理している `Protocol Numbers "
"<http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml>`_ "
"のウェブページを見ると、 IP の上位層に位置するプロトコルと割り当てられている"
"番号の一覧があります。"

msgid ""
"For the above two attributes to be effective, ``enable_dhcp`` of the subnet "
"object must be set to True."
msgstr ""
"上記の 2 つの属性が意味を持つには、そのサブネットの ``enable_dhcp`` 属性が "
"True になっていなければなりません。"

msgid ""
"For typical underlying physical network architectures that implement a "
"single MTU value, you can leverage jumbo frames using two options, one in "
"the ``neutron.conf`` file and the other in the ``ml2_conf.ini`` file. Most "
"environments should use this configuration."
msgstr ""
"使用する MTU 値が 1 つだけの一般的なアンダーレイ物理ネットワークアーキテク"
"チャーの場合、 2 つのオプションを使うことでジャンボフレームを活用できます。 "
"1 つは ``neutron.conf`` ファイルで設定し、もう 1 つは ``ml2_conf.ini`` ファイ"
"ルで設定します。ほとんどの環境で、この設定が使用できることでしょう。"

msgid ""
"Forwarding DataBase (FDB) population is an L2 agent extension to OVS agent "
"or Linux bridge. Its objective is to update the FDB table for existing "
"instance using normal port. This enables communication between SR-IOV "
"instances and normal instances. The use cases of the FDB population "
"extension are:"
msgstr ""
"FDB (Forwarding Database) population は、 OVS エージェントや Linux ブリッジ"
"エージェントに対する L2 エージェント拡張機能です。この機能の目的は、通常ポー"
"トを使った既存のインスタンス用に FDB テーブルを更新することです。これによ"
"り、 SR-IOV インスタンスと通常のインスタンス間での通信が可能になります。 FDB "
"population 拡張機能には、以下のようなユースケースがあります。"

msgid ""
"From the Liberty release onwards, OpenStack Networking supports IPv6 prefix "
"delegation. This section describes the configuration and workflow steps "
"necessary to use IPv6 prefix delegation to provide automatic allocation of "
"subnet CIDRs. This allows you as the OpenStack administrator to rely on an "
"external (to the OpenStack Networking service) DHCPv6 server to manage your "
"project network prefixes."
msgstr ""
"Liberty リリース以降では、 OpenStack Networking は IPv6 prefix delegation に"
"対応しています。このセクションでは、IPv6 prefix delegation を使って サブネッ"
"トの CIDR の自動的な割り当てを行えるようにするのに必要な設定と利用手順を説明"
"します。これにより、 OpenStack 管理者は (OpenStack Networking サービスの) 外"
"部の DHCPv6 サーバーを使って、プロジェクトのネットワークのプレフィックスの管"
"理を行えるようになります。"

msgid "Function: Firewall"
msgstr "機能: ファイアウォール"

msgid "Function: Intrusion detection system (IDS)"
msgstr "機能: 侵入検知システム (IDS)"

msgid ""
"Fundamentally, SFC routes packets through one or more service functions "
"instead of conventional routing that routes packets using destination IP "
"address. Service functions essentially emulate a series of physical network "
"devices with cables linking them together."
msgstr ""
"基本的には、 SFC は、宛先 IP アドレスを使ってパケットを転送する従来のルーティ"
"ングではなく、パケットを 1 つ以上のサービス機能 (service function) 群を順に通"
"過させます。サービス機能群は、本質的には、互いにケーブルで接続される物理ネッ"
"トワークデバイスのつながりをエミュレートするものです。"

msgid "Future support"
msgstr "今後の予定"

msgid "GRE"
msgstr "GRE"

msgid "GRE and VXLAN"
msgstr "GRE と VXLAN"

msgid "Gateway"
msgstr "ゲートウェイ"

msgid "Gateway on the provider network"
msgstr "プロバイダネットワークのゲートウェイ"

msgid "Generic routing encapsulation (GRE)"
msgstr "Generic routing encapsulation (GRE)"

msgid ""
"Generic routing encapsulation (GRE) is a protocol that runs over IP and is "
"employed when delivery and payload protocols are compatible but payload "
"addresses are incompatible. For instance, a payload might think it is "
"running on a datalink layer but it is actually running over a transport "
"layer using datagram protocol over IP. GRE creates a private point-to-point "
"connection and works by encapsulating a payload. GRE is a foundation "
"protocol for other tunnel protocols but the GRE tunnels provide only weak "
"authentication."
msgstr ""
"GRE (Generic routing encapsulation) は、 IP 上で動作するプロトコルで、プロト"
"コルと転送方式はそのまま使えるがペイロードアドレスがそのままでは利用できない"
"場合に利用されます。例えば、ペイロード自体はデータリンク層で動作しているよう"
"に見えるが、実際には IP 上のデータグラムプロトコルを使った転送レイヤー上で動"
"作しているということです。GRE は 1 対 1 の専用の接続を作成し、ペイロードをカ"
"プセル化します。 GRE は他のトンネルプロトコルの基本となるプロトコルですが、 "
"GRE トンネルには弱い認証機構しかありません。"

msgid "Get Me A Network"
msgstr "Get Me A Network"

msgid "Get Network IP address availability for all IPv4 networks:"
msgstr "全 IPv4 ネットワークの IP アドレス利用状況を取得します。"

msgid "Get Network IP address availability for all IPv6 networks:"
msgstr "全 IPv6 ネットワークの IP アドレス利用状況を取得します。"

msgid "Get Network IP address availability statistics for a specific network:"
msgstr "特定のネットワークの IP アドレス使用状況を取得します。"

msgid "Get list of resources with ``not-tags-any`` filter:"
msgstr "``not-tags-any`` フィルターを使ってリソース一覧を取得します。"

msgid "Get list of resources with ``not-tags`` filter:"
msgstr "``not-tags`` フィルターを使ってリソース一覧を取得します。"

msgid "Get list of resources with ``tags-any`` filter:"
msgstr "``tags-any`` フィルターを使ってリソース一覧を取得します。"

msgid "Get list of resources with ``tags`` filter:"
msgstr "``tags`` フィルターを使ってリソース一覧を取得します。"

msgid ""
"Get list of resources with tag filters from networks. The networks are: test-"
"net1 with \"red\" tag, test-net2 with \"red\" and \"blue\" tags, test-net3 "
"with \"red\", \"blue\", and \"green\" tags, and test-net4 with \"green\" tag."
msgstr ""
"タグフィルターを使ってネットワークの一覧を取得できます。以下の例では、 test-"
"net1 にはタグ \"red\"、 test-net2 にはタグ \"red\" と \"blue\"、 test-net3 に"
"はタグ \"red\", \"blue\", \"green\"、 test-net4 にはタグ \"green\" が付与され"
"ています。"

msgid ""
"Get the ``id`` of the network where you want the SR-IOV port to be created:"
msgstr "SR-IOV ポートを作成したいネットワークの ``id`` を取得します。"

msgid "Glossary"
msgstr "用語集"

msgid ""
"Guest instance obtains IPv6 address from OpenStack managed radvd using SLAAC "
"and optional info from dnsmasq using DHCPv6."
msgstr ""
"ゲストインスタンスは SLAAC を使って OpenStack が管理する radvd から IPv6 アド"
"レスを取得し、DHCPv6 を使って dnsmasq から追加情報を取得します。"

msgid ""
"Guest instance obtains IPv6 address from OpenStack managed radvd using SLAAC."
msgstr ""
"ゲストインスタンスは SLAAC を使って OpenStack が管理する radvd から IPv6 アド"
"レスを取得します。"

msgid ""
"Guest instance obtains IPv6 address from dnsmasq using DHCPv6 stateful and "
"optional info from dnsmasq using DHCPv6."
msgstr ""
"ゲストインスタンスは DHCPv6 stateful を使って dnsmasq から IPv6 アドレスを取"
"得し、DHCPv6 を使って dnsmasq から追加情報を取得します。"

msgid ""
"Guest instance obtains IPv6 address from non-OpenStack router using SLAAC."
msgstr ""
"ゲストインスタンスは SLAAC を使って OpenStack 外のルーターから IPv6 アドレス"
"を取得します。"

msgid "HA of DHCP agents"
msgstr "DHCP エージェントの HA"

msgid ""
"HA routers are created on availability zones you selected when creating the "
"router."
msgstr ""
"HA ルーターは、ルーター作成時に指定したアベイラビリティーゾーンに作成されま"
"す。"

msgid "Handles metadata, etc."
msgstr "メタデータを処理する、など"

msgid "Handles physical-virtual network transition"
msgstr "物理〜仮想ネットワーク間の変換を扱う"

msgid "Health monitor"
msgstr "ヘルスモニター"

msgid "Here is an example of output from :command:`ip route show`:"
msgstr ":command:`ip route show` の出力例を以下に示します。"

msgid "Here is the router we have used in our demonstration:"
msgstr "今回のデモでは以下のルーターを使用します。"

msgid "High availability"
msgstr "高可用性"

msgid "High-availability for DHCP"
msgstr "DHCP の高可用性"

msgid ""
"Historically, Open vSwitch (OVS) could not interact directly with *iptables* "
"to implement security groups. Thus, the OVS agent and Compute service use a "
"Linux bridge between each instance (VM) and the OVS integration bridge ``br-"
"int`` to implement security groups. The Linux bridge device contains the "
"*iptables* rules pertaining to the instance. In general, additional "
"components between instances and physical network infrastructure cause "
"scalability and performance problems. To alleviate such problems, the OVS "
"agent includes an optional firewall driver that natively implements security "
"groups as flows in OVS rather than Linux bridge and *iptables*, thus "
"increasing scalability and performance."
msgstr ""
"歴史的に、 Open vSwitch (OVS) は、セキュリティーグループの実装にあたり "
"*iptables* と直接やり取りすることができませんでした。そのため、 OVS エージェ"
"ントと Compute サービスでは、各インスタンス (VM) と OVS 統合ブリッジ ``br-"
"int`` の間に Linux ブリッジを置いて、セキュリティーグループを実装しています。"
"その Linux ブリッジデバイスに、インスタンス用の *iptables* ルールが保持されま"
"す。一般的には、インスタンスと物理ネットワーク基盤の間に追加のコンポーネント"
"が置かれることで、スケーラビリティや性能面の問題が発生します。この問題を緩和"
"するため、 OVS エージェントには、セキュリティーグループを Linux ブリッジと "
"*iptables* ではなく OVS 上のフローとして直接実装するファイアウォールドライ"
"バーがオプションとして提供されています。これにより、スケーラビリティと性能を"
"向上できます。"

msgid "Host"
msgstr "ホスト"

msgid "Host *A* then sends Ethernet frames to host *B*."
msgstr "それから、ホスト *A* はホスト *B* に Ethernet フレームを送信します。"

msgid "Host *B* responds with a response like this:"
msgstr "ホスト *B* は次のような応答を返します。"

msgid "HostA"
msgstr "HostA"

msgid "HostB"
msgstr "HostB"

msgid ""
"Hosts connected to a network use the :term:`Dynamic Host Configuration "
"Protocol (DHCP)` to dynamically obtain IP addresses. A DHCP server hands out "
"the IP addresses to network hosts, which are the DHCP clients."
msgstr ""
"ネットワークに接続されたホストは、 :term:`Dynamic Host Configuration "
"Protocol (DHCP)` を使って、動的に IP アドレスを取得します。 DHCP サーバー"
"は、 IP アドレスを DHCP クライアントとなるネットワークホストに払い出します。"

msgid "How the 'shared' flag relates to these entries"
msgstr "'shared' フラグとポリシーエントリーの関係"

msgid "How they work"
msgstr "どのように動作するか？"

msgid ""
"How those instances communicate across a router to other subnets or the "
"internet."
msgstr ""
"これらのインスタンスがルーター越しに他のサブネットやインターネットとどのよう"
"に通信するか"

msgid "How those instances interact with other OpenStack services."
msgstr ""
"これらのインスタンスが他の OpenStack サービスとどうやってやり取りを行うか"

msgid "How those instances receive an IPv6 address."
msgstr "これらのインスタンスは IPv6 アドレスをどのように取得するか"

msgid "How to disable libvirt networks"
msgstr "libvirt ネットワークを無効にする方法"

msgid "How to enable dual-stack (IPv4 and IPv6 enabled) instances."
msgstr ""
"デュアルスタックの (IPv4 と IPv6 の両方が有効になった) インスタンスを使用する"
"にはどうすればよいか"

msgid ""
"However, libvirt is capable of providing networking services to the virtual "
"machines that it manages. In particular, libvirt can be configured to "
"provide networking functionality akin to a simplified, single-node version "
"of OpenStack. Users can use libvirt to create layer 2 networks that are "
"similar to OpenStack Networking's networks, confined to a single node."
msgstr ""
"しかしながら、 libvirt は、自身が管理する仮想マシンに対してネットワークサービ"
"スを提供することはできます。もう少し具体的に言うと、 libvirt は、簡単な 1 台"
"構成の OpenStack に似たネットワーク機能を提供するように設定することができま"
"す。 1 台構成に限ると、ユーザーは libvirt を使って OpenStack Networking の"
"ネットワークと同様のレイヤー 2 ネットワークを作成できます。"

msgid ""
"However, load balancers deployed onto private or isolated networks need a "
"floating IP address assigned if they must be accessible to external clients. "
"To complete this step, you must have a router between the private and public "
"networks and an available floating IP address."
msgstr ""
"一方、ロードバランサーが分離されたプライベートネットワーク上に配備される場合"
"は、外部のクライアントからアクセスできるようにするには Floating IP アドレスを"
"割り当てる必要があります。 Floating IP アドレスを割り当てるためには、プライ"
"ベートネットワークとパブリックネットワークを接続するルーターと、利用可能な "
"Floating IP アドレスが必要です。"

msgid "IP"
msgstr "IP"

msgid "IP addresses 203.0.113.1 and fd00:203:0:113:0::1"
msgstr "IPアドレス203.0.113.1とfd00:203:0:113:0::1"

msgid ""
"IP addresses are broken up into two parts: a *network number* and a *host "
"identifier*. Two hosts are on the same *subnet* if they have the same "
"network number. Recall that two hosts can only communicate directly over "
"Ethernet if they are on the same local network. ARP assumes that all "
"machines that are in the same subnet are on the same local network. Network "
"administrators must take care when assigning IP addresses and netmasks to "
"hosts so that any two hosts that are in the same subnet are on the same "
"local network, otherwise ARP does not work properly."
msgstr ""
"IP アドレスは *ネットワーク番号* と *ホスト識別子* の 2 つの部分に分解できま"
"す。 2 つのホストが同じネットワーク番号を持つ場合、両者は同じ *サブネット* に"
"あります。 2 つのホストが同じローカルネットワーク上にある場合、両者が通信する"
"手段は直接 Ethernet 経由しかないことを思い出してください。 ARP は同じサブネッ"
"トのすべてのマシンが同じローカルネットワーク上にあると仮定します。ネットワー"
"ク管理者は IP アドレスとネットマスクをホストに割り当てる際に、同じサブネット"
"に属する任意の 2 つのホストが同じローカルネットワーク上にあるように気を付ける"
"必要があります。さもなければ ARP は正しく動作しません。"

msgid "IP availability metrics"
msgstr "IP 利用状況"

msgid "IPAM configuration"
msgstr "IPAM 設定"

msgid "IPv6"
msgstr "IPv6"

msgid "IPv6 addressing"
msgstr "IPv6 アドレス割り当て"

msgid ""
"IPv6 does work when the Distributed Virtual Router functionality is enabled, "
"but all ingress/egress traffic is via the centralized router (hence, not "
"distributed). More work is required to fully enable this functionality."
msgstr ""
"分散仮想ルーター (DVR) 機能が有効の場合も IPv6 は動きますが、すべての入力方"
"向、出力方向のトラフィックが centralized router を経由します (つまり、分散で"
"はありません)。IPv6 が DVR が完全に動作するようになるには、まだ開発が必要で"
"す。"

msgid "IPv6 multicast"
msgstr "IPv6 マルチキャスト"

msgid "IPv6 since OpenStack Networking has no IPv6 floating IPs."
msgstr ""
"OpenStack Networking の IPv6 では IPv6 Floating IP はサポートされていません。"

msgid ""
"IPv6 support in conjunction with any out of tree routers, switches, services "
"or agents whether in physical or virtual form factors."
msgstr ""
"物理仮想を問わず、Neutron コードツリー外のルーター、スイッチ、サービス、エー"
"ジェントとの組み合わせでの IPv6 サポート"

msgid ""
"IPv6 supports three different addressing schemes for address configuration "
"and for providing optional network information."
msgstr ""
"IPv6 では、アドレス設定と追加のネットワーク情報の提供方法に関して、 3 つの異"
"なるアドレス割り当て方法がサポートされています。"

msgid ""
"If Dashboard is configured to compress static files for better performance "
"(usually set through ``COMPRESS_OFFLINE`` in ``local_settings.py``), "
"optimize the static files again:"
msgstr ""
"性能向上のため、ダッシュボードが静的ファイルを圧縮するように設定されている場"
"合 (通常は ``local_settings.py`` の ``COMPRESS_OFFLIME`` により設定されま"
"す)、静的ファイルの最適化をもう一度行います。"

msgid ""
"If ``ebrctl`` does not appear in any of the rootwrap files, add this to the "
"``/etc/nova/rootwrap.d/compute.filters`` file in the ``[Filters]`` section."
msgstr ""
"``ebrctl`` が rootwrap ファイルのいずれにも含まれていない場合、 ``/etc/nova/"
"rootwrap.d/compute.filters`` ファイルの ``[filters]`` セクションに以下を追加"
"してください。"

msgid ""
"If a network is marked as external during creation, it now implicitly "
"creates a wildcard RBAC policy granting everyone access to preserve previous "
"behavior before this feature was added."
msgstr ""
"ネットワーク作成時に external (外部ネットワーク) フラグが指定された場合は、全"
"員にアクセスを許可するワイルドカードの RBAC ポリシーが作成され、本機能が追加"
"される前の動作は保持されます。"

msgid ""
"If a service function involves a pair of ports, the first port acts as the "
"ingress port of the service function and the second port acts as the egress "
"port. If both ports use the same value, they function as a single virtual "
"bidirectional port."
msgstr ""
"サービス機能がポートペアを持つ場合、最初のポートはサービス機能の入力ポートと"
"して機能し、 2 つ目のポートは出力ポートとして機能します。両方のポートが同じ値"
"の場合、これららは 1 つの双方向の仮想ポートとして動作します。"

msgid ""
"If an operator wants to prevent normal users from doing this, the ``"
"\"create_rbac_policy\":`` entry in ``policy.json`` can be adjusted from ``"
"\"\"`` to ``\"rule:admin_only\"``."
msgstr ""
"運用者が通常ユーザーにこれを許したくない場合は、 ``policy.json`` のエント"
"リー  ``create_rbac_policy`` を ``\"\"`` から ``\"rule:admin_only\"`` に変更"
"します。"

msgid ""
"If installing from source, you must configure a daemon file for the init "
"system manually."
msgstr ""
"ソースコードからインストールした場合には、 init システム用のデーモンファイル"
"を手動で設定する必要があります。"

msgid "If necessary, :ref:`configure MTU <config-mtu>`."
msgstr "必要であれば :ref:`MTU を設定します。 <config-mtu>`"

msgid ""
"If that project has ports on the network, the server will prevent the policy "
"from being deleted until the ports have been deleted:"
msgstr ""
"そのプロジェクトのポートが対象のネットワークにある場合は、そのポートが削除さ"
"れるまでポリシーを削除することはできません。"

msgid ""
"If that project has ports or networks with the QoS policy applied to them, "
"the server will not delete the RBAC policy until the QoS policy is no longer "
"in use:"
msgstr ""
"このプロジェクトにその QoS ポリシーが適用されたネットワークのポートがある場合"
"は、その QoS ポリシーが使われなくなるまで RBAC ポリシーの削除は行われません。"

msgid ""
"If that project has router gateway ports attached to that network, the "
"server prevents the policy from being deleted until the ports have been "
"deleted:"
msgstr ""
"そのプロジェクトのルーターのゲートウェイポートが対象のネットワークにある場合"
"は、そのポートが削除されるまでポリシーを削除することはできません。"

msgid ""
"If the DVR/SNAT backup router stops receiving these packets, it assumes "
"failure of the master DVR/SNAT router and promotes itself to master router "
"by configuring IP addresses on the interfaces in the ``snat`` namespace. In "
"environments with more than one backup router, the rules of VRRP are "
"followed to select a new master router."
msgstr ""
"バックアップの DVR/SNAT ルーターがこれらのパケットを受信しなくなると、バック"
"アップのルーターはマスターの DVR/SNAT ルーターの障害とみなし、 自身をマスター"
"ルーターに昇格させ、 ``snat`` 名前空間のインターフェースに IP アドレスを設定"
"します。バックアップルーターが複数ある環境では、 VRRP のルールに基いて新しい"
"マスタールーターが選択されます。"

msgid ""
"If the Open vSwitch agent is being used, set ``extensions`` to ``qos`` in "
"the ``[agent]`` section of ``/etc/neutron/plugins/ml2/openvswitch_agent."
"ini``. For example:"
msgstr ""
"Open vSwitch エージェントを使用している場合、 ``/etc/neutron/plugins/ml2/"
"openvswitch_agent.ini`` の ``[agent]`` セクションで ``extensions`` に "
"``qos`` を設定します。"

msgid ""
"If the OpenStack DNS service is the target external DNS, the ``[designate]`` "
"section of ``/etc/neutron/neutron.conf`` must define the following "
"parameters:"
msgstr ""
"OpenStack DNS サービスが対象の外部 DNS の場合、 ``/etc/neutron/neutron."
"conf`` の ``[designate]`` セクションで以下のパラメーターを定義する必要があり"
"ます。"

msgid ""
"If the address scopes match between networks then pings and other traffic "
"route directly through. If the scopes do not match between networks, the "
"router either drops the traffic or applies NAT to cross scope boundaries."
msgstr ""
"ネットワーク間でアドレススコープが一致する場合、 ping (やその他のトラフィッ"
"ク) はルーターでそのまま転送されます。ネットワーク間でアドレススコープが一致"
"しない場合、ルーターはそのトラフィックを破棄するか、スコープ境界をまたぐため "
"NAT を行います。"

msgid ""
"If the device defined by the PCI address or ``devname`` corresponds to an SR-"
"IOV PF, all VFs under the PF will match the entry. Multiple "
"``pci_passthrough_whitelist`` entries per host are supported."
msgstr ""
"PCI アドレスや ``devname`` で定義されたデバイスが SR-IOV PF に対応している場"
"合、その PF 配下のすべての VF がこのエントリーにマッチします。 1 つのホストで"
"複数の ``pci_passthrough_whitelist`` を設定することもできます。"

msgid ""
"If the interfaces are down, set them to ``up`` before launching a guest, "
"otherwise the instance will fail to spawn:"
msgstr ""
"インターフェースが ``down`` の場合は、ゲストを起動する前にインターフェースを "
"``up`` に設定してください。 ``up`` になっていない場合は、インスタンスの起動に"
"失敗します。"

msgid "If the pool becomes exhausted, load some more prefixes:"
msgstr "プールを使い切った場合は、プレフィックスを追加します。"

msgid ""
"If the prefix delegation server is configured to delegate globally routable "
"prefixes and setup routes, then any instance with a port on this subnet "
"should now have external network access."
msgstr ""
"prefix delegation サーバーがグローバルに到達可能なプレフィックスを移譲して経"
"路を設定するように設定されている場合には、このサブネット上のポートを持つイン"
"スタンスはこの時点で外部ネットワークにアクセスできるようになります。"

msgid ""
"If two switches are to be connected together, and the switches are "
"configured for VLANs, then the switchports used for cross-connecting the "
"switches must be configured to allow Ethernet frames from any VLAN to be "
"forwarded to the other switch. In addition, the sending switch must tag each "
"Ethernet frame with the VLAN ID so that the receiving switch can ensure that "
"only hosts on the matching VLAN are eligible to receive the frame."
msgstr ""
"2 台のスイッチは互いに接続されていて、両方のスイッチで VLAN が設定されている"
"場合、スイッチ間の相互接続に使用されるスイッチポートは、どの VLAN からの "
"Ethernet フレームももう一方のスイッチに転送できなければいけません。さらに、受"
"信側のスイッチが VLAN に対応するホストだけがそのフレームを受信できることを保"
"証できるように、送信側のスイッチは Ethernet フレームに VLAN ID のタグを付けな"
"ければいけません。"

msgid ""
"If you are an admin, you can create a pool which can be accessed by any "
"regular project. Being a shared resource, there is a quota mechanism to "
"arbitrate access."
msgstr ""
"管理者の場合、任意の通常プロジェクトが利用可能なプールを作成できます。共有リ"
"ソースの場合には、クォータ機構を使って利用を調停します。"

msgid ""
"If you are not using the default dibbler-based driver for prefix delegation, "
"then you also need to set the driver in ``/etc/neutron/neutron.conf``:"
msgstr ""
"prefix delegation 用としてデフォルトの dibbler ベースのドライバーを使っていな"
"い場合は、 ``/etc/neutron/neutron.conf`` でドライバーの設定も必要です。"

msgid ""
"If you have access to an OpenStack Kilo or later based neutron, you can play "
"with this feature now. Give it a try. All of the following commands work "
"equally as well with IPv6 addresses."
msgstr ""
"Kilo 以降の Neutron を使った OpenStack を使用できるのであれば、この機能をすぐ"
"に使うことができます。やってみましょう。以下のコマンドはすべて IPv6 アドレス"
"でも同じように動きます。"

msgid ""
"If you have deployed LBaaS v1, **stop the LBaaS v1 agent now**. The v1 and "
"v2 agents **cannot** run simultaneously."
msgstr ""
"LBaaS v1 をデプロイしていた場合には、 **LBaaS v1 エージェントをこの時点で停止"
"してください。** v1 と v2 のエージェントは同時には実行 **できません。**"

msgid ""
"If you have existing service providers for other networking service plug-"
"ins, such as VPNaaS or FWaaS, add the ``service_provider`` line shown above "
"in the ``[service_providers]`` section as a separate line. These "
"configuration directives are repeatable and are not comma-separated."
msgstr ""
"VPNaaS や FWaaS などの他のネットワークサービスプラグイン用のサービスプロバイ"
"ダーをすでに設定している場合には、 ``service_provider`` 行を上記の "
"``[service_provider]`` セクションに新しい行として追加します。この設定項目は繰"
"り返し指定することができ、コンマ区切りではありません。"

msgid "Impact and limitations"
msgstr "影響と制限事項"

msgid ""
"In *Destination Network Address Translation* (DNAT), the NAT router modifies "
"the IP address of the destination in IP packet headers."
msgstr ""
"*宛先ネットワークアドレス変換* (DNAT) では、NAT ルーターは IP パケットヘッ"
"ダーの宛先 IP アドレスを変更します。"

msgid ""
"In *Source Network Address Translation* (SNAT), the NAT router modifies the "
"IP address of the sender in IP packets. SNAT is commonly used to enable "
"hosts with *private addresses* to communicate with servers on the public "
"Internet."
msgstr ""
"*送信元ネットワークアドレス変換* (SNAT) では、NAT ルーターは IP パケットヘッ"
"ダーの送信元 IP アドレスを変更します。 SNAT は *プライベートアドレス* のホス"
"トをパブリックインターネット上のサーバーと通信できるようにするのに広く使われ"
"ます。"

msgid ""
"In *one-to-one NAT*, the NAT router maintains a one-to-one mapping between "
"private IP addresses and public IP addresses. OpenStack uses one-to-one NAT "
"to implement floating IP addresses."
msgstr ""
"*one-to-one NAT* では、 NAT ルーターはプライベート IP アドレスとパブリック "
"IP アドレスの 1 対 1 のマッピングを管理します。 OpenStack は one-to-one NAT "
"を使って Floating IP アドレスを実装しています。"

msgid ""
"In :ref:`config-dns-use-case-1`, the externally accessible network must meet "
"the following requirements:"
msgstr ""
":ref:`config-dns-use-case-1` では、外部からアクセス可能なネットワークは以下の"
"要件を満たす必要があります。"

msgid ""
"In Liberty and Mitaka, the IPAM implementation within OpenStack Networking "
"provided a pluggable and non-pluggable flavor. As of Newton, the non-"
"pluggable flavor is no longer available. Instead, it is completely replaced "
"with a reference driver implementation of the pluggable framework. All data "
"will be automatically migrated during the upgrade process, unless you have "
"previously configured a pluggable IPAM driver. In that case, no migration is "
"necessary."
msgstr ""
"Liberty と Mitaka リリースでは、 OpenStack Networking の IPAM 実装としては、"
"取り換え対応の IPAM と組み込みの IPAM が提供されていました。 Newton リリース"
"では、組み込みの IPAM は利用できなくなりました。代わりに、取り換え対応のフ"
"レームワークの参照実装ドライバーが使われるようになりました。アップグレード手"
"順の中ですべてのデータが自動的に移行されます。なお、取り換え対応の IPAM ドラ"
"イバーをすでに使用していた場合は、移行処理は不要です。"

msgid ""
"In ``/etc/neutron/plugins/ml2/ml2_conf.ini``, add ``qos`` to "
"``extension_drivers`` in the ``[ml2]`` section. For example:"
msgstr ""
"``/etc/neutron/plugins/ml2/ml2_conf.ini`` で、 ``[ml2]`` セクションの "
"``extension_drivers`` に ``qos`` を追加します。例:"

msgid ""
"In a network namespace, the scoped 'identifiers' are network devices; so a "
"given network device, such as ``eth0``, exists in a particular namespace. "
"Linux starts up with a default network namespace, so if your operating "
"system does not do anything special, that is where all the network devices "
"will be located. But it is also possible to create further non-default "
"namespaces, and create new devices in those namespaces, or to move an "
"existing device from one namespace to another."
msgstr ""
"ネットワーク名前空間の場合、範囲が限定される 'ID' (識別子) はネットワークデバ"
"イスになります。名前空間には、 ``eth0`` のようなネットワークデバイスが存在し"
"ます。 Linux はデフォルトネットワーク名前空間で開始し、オペレーティングシステ"
"ムが何か特別なことをしない限り、すべてのネットワークデバイスはデフォルトネッ"
"トワーク名前空間にロードされます。しかし、デフォルト以外の名前空間をさらに作"
"成することができ、その名前空間内に新しいデバイスを作成したり、ある名前空間に"
"すでに存在するデバイスを別の名前空間に移動できます。"

msgid ""
"In an Ethernet network, every host on the network can send a frame directly "
"to every other host. An Ethernet network also supports broadcasts so that "
"one host can send a frame to every host on the network by sending to the "
"special MAC address ``ff:ff:ff:ff:ff:ff``. ARP_ and DHCP_ are two notable "
"protocols that use Ethernet broadcasts. Because Ethernet networks support "
"broadcasts, you will sometimes hear an Ethernet network referred to as a "
"*broadcast domain*."
msgstr ""
"Ethernet ネットワークでは、ネットワーク上のどのホストも他のどのホストにも直接"
"フレームを送信できます。 Ethernet ネットワークはブロードキャストもサポートし"
"ており、特別な MAC アドレス``ff:ff:ff:ff:ff:ff`` に送信することで、 あるホス"
"トが 1 つのフレームでネットワーク上のすべてのホストに送信ができます。 "
"Ethernet のブロードキャストを使う有名なプロトコルが 2 つあり、 ARP_ と DHCP_ "
"です。 Ethernet ネットワークはブロードキャストをサポートしているため、 "
"Ethernet ネットワークは *ブロードキャストドメイン* と呼ばれることもあります。"

msgid ""
"In an Ethernet network, the hosts connected to the network communicate by "
"exchanging *frames*. Every host on an Ethernet network is uniquely "
"identified by an address called the media access control (MAC) address. In "
"particular, every virtual machine instance in an OpenStack environment has a "
"unique MAC address, which is different from the MAC address of the compute "
"host. A MAC address has 48 bits and is typically represented as a "
"hexadecimal string, such as ``08:00:27:b9:88:74``. The MAC address is hard-"
"coded into the NIC by the manufacturer, although modern NICs allow you to "
"change the MAC address programmatically. In Linux, you can retrieve the MAC "
"address of a NIC using the :command:`ip` command:"
msgstr ""
"Ethernet ネットワークでは、ネットワークに接続されたホストは *フレーム* をやり"
"取りして通信します。 Ethernet ネットワーク上の各ホストは、MAC (media access "
"control; メディアアクセス制御) アドレスと呼ばれるアドレスにより一意に識別され"
"ます。特に、 OpenStack 環境では、各仮想マシンインスタンスは一意な MAC アドレ"
"スを持ち、その MAC アドレスはコンピュートホストの MAC アドレスとも異なりま"
"す。 MAC アドレスは 48 ビットで、通常は ``08:00:27:b9:88:74`` のような 16 進"
"数で表現されます。 MAC アドレスは製造ベンダーにより NIC に書き込まれています"
"が、最近の NIC は MAC アドレスをプログラムして書き換えることもできます。 "
"Linux では :command:`ip` コマンドを使って NIC の MAC アドレスを取得できます。"

msgid ""
"In both cases, install and configure Open vSwitch with DPDK support for each "
"node. For more information, see the `OVS-DPDK <https://github.com/"
"openvswitch/ovs/blob/v2.5.0/INSTALL.DPDK.md>`__ installation guide."
msgstr ""
"どちらの場合も、各ノードで DPDK 対応の Open vSwitch をインストールと設定を行"
"う必要があります。詳細な情報は、 `OVS-DPDK <https://github.com/openvswitch/"
"ovs/blob/v2.5.0/INSTALL.DPDK.md>`__ インストールガイドを参照してください。"

msgid ""
"In deployments using DVR, the BGP speaker advertises floating IP addresses "
"and self-service networks differently. For floating IP addresses, the BGP "
"speaker advertises the floating IP agent gateway on the corresponding "
"compute node as the next-hop IP address. For self-service networks using "
"SNAT, the BGP speaker advertises the DVR SNAT node as the next-hop IP "
"address."
msgstr ""
"DVR を使ったデプロイメントでは、 BGP スピーカーは Floating IP アドレスとセル"
"フサービスネットワークを異なる方法で広告します。 Floating IP アドレスの場合"
"は、 BGP スピーカーは対応するコンピュートノードの Floating IP エージェント"
"ゲートウェイをネクストホップの IP アドレスとして広告します。 SNAT を使ったセ"
"ルフサービスネットワークの場合は、 BGP スピーカーは DVR SNAT ノードをネクスト"
"ホップの IP アドレスとして広告します。"

msgid ""
"In existing deployments, check the current database version using the "
"following command:"
msgstr ""
"既存のデプロイメントでは、以下のコマンドを使って現在のデータベースのバージョ"
"ンを確認します。"

msgid ""
"In general, the OpenStack Networking software components that handle layer-3 "
"operations impact performance and reliability the most. To improve "
"performance and reliability, provider networks move layer-3 operations to "
"the physical network infrastructure."
msgstr ""
"一般には、 レイヤー 3 操作を行う OpenStack Networking のソフトウェアコンポー"
"ネントは、最も性能と信頼性に影響を与えるコンポーネントです。性能と信頼性を向"
"上させるため、プロバイダーネットワークでは、レイヤー 3 操作を物理ネットワーク"
"基盤に移しています。"

msgid ""
"In new deployments, you start with an empty database and then upgrade to the "
"latest database version using the following command:"
msgstr ""
"新規のデプロイメントでは、空のデータベースから始め、以下のコマンドを使って最"
"新のデータベースバージョンまでアップグレードします。"

msgid ""
"In one particular use case, the OpenStack deployment resides in a mixed "
"environment with conventional virtualization and bare-metal hosts that use a "
"sizable physical network infrastructure. Applications that run inside the "
"OpenStack deployment might require direct layer-2 access, typically using "
"VLANs, to applications outside of the deployment."
msgstr ""
"ある特定のユースケースでは、従来の仮想化とベアメタルホストが混在する、かなり"
"大きな物理ネットワーク基盤を使った環境に、 OpenStack 環境があります。 "
"OpenStack 環境内で動作するアプリケーションが OpenStack 環境外のアプリケーショ"
"ンに直接レイヤー 2 (通常は VLAN を使用) でのアクセスが必要な場合があります。"

msgid ""
"In order to attach a QoS policy to a network, update an existing network, or "
"initially create the network attached to the policy."
msgstr ""
"ネットワークに QoS ポリシーを付与するには、既存のネットワークを更新するか、ポ"
"リシーを付与してネットワークを作成します。"

msgid ""
"In order to detach a port from the QoS policy, simply update again the port "
"configuration."
msgstr ""
"ポートから QoS ポリシーの関連付けを解除するには、ポート設定をもう一度更新する"
"だけです。"

msgid "In order to enable SR-IOV, the following steps are required:"
msgstr "SR-IOV を有効にするには、以下の手順を行う必要があります。"

msgid ""
"In order to support a wide range of deployment options, the migration "
"process described here requires a rolling restart of hypervisors. The rate "
"and timing of specific hypervisor restarts is under the control of the "
"operator."
msgstr ""
"幅広いデプロイメントの選択肢に対応するため、ここで説明する移行手順では、ハイ"
"パーバイザーを順に再起動 (rolling restart) していく必要があります。個々のハイ"
"パーバイザーの再起動をどのくらいの早さで、いつ行っていくかについては、オペ"
"レーターが制御できます。"

msgid ""
"In order to support the widest range of deployer needs, the process "
"described here is easy to automate but is not already automated. Deployers "
"should expect to perform multiple manual steps or write some simple scripts "
"in order to perform this migration."
msgstr ""
"様々なデプロイメントでの需要に対応するため、ここで説明する手順は、簡単に自動"
"化できますが、まだ自動化はされていません。オペレーターは、この移行手順を実行"
"するのに、手動作業をいくつか実行したり、簡単なスクリプトを書く必要があること"
"でしょう。"

msgid ""
"In the OSI model of networking protocols IP occupies the third layer, known "
"as the network layer. When discussing IP, you will often hear terms such as "
"*layer 3*, *L3*, and *network layer*."
msgstr ""
"IP は、ネットワークプロトコルの OSI モデルの第 3 層にあたり、ネットワーク層と"
"も呼ばれます。 IP の話をすると、 *レイヤー 3*、 *L3*、*ネットワーク層* といっ"
"た用語をしばしば聞くことでしょう。"

msgid ""
"In the `OSI model <https://en.wikipedia.org/wiki/OSI_model>`_ of networking "
"protocols, Ethernet occupies the second layer, which is known as the data "
"link layer. When discussing Ethernet, you will often hear terms such as "
"*local network*, *layer 2*, *L2*, *link layer* and *data link layer*."
msgstr ""
"Ethernet は、ネットワークプロトコルの `OSI model  <https://en.wikipedia.org/"
"wiki/OSI_model>`_ の第 2 層にあたり、データリンク層とも呼ばれます。 Ethernet "
"の話をすると、 *ローカルネットワーク*、*レイヤー 2*、 *L2*、*リンクレイヤー"
"*、 *データリンク層* といった用語をしばしば聞くことでしょう。"

msgid "In the ``bgp_dragent.ini`` file:"
msgstr "``bgp_dragent.ini`` ファイル:"

msgid ""
"In the ``dhcp_agent.ini`` file, configure one or more DNS resolvers. To "
"configure more than one DNS resolver, use a comma between each value."
msgstr ""
"``dhcp_agent.ini`` ファイルで、 DNS レゾルバーを設定します。複数の DNS レゾル"
"バーを設定する場合は、コンマを使って値を区切ります。"

msgid "In the ``dhcp_agent.ini`` file, configure the DHCP agent:"
msgstr "``dhcp_agent.ini`` ファイルで DHCP エージェントを設定します。"

msgid ""
"In the ``dhcp_agent.ini`` file, enable advertisement of the DNS resolver(s) "
"on the host."
msgstr ""
"``dhcp_agent.ini`` ファイルで、ホストの DNS レゾルバーを広告するようにしま"
"す。"

msgid ""
"In the ``linuxbridge_agent.ini`` file, configure the Linux bridge agent:"
msgstr ""
"``linuxbridge_agent.ini`` ファイルで Linux ブリッジエージェントを設定します。"

msgid "In the ``metadata_agent.ini`` file, configure the metadata agent:"
msgstr "``metadata_agent.ini`` ファイルでメタデータエージェントを設定します。"

msgid "In the ``ml2_conf.ini`` file:"
msgstr "``ml2_conf.ini`` ファイル:"

msgid ""
"In the ``neutron.conf`` file, enable the conventional layer-3 and BGP "
"dynamic routing service plug-ins:"
msgstr ""
"``neutron.conf`` ファイルで、従来のレイヤー 3 サービスプラグインと BGP 動的"
"ルーティングサービスプラグインを有効にします。"

msgid "In the ``neutron.conf`` file:"
msgstr "``neutron.conf`` ファイル:"

msgid "In the ``openvswitch_agent.ini`` file:"
msgstr "``openvswitch_agent.ini`` ファイル:"

msgid ""
"In the above configuration, we use ``dhcp_agents_per_network = 1`` for this "
"demonstration. In usual deployments, we suggest setting "
"``dhcp_agents_per_network`` to more than one to match the number of DHCP "
"agents in your deployment. See :ref:`conf-dhcp-agents-per-network`."
msgstr ""
"上記の設定では、デモ用に ``dhcp_agents_per_network = 1`` を使用しています。通"
"常の環境では、 ``dhcp_agents_per_network`` をお使いの環境の DHCP エージェント"
"数に合うように複数に設定することをお薦めします。 :ref:`conf-dhcp-agents-per-"
"network` を参照してください。"

msgid "In the above example notice that:"
msgstr "上記の例では、以下の点に注意してください。"

msgid ""
"In the absence of an upstream RA support, ``ipv6_gateway`` flag can be set "
"with the external router gateway LLA in the neutron L3 agent configuration "
"file. This also requires that no subnet is associated with that port."
msgstr ""
"上流ルーターが RA をサポートしていない場合、 neutron L3 エージェントの設定"
"ファイルの ``ipv6_gateway`` フラグで外部ルーターのゲートウェイ LLA を設定でき"
"ます。"

msgid ""
"In the most simple case, the property can be represented by a simple Python "
"list defined on the class."
msgstr ""
"最も簡単な場合では、プロパティーはクラス内で単純な Python リストで定義されて"
"います。"

msgid ""
"In this case, the DHCP agent offers one or more unique DNS resolvers to "
"instances via DHCP on each virtual network. You can configure a DNS resolver "
"when creating or updating a subnet. To configure more than one DNS resolver, "
"use a comma between each value."
msgstr ""
"この場合、 DHCP エージェントは、 1 つ以上の独自の DNS レゾルバーを、 各仮想"
"ネットワークのインスタンスに DHCP 経由で提供します。サブネットの作成時または"
"更新時に、 DNS レゾルバーを設定できます。 DNS レゾルバーを複数設定する場合"
"は、コンマを使って値を区切ります。"

msgid ""
"In this case, the DHCP agent offers the DNS resolver(s) in the ``resolv."
"conf`` file on the host running the DHCP agent via DHCP to instances on all "
"virtual networks."
msgstr ""
"この場合、 DHCP エージェントは、 DHCP エージェントが動作しているホストの "
"``resolv.conf`` ファイルに書かれた DNS レゾルバーを、 DHCP 経由ですべての仮想"
"ネットワークのインスタンスに提供します。"

msgid ""
"In this case, the DHCP agent offers the same DNS resolver(s) to instances "
"via DHCP on all virtual networks."
msgstr ""
"この場合、 DHCP エージェントは、同じ DNS レゾルバーを、すべての仮想ネットワー"
"クのインスタンスに DHCP 経由で提供します。"

msgid ""
"In this case, the user is creating ports or booting instances on a network "
"that is accessible externally. The steps to publish the port in the external "
"DNS service are the following:"
msgstr ""
"このユースケースでは、ユーザーは外部からアクセス可能なネットワーク上にポート"
"を作成したりインスタンスを起動したりします。外部 DNS サービスにポートを公開す"
"る手順は以下の通りです。"

msgid ""
"In this case, we should let the Networking service find these networks. "
"Obviously, there are no such networks and the service will return an empty "
"list."
msgstr ""
"この場合、 Networking サービスにこのようなネットワークを検索させることになり"
"ます。明らかに、このようなネットワークは存在しないので、空のリストが返されま"
"す。"

msgid ""
"In this example the port is created manually by the user and then used to "
"boot an instance. Notice that:"
msgstr ""
"この例では、ポートはユーザーが手動で作成し、インスタンス起動時に使用されてい"
"ます。以下の点に注意してください。"

msgid ""
"In this example, notice that the data is published in the DNS service when "
"the floating IP is associated to the port."
msgstr ""
"この例では、 Floating IP がポートに関連付けられた際にデータが DNS サービスで"
"公開されている点に注目してください。"

msgid ""
"In this example, the health monitor removes the server from the pool if it "
"fails a health check at two five-second intervals. When the server recovers "
"and begins responding to health checks again, it is added to the pool once "
"again."
msgstr ""
"この例では、ヘルスモニターは、 5 秒間隔で 2 回ヘルスチェックに失敗すると、そ"
"のサーバーをプールから削除します。サーバーが復活しヘルスチェックに再び応答し"
"始めると、そのサーバーはプールにもう一度追加されます。"

msgid ""
"In this example, the load balancer uses the round robin algorithm and the "
"traffic alternates between the web servers on the backend."
msgstr ""
"この例では、ロードバランサーはラウンドロビン方式を使用しており、トラフィック"
"はバックエンドのサーバー間に交互に渡されます。"

msgid ""
"In this output, ``heartbeat_timestamp`` is the time on the neutron server. "
"You do not need to synchronize all agents to this time for this extension to "
"run correctly. ``configurations`` describes the static configuration for the "
"agent or run time data. This agent is a DHCP agent and it hosts one network, "
"one subnet, and three ports."
msgstr ""
"この出力で、 ``heartbeat_timestamp`` は neutron サーバーにおける時刻です。こ"
"の拡張機能を正しく動作させるためには、すべてのエージェントが neutron サーバー"
"に時刻が同期できている必要は特にありません。 ``configurations`` には、エー"
"ジェントの静的な設定や実行時のデータが入ります。このエージェントは DHCP エー"
"ジェントで、ネットワークを 1 つ、サブネットを 1 つ、ポートを 3 つ扱っていま"
"す。"

msgid ""
"In this section, the combination of a mechanism driver and an L2 agent is "
"called 'reference implementation'. The following table lists these "
"implementations:"
msgstr ""
"この節では、メカニズムドライバーと L2 エージェントの組み合わせを「参照実装」"
"と呼びます。以下の表はこうした実装の一覧です。"

msgid ""
"In this use case, the address of a floating IP is published in the external "
"DNS service in conjunction with the ``dns_name`` of its associated port and "
"the ``dns_domain`` of the port's network. The steps to execute in this use "
"case are the following:"
msgstr ""
"このユースケースでは、 Floating IP のアドレスが外部 DNS サービスで公開されま"
"す。名前は、関連付けられたポートの ``dns_name`` とポートのネットワークの "
"dns_domain`` を組み合わせたものになります。この手順で実行する手順は以下の通り"
"です。"

msgid ""
"In this use case, the user assigns ``dns_name`` and ``dns_domain`` "
"attributes to a floating IP when it is created. The floating IP data becomes "
"visible in the external DNS service as soon as it is created. The floating "
"IP can be associated with a port on creation or later on. The following "
"example shows a user booting an instance and then creating a floating IP "
"associated to the port allocated for the instance:"
msgstr ""
"このユースケースでは、ユーザーが Floating IP 作成時に Floating IP に "
"``dns_name`` と ``dns_domain`` 属性を割り当てます。 Floating IP のデータは作"
"成直後から外部 DNS サービスで参照可能になります。 Floating IP は作成時にポー"
"トと関連付けることも後で関連付けることもできます。以下の例では、ユーザーがイ"
"ンスタンスを起動し、それからインスタンスに割り当てられたポートを関連付けて "
"Floating IP を作成しています。"

msgid "Input type"
msgstr "入力データ型"

msgid "Install the Dashboard panel plug-in:"
msgstr "ダッシュボードパネルのプラグインをインストールします。"

msgid "Install the SR-IOV agent."
msgstr "SR-IOV エージェントをインストールします。"

msgid "Install the ``ebrctl`` utility on the compute nodes."
msgstr "コンピュートノードに ``ebrctl`` ユーティリティーをインストールします。"

msgid "Instance 1"
msgstr "インスタンス 1"

msgid "Instance 1 resides on compute node 1 and uses provider network 1."
msgstr ""
"インスタンス 1 はコンピュートノード 1 上にあり、プロバイダーネットワーク 1 を"
"使用します。"

msgid "Instance 1 sends a packet to instance 2."
msgstr "インスタンス 1 がインスタンス 2 にパケットを送信します。"

msgid "Instance 2"
msgstr "インスタンス 2"

msgid "Instance 3"
msgstr "インスタンス 3"

msgid "Instance network interfaces (VIFs)"
msgstr "インスタンスのネットワークインターフェース (VIF)"

msgid ""
"Instead of having the Compute service create the port for the instance, the "
"user might have created it and assigned a value to its ``dns_name`` "
"attribute. In this case, the value assigned to the ``dns_name`` attribute "
"must be equal to the value that Compute service will assign to the "
"instance's ``hostname``, in this example ``my-vm``. Otherwise, the instance "
"boot will fail."
msgstr ""
"Compute サービスがインスタンス用のポートを作成する代わりに、ユーザーがポート"
"を作成して ``dns_name`` 属性に値を割り当てることもできます。この場合、 "
"``dns_name`` 属性に割り当てられる値は、 Compute サービスがインスタンスの "
"``hostname`` に割り当て値、この例では ``my-vm`` と等しくなければいけません。"
"さもなければ、インスタンスの起動は失敗します。"

msgid ""
"Integration of the Compute service and the Networking service with an "
"external DNSaaS (DNS-as-a-Service)."
msgstr ""
"外部 DNSaaS (DNS-as-a-Service) との Compute サービスと Networking サービスの"
"連携"

msgid "Integration with an external DNS service"
msgstr "外部 DNS サービスとの連携"

msgid "Intel"
msgstr "Intel"

msgid "Interface on self-service network 1"
msgstr "セルフサービスネットワーク1のインターフェイス"

msgid "Interface on self-service network 2"
msgstr "セルフサービスネットワーク2のインターフェイス"

msgid ""
"Internal router ports, that act as default gateway ports for a network, will "
"share a common port for all IPv6 subnets associated with the network. This "
"implies that there will be an IPv6 internal router interface with multiple "
"IPv6 addresses from each of the IPv6 subnets associated with the network and "
"a separate IPv4 internal router interface for the IPv4 subnet. On the other "
"hand, external router ports are allowed to have a dual-stack configuration "
"with both an IPv4 and an IPv6 address assigned to them."
msgstr ""
"ネットワークのデフォルトゲートウェイポートして動作する内部ルーターポートで"
"は、そのネットワークに関連付けられた IPv6 サブネットすべてで 1 つの共通のポー"
"トが共有されます。つまり、IPv6 内部ルーターインターフェースは複数の IPv6 アド"
"レスを持ち、そのアドレスはそのネットワークに関連付けられた各 IPv6 サブネット"
"から 1 つずつ割り当てられ、それとは別に IPv4 サブネットに対する IPv4 内部ルー"
"ターインターフェースが作成されるということになります。一方、外部ルーターポー"
"トではデュアルスタック設定が可能で、 IPv4 と IPv6 アドレスの両方が割り当てら"
"れます。"

msgid "Introduction"
msgstr "はじめに"

msgid ""
"Irrelevant fields have been trimmed from the output of these commands for "
"brevity."
msgstr ""
"分かりやすくするため、これらのコマンドの出力のうち無関係なフィールドは省略し"
"ています。"

msgid ""
"Is deployed besides an other mechanism driver and L2 agent such as OVS or "
"Linux bridge. It offers instances direct access to the network adapter "
"through a PCI Virtual Function (VF). This gives an instance direct access to "
"hardware capabilities and high performance networking."
msgstr ""
"OVS や Linux ブリッジなどの他のメカニズムドライバーや L2 エージェントと組み合"
"わせて使用します。 PCI Virtual Function (VF) 経由でインスタンスからネットワー"
"クアダプターへの直接アクセスが可能です。インスタンスは、ハードウェア機能を直"
"接利用でき、高性能なネットワークを得られます。"

msgid ""
"It follows that with these two flags set to ``True`` in the configuration "
"file, routers created by all users will default to distributed HA routers "
"(DVR HA)."
msgstr ""
"要するに、設定ファイルでこれら 2 つのフラグを ``True`` に設定すると、すべての"
"ユーザーが作成するルーターがデフォルトで分散 HA ルーター (DVR HA) になるとい"
"うことです。"

msgid "It includes the following components:"
msgstr "以下のコンポーネントがあります。"

msgid ""
"It is allocated to DHCP agent on HostA. If you want to validate the behavior "
"through the :command:`dnsmasq` command, you must create a subnet for the "
"network because the DHCP agent starts the dnsmasq service only if there is a "
"DHCP."
msgstr ""
"ネットワークは HostA の DHCP エージェントに割り当てられています。 :command:"
"`dnsmasq` コマンドにより動作を検証する場合、そのネットワークにサブネットを作"
"成しなければいけません。 DHCP エージェントは DHCP が有効な場合にのみ dnsmasq "
"サービスを開始するからです。"

msgid ""
"It is common for a packet to hop across multiple routers to reach its final "
"destination. On a Linux machine, the ``traceroute`` and more recent ``mtr`` "
"programs prints out the IP address of each router that an IP packet "
"traverses along its path to its destination."
msgstr ""
"パケットが最終的な宛先に到達するまでに複数のルーターを経由することはよくある"
"ことです。 Linux マシンでは、 ``traceroute`` や最近では ``mtr`` プログラムを"
"使うと、 IP パケットが宛先に到達するまでに通過する各ルーターの IP アドレスが"
"表示されます。"

msgid ""
"It is positioned as alternative to Open vSwitch or Linux bridge support on "
"the compute node for internal deployments."
msgstr ""
"内向きのデプロイメントでの、コンピュートノードの Open vSwitch や Linux ブリッ"
"ジの代替という位置付けです。"

msgid "Jumbo frames"
msgstr "ジャンボフレーム"

msgid ""
"Just like with bandwidth limiting, create a policy for DSCP marking rule:"
msgstr "帯域制限の場合と同様、 DSCP マーキングルールのポリシーを作成します。"

msgid ""
"Kernel version 3.3, but less than 4.3, does not include *conntrack* support "
"and requires building the OVS modules."
msgstr ""
"バージョン 3.3 以降 4.3 未満のカーネルには *conntrack* サポートが入っていない"
"ため、 OVS モジュールを作成する必要があります。"

msgid "Kernel version 4.3 or newer includes *conntrack* support."
msgstr "バージョン 4.3 以降のカーネルには *conntrack* サポートが入っています。"

msgid "Known limitations"
msgstr "既知の制限"

msgid "L2 agent"
msgstr "L2 エージェント"

msgid "L2 agents support some important security configurations."
msgstr "L2 エージェントはいくつかの重要なセキュリティー機能を持ちます。"

msgid "L2 population"
msgstr "L2 population"

msgid ""
"L2 population is a special mechanism driver that optimizes BUM (Broadcast, "
"unknown destination address, multicast) traffic in the overlay networks "
"VXLAN and GRE. It needs to be used in conjunction with either the Linux "
"bridge or the Open vSwitch mechanism driver and cannot be used as standalone "
"mechanism driver. For more information, see the *Mechanism drivers* section "
"below."
msgstr ""
"L2 population は、 VXLAN や GRE のオーバーレイネットワークにおいて BUM (ブ"
"ロードキャスト、不明な宛先アドレス、マルチキャスト) トラフィックを最適化する"
"ための特別なメカニズムドライバーです。 Linux ブリッジメカニズムドライバーか "
"Open vSwitch メカニズムドライバーと組み合わせて使用する必要があり、単独のメカ"
"ニズムドライバーとして使用することはできません。詳しい情報は、下記の *メカニ"
"ズムドライバー* の節を参照してください。"

msgid ""
"L2 population is not listed here, as it is not a standalone mechanism. If "
"other agents are supported depends on the conjunctive mechanism driver that "
"is used for binding a port."
msgstr ""
"L2 population は、独立して動作するメカニズムドライバーではないため、この表に"
"は記載されていません。他のエージェントが使用できるかは、ポートのバインド時に"
"使用される、組み合わせて使うメカニズムドライバーにより決まります。"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_service.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "L3"
msgstr "L3"

msgid "L3 HA to Legacy"
msgstr "L3 HA からレガシー"

msgid "L3 Metering agent"
msgstr "L3 メータリングエージェント"

# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "L3 agent"
msgstr "L3 エージェント"

msgid "L3 high availability"
msgstr "L3 の高可用性"

msgid "L3 metering agent"
msgstr "L3 メータリングエージェント"

# #-#-#-#-#  adv_config_ipv6.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  adv_config_LBaaS.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "LBaaS"
msgstr "LBaaS"

msgid ""
"LBaaS v1 was removed in the Newton release. These links provide more details "
"about how LBaaS v1 works and how to configure it:"
msgstr ""
"LBaaS v1 は Newton リリースで削除されました。LBaaS v1 の動作や設定方法の詳細"
"については以下のリンクを参照してください。"

msgid "LBaaS v2 Concepts"
msgstr "LBaaS v2 の概念"

msgid ""
"LBaaS v2 adds the concept of listeners to the LBaaS v1 load balancers. LBaaS "
"v2 allows you to configure multiple listener ports on a single load balancer "
"IP address."
msgstr ""
" LBaaS v2 では、 LBaaS v1 ロードバランサーにリスナーの概念が追加されていま"
"す。 LBaaS v2 では、 1 つのロードバランサー IP アドレスに対して複数のリスナー"
"を設定できます。"

msgid ""
"LBaaS v2 has multiple implementations via different service plug-ins. The "
"two most common implementations use either an agent or the Octavia services. "
"Both implementations use the `LBaaS v2 API <https://developer.openstack.org/"
"api-ref/networking/v2/#lbaas-2-0-stable>`_."
msgstr ""
"LBaaS v2 には、異なるサービスプラグインにより複数の実装があります。最も一般的"
"な 2 つの実装はエージェントや Octavia サービスを使用していますが、どちらの実"
"装も `LBaaS v2 API <https://developer.openstack.org/api-ref/networking/v2/"
"#lbaas-2-0-stable>`_ を使用しています。"

msgid "LBaaS v2 has several new concepts to understand:"
msgstr "LBaaS v2 には、理解しておくべき新しい概念がいくつかあります。"

msgid "LBaaS v2 operations"
msgstr "LBaaS v2 の操作"

msgid ""
"Large pages are required for each instance running on hosts with OVS-DPDK. "
"If large pages are not present in the guest, the interface will appear but "
"will not function."
msgstr ""
"OVS-DPDK を使うホストで起動する各インスタンスでラージページが必要です。ゲスト"
"でラージページが存在しない場合、インターフェースは見えますが、正常に動作しま"
"せん。"

msgid ""
"Launch an instance using the network. For example, using the ``cirros`` "
"image and ``m1.tiny`` flavor."
msgstr ""
"上記のネットワークを使ってインスタンスを起動します。例えば、 ``cirros`` イ"
"メージと ``m1.tiny`` フレーバーを使用しています。"

msgid ""
"Launch service function instance ``vm1`` using ports ``p1`` and ``p2``, "
"``vm2`` using ports ``p3`` and ``p4``, and ``vm3`` using ports ``p5`` and "
"``p6``."
msgstr ""
"サービス機能インスタンス ``vm1`` をポート ``p1`` と ``p2`` を使って作成しま"
"す。 ``vm2`` をポート ``p3`` と ``p4`` を使って作成します。 ``vm3`` をポート "
"``p5`` と ``p6`` を使って作成します。"

msgid ""
"Launch two instances, ``instance1`` on ``network1`` and ``instance2`` on "
"``network2``. Associate a floating IP address to both instances."
msgstr ""
"2 つのインスタンス、 ``network1`` に ``instance1`` を、 ``network2`` を "
"``instance2`` を起動します。両方のインスタンスに Floating IP アドレスを付与し"
"ます。"

msgid "Launching instances with SR-IOV ports"
msgstr "SR-IOV ポートを持ったインスタンスの起動"

msgid "Layer 2 (Ethernet and Switching)"
msgstr "レイヤー 2 (Ethernet とスイッチング)"

msgid "Layer 3 (IP and Routing)"
msgstr "レイヤー 3 (IP とルーティング)"

msgid "Legacy nova-network to OpenStack Networking (neutron)"
msgstr "以前の nova-network から OpenStack Networking (neutron) へ"

msgid ""
"Like TCP, the sockets API is the most common API for writing UDP-based "
"applications. The sockets API provides a *message-oriented* interface for "
"writing UDP applications: a programmer sends data over UDP by transmitting a "
"fixed-sized message. If an application requires retransmissions of lost "
"packets or a well-defined ordering of received packets, the programmer is "
"responsible for implementing this functionality in the application code."
msgstr ""
"TCP と同様に、ソケット API が UDP を使うアプリケーションを書く際に最も広く使"
"われています。ソケット API は UDP を使うアプリケーションに対して *メッセージ"
"志向* インターフェースを提供します。プログラマーは固定サイズのメッセージを送"
"信して、 UDP 上でデータ送信を行います。アプリケーションが失われたパケットの再"
"送や受信パケットの並び替えを必要とする場合、アプリケーションのコードでこれら"
"の機能を実装するのはプログラマーの仕事になります。"

msgid "Limitations"
msgstr "制限事項"

msgid ""
"Line 1 of the output specifies the location of the default route, which is "
"the effective routing rule if none of the other rules match. The router "
"associated with the default route (``10.0.2.2`` in the example above) is "
"sometimes referred to as the *default gateway*. A DHCP_ server typically "
"transmits the IP address of the default gateway to the DHCP client along "
"with the client's IP address and a netmask."
msgstr ""
"出力の 1 行目は、デフォルトルートの場所を示しています。デフォルトルートは、他"
"のどのルールにもマッチしなかった場合に使用されるルーティングルールです。デ"
"フォルトルートに関連づいているルーター (上記の例では ``10.0.2.2``) は *デフォ"
"ルトゲートウェイ* と呼ばれることもあります。 DHCP_ サーバーは、通常、クライア"
"ントの IP アドレスとネットマスクと一緒に、デフォルトゲートウェイの IP アドレ"
"スを DHCP クライアントに通知します。"

msgid "Linux Bridge"
msgstr "Linux ブリッジ"

msgid "Linux bridge"
msgstr "Linux ブリッジ"

msgid "Linux bridge & Linux bridge agent"
msgstr "Linux ブリッジ & Linux ブリッジエージェント"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Linux bridge agent"
msgstr "Linux ブリッジエージェント"

msgid "Linux bridge mechanism and Linux bridge agent"
msgstr "Linux ブリッジメカニズムドライバーと Linux ブリッジエージェント"

msgid "Linux bridging for implementing a layer 2 network"
msgstr "Linux ブリッジング: レイヤー 2 ネットワークを実現するため"

msgid "Linux network namespaces"
msgstr "Linux 名前空間"

msgid "List DHCP agents that host a specified network:"
msgstr "特定のネットワークを扱っている DHCP エージェントの一覧を表示します。"

msgid "List all agents:"
msgstr "全エージェントを一覧表示します。"

msgid "List the networks hosted by a given DHCP agent:"
msgstr "指定した DHCP エージェントが扱っているネットワークの一覧を表示します。"

msgid "Listener"
msgstr "リスナー"

msgid "Live migration is not supported for instances with SR-IOV ports."
msgstr ""
"SR-IOV ポートを持つインスタンスのライブマイグレーションはサポートされていませ"
"ん。"

msgid "Load Balancer as a Service (LBaaS)"
msgstr "Load Balancer as a Service (LBaaS)"

msgid "Load balancer"
msgstr "ロードバランサー"

msgid "Load balancers"
msgstr "負荷分散装置"

msgid ""
"Load balancers can be software-based or hardware-based devices that allow "
"traffic to evenly be distributed across several servers. By distributing the "
"traffic across multiple servers, it avoids overload of a single server "
"thereby preventing a single point of failure in the product. This further "
"improves the performance, network throughput, and response time of the "
"servers. Load balancers are typically used in a 3-tier architecture. In this "
"model, a load balancer receives a request from the front-end web server, "
"which then forwards the request to one of the available back-end database "
"servers for processing. The response from the database server is passed back "
"to the web server for further processing."
msgstr ""
"ロードバランサーは、複数のサーバー間でトラフィックを均等に振り分けることがで"
"きるデバイスで、ソフトウェアベースのものもハードウェアベースのものがありま"
"す。複数のサーバーにトラフィックを振り分けることで、サーバー 1 台の過負荷を避"
"けることができ、提供機能の単一障害点を防止できます。また、性能、ネットワーク"
"スループット、サーバーの応答時間などを改善します。通常、ロードバランサーは 3 "
"階層アーキテクチャーで使用されます。このモデルでは、ロードバランサーは、フロ"
"ントエンドのウェブサーバーからリクエストを受信し、そのリクエストを処理を行う"
"利用可能なバックエンドのデータベースサーバーに転送します。データベースサー"
"バーからの応答はウェブサーバーに戻され、さらに処理が行われます。"

msgid ""
"Load balancers can listen for requests on multiple ports. Each one of those "
"ports is specified by a listener."
msgstr ""
"ロードバランサーは複数のポートに対するリクエストをリッスンできます。それぞれ"
"のポートはリスナーで指定されます。"

msgid ""
"Load balancers that are deployed on a public or provider network that are "
"accessible to external clients do not need a floating IP address assigned. "
"External clients can directly access the virtual IP address (VIP) of those "
"load balancers."
msgstr ""
"ロードバランサーが外部のクライアントと通信可能なパブリックネットワークやプロ"
"バイダーネットワークに配備される場合は、 Floating IP アドレスを割り当てる必要"
"がありません。外部のクライアントはロードバランサーの仮想 IP アドレス (VIP) に"
"直接アクセスできます。"

msgid ""
"Log in to the ``myserver4`` VM, and run ``udhcpc``, ``dhclient`` or other "
"DHCP client."
msgstr ""
"``myserver4`` VM にログインして、 ``udhcpc`` 、 ``dhclient`` もしくはその他"
"の DHCP クライアントを実行します。"

msgid ""
"Look at the ``availability_zones`` attribute of each resource to confirm in "
"which zone the resource is hosted:"
msgstr ""
"どのゾーンにそのリソースが配置されたかを確認するには、各リソースの "
"``availability_zones`` を見ます。"

msgid "ML2 driver support matrix"
msgstr "ML2 ドライバーの対応状況"

msgid "ML2 plug-in"
msgstr "ML2 プラグイン"

msgid "MTU considerations"
msgstr "MTU に関する考慮事項"

msgid "MacVTap"
msgstr "MacVTap"

msgid "MacVTap & MacVTap agent"
msgstr "MacVTap & MacVTap エージェント"

msgid "MacVTap agent"
msgstr "MacVTap エージェント"

msgid "MacVTap mechanism driver and MacVTap agent"
msgstr "MacVTap メカニズムドライバーと MacVTap エージェント"

msgid ""
"MacVTap offers a direct connection with very little overhead between "
"instances and down to the adapter. You can use MacVTap agent on the compute "
"node when you require a network connection that is performance critical. It "
"does not require specific hardware (like with SRIOV)."
msgstr ""
"macvtap を使うと、インスタンスとアダプター間を非常に小さいオーバーヘッドで直"
"接接続できます。性能が非常に重要なネットワーク接続が必要な場合、コンピュート"
"ノードで macvtap エージェントを使用できます。 (SRIOV の場合のように) 特別な"
"ハードウェアは必要としません。"

msgid "Macvtap agent"
msgstr "Macvtap エージェント"

msgid ""
"Make Compute REST API read-write again. This means legacy networking DB is "
"now unused, new changes are now stored in the Networking DB, and no rollback "
"is possible from here without losing those new changes."
msgstr ""
"Compute REST API を読み書き両用に戻します。この時点で、レガシーネットワーク用"
"の DB は使用されなくなり、新しい変更は Networking DB に格納されなくなります。"
"これ以降は新規の変更を保持したままロールバックはできません。"

msgid "Make sure both DHCP agents hosting ``net2``:"
msgstr "両方の DHCP エージェントが ``net2`` を担当するようにします。"

msgid ""
"Make sure that subnets on an external network are created from the subnet "
"pools created above:"
msgstr ""
"外部ネットワークのサブネットは、上記で作成したサブネットプールから作成してく"
"ださい。"

msgid "Make sure that the router's ``ha`` attribute has changed to ``False``."
msgstr ""
"ルーターの ``ha`` 属性が ``False`` に変更されたことを確認してください。"

msgid "Make sure that the router's ``ha`` attribute has changed to ``True``."
msgstr "ルーターの ``ha`` 属性が ``True`` に変更されたことを確認してください。"

msgid "Make the Compute REST API read-only."
msgstr "Compute REST API を読み出し専用にします。"

msgid "Make the Networking API read-write and disable legacy networking."
msgstr ""
"Networking API を読み書きモードにして、レガシーネットワークを無効にします。"

msgid "Managed Configuration Flag = 0"
msgstr "Managed Configuration Flag = 0"

msgid "Management impact"
msgstr "管理面での影響"

msgid "Manages agents"
msgstr "エージェントを管理する"

msgid "Managing agents in neutron deployment"
msgstr "neutron 環境でのエージェントの管理"

msgid "Managing assignment of networks to DHCP agent"
msgstr "DHCP エージェントへのネットワーク割り当ての管理"

msgid "Mechanism Driver"
msgstr "メカニズムドライバー"

msgid "Mechanism drivers"
msgstr "メカニズムドライバー"

msgid "Mechanism drivers and L2 agents"
msgstr "メカニズムドライバーと L2 エージェント"

msgid ""
"Mechanism drivers can utilize L2 agents (via RPC) and/or interact directly "
"with external devices or controllers."
msgstr ""
"メカニズムドライバーは、 (RPC 経由で) L2 エージェントを活用したり、外部のデバ"
"イスやコントローラーと直接やり取りしたりできます。"

msgid "Mellanox"
msgstr "Mellanox"

msgid "Member"
msgstr "メンバー"

msgid ""
"Members are servers that serve traffic behind a load balancer. Each member "
"is specified by the IP address and port that it uses to serve traffic."
msgstr ""
"メンバーは、ロードバランサーの裏でトラフィックを処理するサーバーです。各メン"
"バーはトラフィックを処理するのに使われる IP アドレスとポート番号で指定されま"
"す。"

msgid ""
"Members may go offline from time to time and health monitors divert traffic "
"away from members that are not responding properly. Health monitors are "
"associated with pools."
msgstr ""
"メンバーは時としてオフラインになることがあります。ヘルスモニターは、正常に応"
"答していないメンバーにトラフィックが向かないようにします。ヘルスモニターは"
"プールに関連付けされます。"

msgid "Messaging queue"
msgstr "メッセージングキュー"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_service.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Metadata"
msgstr "メタデータ"

# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Metadata agent"
msgstr "メタデータエージェント"

msgid ""
"Migrating a router from distributed only, HA only, or legacy to distributed "
"HA is not supported at this time. The router must be created as distributed "
"HA. The reverse direction is also not supported. You cannot reconfigure a "
"distributed HA router to be only distributed, only HA, or legacy."
msgstr ""
"現時点では、分散のみ、HA のみ、レガシーモードのルーターから分散 HA ルーターへ"
"の移行には対応していません。ルーターは分散 HA モードで作成しなければいけませ"
"ん。逆方向の移行にも対応していません。分散 HA ルーターを、分散のみ、HA のみ、"
"レガシーモードに設定し直すことはできません。"

msgid "Migration"
msgstr "移行"

msgid "Migration Completed!"
msgstr "これで移行は完了です!"

msgid "Migration process overview"
msgstr "移行手順の概要"

# #-#-#-#-#  intro_os_networking_service.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  miscellaneous.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Miscellaneous"
msgstr "その他"

msgid "Modify ``/etc/neutron/policy.json`` policy entries as follows:"
msgstr ""
"``/etc/neutron/policy.json`` のポリシーエントリーを以下のように変更します。"

msgid ""
"More information about L2 population see the `OpenStack Manuals <http://docs."
"ocselected.org/openstack-manuals/kilo/networking-guide/content/"
"ml2_l2pop_scenarios.html>`__."
msgstr ""
"L2 population についての詳しい情報は `OpenStack マニュアル <http://docs."
"ocselected.org/openstack-manuals/kilo/networking-guide/content/"
"ml2_l2pop_scenarios.html>`__ を参照してください。"

msgid ""
"Most OpenStack deployments use the `libvirt <http://libvirt.org>`__ toolkit "
"for interacting with the hypervisor. Specifically, OpenStack Compute uses "
"libvirt for tasks such as booting and terminating virtual machine instances. "
"When OpenStack Compute boots a new instance, libvirt provides OpenStack with "
"the VIF associated with the instance, and OpenStack Compute plugs the VIF "
"into a virtual device provided by OpenStack Network. The libvirt toolkit "
"itself does not provide any networking functionality in OpenStack "
"deployments."
msgstr ""
"ほとんどの OpenStack デプロイメントでは、ハイパーバイザーとのやり取りに "
"`libvirt <http://libvirt.org>`__ ツールキットを使用します。特に、 OpenStack "
"Compute が仮想マシンインスタンスの起動、終了などの処理を行うのに libvirt を使"
"用します。 OpenStack Compute が新しいインスタンスを起動する際、 libvirt は イ"
"ンスタンスに関連付けられた仮想インターフェイス (VIF) を OpenStack に渡し、 "
"OpenStack Compute は VIF を OpenStack Networking が提供する仮想デバイスに挿し"
"ます。 libvirt ツールキット自身は OpenStack 環境ではネットワーク機能は一切提"
"供しません。"

msgid ""
"Multiple mechanism and type drivers can be used simultaneously to access "
"different ports of the same virtual network."
msgstr ""
"同じ仮想ネットワークのいろいろなポートを扱うために、複数のメカニズムドライ"
"バーやタイプドライバーを同時に使用できます。"

msgid ""
"Multiqueue support is available if the following newer versions are used:"
msgstr "マルチキューのサポートは、以下のバージョン以降で利用できます。"

msgid "N/A"
msgstr "N/A"

msgid "NAT & Floating IPs"
msgstr "NAT と Floating IP"

msgid ""
"NAT is often implemented by routers, and so we will refer to the host "
"performing NAT as a *NAT router*. However, in OpenStack deployments it is "
"typically Linux servers that implement the NAT functionality, not hardware "
"routers. These servers use the `iptables <http://www.netfilter.org/projects/"
"iptables/index.html>`_ software package to implement the NAT functionality."
msgstr ""
"NAT はしばしばルーターで行われます。そのため、 NAT を行うホストを *NAT ルー"
"ター* と呼びます。しかしながら、 OpenStack デプロイメントでは、通常 Linux "
"サーバーで NAT 機能が実装され、ハードウェアルーターではありません。これらの"
"サーバーでは `iptables <http://www.netfilter.org/projects/iptables/index."
"html>`_ ソフトウェアパッケージを使って NAT 機能を実装します。"

msgid "Name"
msgstr "名前"

msgid "Name resolution for instances"
msgstr "インスタンス用の名前解決"

msgid "Name: vm1"
msgstr "名前: vm1"

msgid "Name: vm2"
msgstr "名前: vm2"

msgid "Name: vm3"
msgstr "名前: vm3"

msgid "Native Open vSwitch firewall driver"
msgstr "ネイティブ Open vSwitch ファイアウォールドライバー"

msgid ""
"Network IP Availability is an information-only API extension that allows a "
"user or process to determine the number of IP addresses that are consumed "
"across networks and the allocation pools of their subnets. This extension "
"was added to neutron in the Mitaka release."
msgstr ""
"ネットワーク IP アドレス利用状況機能 (network IP availability) は情報取得用"
"の API 拡張で、これを使うとユーザーやプロセスがネットワークやサブネットのアド"
"レス割り当てプールで使用されている IP アドレス数を取得できます。この API 拡張"
"は Mitaka リリースで追加されました。"

msgid "Network address translation"
msgstr "ネットワークアドレス変換 (NAT)"

msgid "Network components"
msgstr "ネットワークコンポーネント"

msgid ""
"Network devices such as switches and routers can mark traffic so that it is "
"handled with a higher priority to fulfill the QoS conditions agreed under "
"the SLA. In other cases, certain network traffic such as Voice over IP "
"(VoIP) and video streaming needs to be transmitted with minimal bandwidth "
"constraints. On a system without network QoS management, all traffic will be "
"transmitted in a \"best-effort\" manner making it impossible to guarantee "
"service delivery to customers."
msgstr ""
"スイッチやルーターといったネットワークデバイスはトラフィックにマークを付ける"
"ことができ、そららを高優先度として扱うことで、 SLA において合意された QoS 条"
"件を達成します。他の例としては、 Voice over IP (VoIP) やビデオストリーミング"
"などのネットワークトラフィックを最小限の帯域制約で転送するために QoS が必要で"
"す。ネットワーク QoS 管理のないシステムでは、すべてのトラフィックは「ベストエ"
"フォート」で転送され、顧客へのサービス提供を保証することが困難になります。"

msgid "Network namespaces"
msgstr "ネットワーク名前空間"

# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Network node"
msgstr "ネットワークノード"

# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Network node 1:"
msgstr "ネットワークノード 1:"

# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Network node 2:"
msgstr "ネットワークノード 2:"

# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Network nodes"
msgstr "ネットワークノード"

msgid "Network scheduler"
msgstr "ネットワークスケジューラー"

msgid "Network type drivers"
msgstr "ネットワークタイプドライバー"

msgid "Networks"
msgstr "ネットワーク"

msgid ""
"Networks created before the Mitaka release do not contain explicitly named "
"address scopes, unless the network contains subnets from a subnet pool that "
"belongs to a created or updated address scope. The Networking service "
"preserves backwards compatibility with pre-Mitaka networks through special "
"address scope properties so that these networks can perform advanced routing:"
msgstr ""
"Mitaka リリースより前に作成されたネットワークは、明示的なアドレススコープを持"
"ちません。ただし、ネットワークのサブネットが、作成、更新されたアドレススコー"
"プに属すサブネットプールから作られている場合はこの限りではありません。 "
"Networking サービスは、特別なアドレススコープを使うことで Mitaka リリースより"
"前に作成されたネットワークに対する後方互換性を実現しており、こうしたネット"
"ワークでは以下のようなルーティングが行われます。"

msgid "Neutron configuration file ``/etc/neutron/neutron.conf``:"
msgstr "neutron 設定ファイル ``/etc/neutron/neutron.conf``:"

msgid "Neutron dhcpv6_pd_agent"
msgstr "Neutron dhcpv6_pd_agent"

msgid ""
"Neutron project networks that are assigned Global Unicast Address (GUA) "
"prefixes and addresses don’t require NAT on the neutron router external "
"gateway port to access the outside world. As a consequence of the lack of "
"NAT the external router port doesn’t require a GUA to send and receive to "
"the external networks. This implies a GUA IPv6 subnet prefix is not "
"necessarily needed for the neutron external network. By default, a IPv6 LLA "
"associated with the external gateway port can be used for routing purposes. "
"To handle this scenario, the implementation of router-gateway-set API in "
"neutron has been modified so that an IPv6 subnet is not required for the "
"external network that is associated with the neutron router. The LLA address "
"of the upstream router can be learned in two ways."
msgstr ""
"グローバルに一意なアドレス (Global Unicast Address; GUA) プレフィックスとアド"
"レスを割り当てられた neutron プロジェクトネットワークは、外部の世界にアクセス"
"する際に neutron ルーターの外部ゲートウェイポートでの NAT が不要です。 NAT が"
"不要なため、外部ルーターポートは外部ネットワークと送受信するための GUA が必要"
"ありません。これは、neutron 外部ネットワークに GUA な IPv6 サブネットプレ"
"フィックスが不要なことを意味します。デフォルトでは、外部ゲートウェイポートに"
"関連付けられた IPv6 LLA がルーティング用に使用されます。このシナリオに対応す"
"るため、 neutron の router-gateway-set API に変更が行われ、 neutron ルーター"
"に関連付ける外部ネットワークで IPv6 サブネットが必須ではなくなりました。 上流"
"ルーターの LLA アドレスは以下の 2 つの方法で学習されます。"

msgid ""
"Neutron routers, by default, will NAT traffic from internal networks to "
"external networks."
msgstr ""
"デフォルトでは、Neutron ルーターは、内部ネットワークから外部ネットワークへの"
"トラフィックに対して NAT を行います。"

msgid "Neutron subnets and the IPv6 API attributes"
msgstr "Neutron サブネットと IPv6 API 属性"

msgid "Neutron's Distributed Router feature and IPv6"
msgstr "Neutron の DVR (分散ルーター機能) と IPv6"

msgid ""
"Next, you'll need to migrate each hypervisor.  To do that, follow these "
"steps:"
msgstr ""
"次に、各ハイパーバイザーを移行する必要があります。以下の手順を行います。"

msgid "No"
msgstr "いいえ"

msgid "No additional configuration required."
msgstr "追加の設定はありません。"

msgid ""
"No additional configurations required for the mechanism driver. Additional "
"agent configuration is required. For details, see the related *L2 agent* "
"section below."
msgstr ""
"メカニズムドライバーに関する追加の設定は不要です。追加のエージェント設定が必"
"要です。詳細は下記の *L2 エージェント* の節を参照してください。"

msgid ""
"No additional configurations required for the mechanism driver. Additional "
"agent configuration is required. Please see the related section."
msgstr ""
"メカニズムドライバーに関する追加の設定は不要です。追加のエージェント設定が必"
"要です。関連する節を参照してください。"

msgid "No changes."
msgstr "変更なし。"

msgid "Not Defined"
msgstr "未定義"

msgid "Not currently implemented in the reference implementation."
msgstr "今のところ参照実装では未実装です。"

msgid "Not specified."
msgstr "指定なし"

msgid "Note that in this use case:"
msgstr "このユースケースで注意する点は以下です。"

msgid ""
"Now consider the scenario that all of the switchports in the first switch "
"become occupied, and so the organization buys a second switch and connects "
"it to the first switch to expand the available number of switchports. The "
"second switch is also configured to support VLAN IDs 10, 11, and 12. Now "
"imagine host A connected to switch 1 on a port configured for VLAN ID 10 "
"sends an Ethernet frame intended for host B connected to switch 2 on a port "
"configured for VLAN ID 10. When switch 1 forwards the Ethernet frame to "
"switch 2, it must communicate that the frame is associated with VLAN ID 10."
msgstr ""
"今度は、 1 台目のスイッチのスイッチポートがすべて利用され、組織が 2 台目のス"
"イッチを購入して、1 台目のスイッチに接続して、利用できるスイッチポート数を拡"
"張する、というシナリオを考えましょう。 2 台目のスイッチも VLAN 10, 11, 12 が"
"使用できるように設定します。ここで、スイッチ 1 の VLAN ID 10 に設定されたポー"
"トに接続されたホスト A が、スイッチ 2 の VLAN ID 10 に設定されたポートに接続"
"されたホスト B に Ethernet フレームを送信する場面を考えます。スイッチ 1 は "
"Ethernet フレームをスイッチ 2 に転送する際に、そのフレームは VLAN ID 10 に関"
"連付けられていることを伝える必要があります。"

msgid "Now, use them. It is easy to create a subnet from a pool:"
msgstr ""
"このサブネットプールを使ってみましょう。プールからサブネットを作るのは簡単で"
"す。"

msgid "OVS"
msgstr "OVS"

msgid "OVS 2.4"
msgstr "OVS 2.4"

msgid "OVS 2.5"
msgstr "OVS 2.5"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Obtain access to the instance."
msgstr "インスタンスにアクセスします。"

msgid ""
"Octavia provides additional capabilities for load balancers, including using "
"a compute driver to build instances that operate as load balancers. The "
"`Hands on Lab - Install and Configure OpenStack Octavia <https://www."
"openstack.org/summit/tokyo-2015/videos/presentation/rsvp-required-hands-on-"
"lab-install-and-configure-openstack-octavia>`_ session at the OpenStack "
"Summit in Tokyo provides an overview of Octavia."
msgstr ""
"Octavia はロードバランサーに関する追加の機能を提供します。例えば、コンピュー"
"トドライバーを使って、ロードバランサーとして機能するインスタンスを作成すると"
"いったことです。 Octavia の概要については、東京の OpenStack Summit でのセッ"
"ション `Hands on Lab - Install and Configure OpenStack Octavia (ハンズオンラ"
"ボ - OpenStack Octavia のインストールと設定) <https://www.openstack.org/"
"summit/tokyo-2015/videos/presentation/rsvp-required-hands-on-lab-install-and-"
"configure-openstack-octavia>`_ を見てください。"

msgid "Off"
msgstr "オフ"

msgid ""
"Offline migration requires all Neutron server instances in the cluster to be "
"shutdown before you apply any contract scripts."
msgstr ""
"オフライン移行を行うには、 contract スクリプトを適用する前に、クラスター内の"
"すべての Neutron サーバーをシャットダウンする必要があります。"

msgid ""
"Often, an application running on a host with a private IP address will need "
"to connect to a server on the public Internet. An example is a user who "
"wants to access a public website such as www.openstack.org. If the IP "
"packets reach the web server at www.openstack.org with a private IP address "
"as the source, then the web server cannot send packets back to the sender."
msgstr ""
"プライベート IP アドレスを持つホストで動作するアプリケーションがパブリックな"
"インターネット上のサーバーへの接続を必要とすることはしばしばあります。 1 例と"
"しては、ユーザーが www.openstack.org のような公開ウェブサイトにアクセスしたい"
"場面があるでしょう。 IP パケットが送信元アドレスがプライベート IP アドレスを"
"持ったまま www.openstack.org があるウェブサーバーに到達してしまうと、ウェブ"
"サーバーは送信元にパケットを送り返すことができません。"

msgid ""
"On Ubuntu, the iptables ruleset that libvirt creates includes the following "
"rules::"
msgstr ""
"Ubuntu では、 libvirt が作成する iptable ルールセットには以下のルールが含まれ"
"ます。"

msgid ""
"On a Linux machine, any of the following commands displays the routing table:"
msgstr ""
"Linux マシンでは、以下のどのコマンドを使ってもルーティングテーブルを表示でき"
"ます。"

msgid "On compute nodes:"
msgstr "コンピュートノード:"

msgid "On each compute node, create the VFs via the PCI SYS interface:"
msgstr ""
"各コンピュートノードで、 PCI SYS インターフェース経由で VF を作成します。"

msgid ""
"On every controller node running the ``nova-scheduler`` service, add "
"``PciPassthroughFilter`` to ``scheduler_default_filters`` to enable "
"``PciPassthroughFilter`` by default. Also ensure "
"``scheduler_available_filters`` parameter under the ``[DEFAULT]`` section in "
"``nova.conf`` is set to ``all_filters`` to enable all filters provided by "
"the Compute service."
msgstr ""
"``nova-scheduler`` サービスを実行しているすべてのコントローラーノードで、 "
"``scheduler_default_filters`` パラメーターに ``PciPassthroughFilter`` を追加"
"し、デフォルトで ``PciPassthroughFilter`` が有効になるようにします。また、 "
"Compute サービスで提供されているすべてのフィルターが有効になるように、 "
"``nova.conf`` の ``[DEFAULT]`` セクションの ``scheduler_available_filters`` "
"パラメーターを ``all_filters`` に設定します。"

msgid "On network nodes:"
msgstr "ネットワークノード:"

msgid ""
"On nodes running the Open vSwitch agent, edit the ``openvswitch_agent.ini`` "
"file and enable the firewall driver."
msgstr ""
"Open vSwitch エージェントが動作しているノードで、 ``openvswitch_agent.ini`` "
"ファイルを編集し、ファイアウォールドライバーを有効にします。"

msgid ""
"On some PCI devices, observe that when changing the amount of VFs you "
"receive the error ``Device or resource busy``. In this case, you must first "
"set ``sriov_numvfs`` to ``0``, then set it to your new value."
msgstr ""
"PCI デバイスによっては、 VF の総数を変更する際に ``Device or resource busy`` "
"というエラーを出る場合があります。この場合は、まず ``sriov_numvfs`` を ``0`` "
"に設定し、それから新しい値に設定してください。"

msgid ""
"Once OVS is correctly configured with DPDK support, ``vhost-user`` "
"interfaces are completely transparent to the guest. However, guests must "
"request large pages. This can be done through flavors. For example:"
msgstr ""
"DPDK 対応の OVS の設定が正常に完了すれば、 ``vhost-user`` インターフェースは"
"ゲストからは全く同じように利用できます。ただし、ゲストはラージページを必要と"
"します。ラージページの要求はフレーバー経由で指定します。例:"

msgid ""
"Once configuration is complete, you can launch instances with SR-IOV ports."
msgstr "設定が完了したら、 SR-IOV ポートを持ったインスタンスを起動できます。"

msgid ""
"Once starting the migration, south-north connections (instances to internet) "
"will be severed. New connections will be able to start only when the "
"migration is complete."
msgstr ""
"一度移行作業を開始すると、south-north トラフィック (インスタンスからインター"
"ネット) は切断されます。新しいコネクションを開始できるのは移行完了後です。"

msgid ""
"Once the ``neutron-server`` has been configured and restarted, users will "
"have functionality that covers three use cases, described in the following "
"sections. In each of the use cases described below:"
msgstr ""
"``neutron-server`` の設定と再起動が終わると、ユーザーは以下の節で説明する 3 "
"つのユースケースが実現できる機能を使えるようになります。各ユースケースに共通"
"の事項として以下があります。"

msgid ""
"Once these steps are executed, the port's DNS data will be published in the "
"external DNS service. This is an example:"
msgstr ""
"これらの手順を実行すると、ポートの DNS データが外部 DNS サービスで公開されま"
"す。例を示します。"

msgid ""
"Once you have stacked run the command below to start the neutron-pd-agent:"
msgstr ""
"DevStack 実行後は、以下のコマンドを実行して neutron-pd-agent を開始します。"

msgid "One BGP agent."
msgstr "1 個の BGP エージェント。"

msgid ""
"One address scope containing IP address range 203.0.113.0/24 for provider "
"networks, and IP address ranges 10.0.1.0/24 and 10.0.2.0/24 for self-service "
"networks."
msgstr ""
"1 個のアドレススコープ。このアドレススコープは、プロバイダーネットワーク用の "
"IP アドレス範囲 203.0.113.0/24 および、セルフサービスネットワーク用の IP アド"
"レス範囲 10.0.1.0/24 と 10.0.2.0/24 を含みます。"

msgid "One provider network using IP address range 203.0.113.0/24."
msgstr ""
"1 個のプロバイダーネットワーク。 IP アドレス範囲として 203.0.113.0/24 を使用"
"します。"

msgid "One-to-one NAT"
msgstr "One-to-One (1対1) NAT"

msgid ""
"Only compute resources can be attached via macvtap. Attaching other "
"resources like DHCP, Routers and others is not supported. Therefore run "
"either OVS or linux bridge in VLAN or flat mode on the controller node."
msgstr ""
"コンピュートリソースだけが macvtap 経由で接続できます。 DHCP、ルーターなどの"
"他のリソースの接続には対応していません。したがって、コントローラーノードでは "
"OVS エージェントか Linux ブリッジエージェントを VLAN かフラットモードで動かし"
"ます。"

msgid ""
"Only for :ref:`config-dns-use-case-1`, if the port binding extension is "
"enabled in the Networking service, the Compute service will execute one "
"additional port update operation when allocating the port for the instance "
"during the boot process. This may have a noticeable adverse effect in the "
"performance of the boot process that must be evaluated before adoption of "
"this use case."
msgstr ""
":ref:`config-dns-use-case-1` の場合だけですが、 Networking サービスで port "
"binding API 拡張が有効になっている場合、 Compute サービスは起動処理中にインス"
"タンスにポートを割り当てる際に余計に 1 回ポート更新操作を行うことになります。"
"このことは、起動処理の性能に目に見えるマイナス影響を与える可能性もあり、この"
"ユースケースを採用する前に評価を行うべきです。"

msgid "Open source"
msgstr "オープンソース"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Open vSwitch"
msgstr "Open vSwitch"

msgid "Open vSwitch & Open vSwitch agent"
msgstr "Open vSwitch & Open vSwitch エージェント"

msgid ""
"Open vSwitch (OVS) provides support for a Data Plane Development Kit (DPDK) "
"datapath since OVS 2.2, and a DPDK-backed ``vhost-user`` virtual interface "
"since OVS 2.4. The DPDK datapath provides lower latency and higher "
"performance than the standard kernel OVS datapath, while DPDK-backed ``vhost-"
"user`` interfaces can connect guests to this datapath. For more information "
"on DPDK, refer to the `DPDK <http://dpdk.org/>`__ website."
msgstr ""
"Open vSwitch (OVS) は、 OVS 2.2 以降で Data Plane Development Kit (DPDK) デー"
"タパスに対応しており、 OVS 2.4 以降では DPDK を利用した ``vhost-user`` 仮想イ"
"ンターフェースに対応しています。 DPDK データパスを使うと、標準のカーネル OVS "
"のデータパスよりも低遅延で高性能なデータパスが実現できます。 DPDK を利用した "
"``vhost-user`` インターフェースを使うと、ゲストを DPDK データパスに接続できま"
"す。 DPDK の詳しい情報は `DPDK <http://dpdk.org/>`__ のウェブサイトを参照して"
"ください。"

# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Open vSwitch agent"
msgstr "Open vSwitch エージェント"

msgid "Open vSwitch agent, Linux bridge agent"
msgstr "Open vSwitch エージェント、 Linux ブリッジエージェント"

msgid "Open vSwitch mechanism and Open vSwitch agent"
msgstr "Open vSwitch メカニズムドライバーと Open vSwitch エージェント"

msgid "Open vSwitch with DPDK datapath"
msgstr "Open vSwitch を DPDK データパスで使用する"

msgid "OpenContrail"
msgstr "OpenContrail"

msgid "OpenDaylight"
msgstr "OpenDaylight"

msgid ""
"OpenStack :term:`Compute service (nova)` is used to plug each virtual NIC on "
"the VM into a particular network."
msgstr ""
"OpenStack :term:`Compute サービス (nova) <Compute service (nova)>` は、仮想マ"
"シンの各仮想 NIC を特定のネットワークに差し込むために使用されます。"

msgid "OpenStack Networking"
msgstr "OpenStack Networking"

msgid "OpenStack Networking Guide"
msgstr "OpenStack ネットワークガイド"

msgid ""
"OpenStack Networking allows you to create and manage network objects, such "
"as networks, subnets, and ports, which other OpenStack services can use. "
"Plug-ins can be implemented to accommodate different networking equipment "
"and software, providing flexibility to OpenStack architecture and deployment."
msgstr ""
"OpenStack Networking により、ネットワーク、サブネット、ポートなどのネットワー"
"クオブジェクトを作成、管理でき、これらのネットワークオブジェクトは他の "
"OpenStack サービスも利用できます。プラグインにより様々なネットワーク装置や"
"ネットワークソフトウェアを収容することができ、 自由度のある OpenStack アーキ"
"テクチャーやデプロイメントが実現できます。"

msgid ""
"OpenStack Networking consists of the neutron-server, a database for "
"persistent storage, and any number of plug-in agents, which provide other "
"services such as interfacing with native Linux networking mechanisms, "
"external devices, or SDN controllers."
msgstr ""
"OpenStack Networking は、 neutron-server、永続ストレージとしてのデータベース"
"と、任意の数のプラグインエージェントで構成されます。プラグインエージェント"
"は、 Linux が持つネットワーク機構、外部デバイス、SDN コントローラーなどとやり"
"取りを行い、それ以外のサービスを提供します。"

msgid "OpenStack Networking integrates with various OpenStack components:"
msgstr ""
"OpenStack Networking は、さまざまな OpenStack コンポーネントと統合されていま"
"す。"

msgid ""
"OpenStack Networking is entirely standalone and can be deployed to a "
"dedicated host. If your deployment uses a controller host to run centralized "
"Compute components, you can deploy the Networking server to that specific "
"host instead."
msgstr ""
"OpenStack Networking は完全にそれだけで完結しており、専用のホストのデプロイで"
"きます。お使いの環境で、 Compute の集中型のコンポーネントを実行するコントロー"
"ラーホストを使っている場合は、 Networking サーバーをそのホストに置くこともで"
"きます。"

msgid "OpenStack Networking plug-in and agents"
msgstr "OpenStack Networking プラグインとエージェント"

msgid ""
"OpenStack can be setup such that OpenStack Networking directly provides RA, "
"DHCP relay and DHCPv6 address and optional information for their networks or "
"this can be delegated to external routers and services based on the drivers "
"that are in use. There are two neutron subnet attributes - ``ipv6_ra_mode`` "
"and ``ipv6_address_mode`` – that determine how IPv6 addressing and network "
"information is provided to project instances:"
msgstr ""
"OpenStack は、OpenStack Networking が OpenStack 上のネットワークに対して "
"RA、 DHCP relay、 DHCPv6 アドレス、追加の情報を直接提供するようにセットアップ"
"することも、こうした機能を使用するドライバーに基いて外部のルーターやサービス"
"に移譲できるようにすることもできます。 Neutron サブネットには、 "
"``ipv6_ra_mode`` と ``ipv6_address_mode`` という 2 つの属性があり、これらの属"
"性により IPv6 アドレスとネットワーク情報をプロジェクトのインスタンスにどのよ"
"うに提供するかが決定されます。"

msgid "OpenStack control & management network considerations"
msgstr "OpenStack の制御、管理ネットワークでの考慮事項"

msgid ""
"OpenStack control communication between servers and services over an IPv6 "
"network."
msgstr "IPv6 ネットワーク越しの、サーバー間、サービス間での OpenStack 制御通信"

msgid "OpenStack controller host - controlnode"
msgstr "OpenStack コントローラーホスト - controlnode"

msgid ""
"OpenStack currently doesn't support the privacy extensions defined by RFC "
"4941. The interface identifier and DUID used must be directly derived from "
"the MAC as described in RFC 2373. The compute hosts must not be setup to "
"utilize the privacy extensions when generating their interface identifier."
msgstr ""
"OpenStack は現在のところ RFC 4941 で定義されたプライバシー拡張に対応していま"
"せん。使用するインターフェース識別子と DUID は、 RFC 2373 に書かれているよう"
"に直接 MAC に基づいて生成される必要があります。コンピュートホストは、インター"
"フェース識別子の生成時にプライバシー拡張を使用しないように設定しなければいけ"
"ません。"

msgid ""
"OpenStack uses DNAT to route packets from instances to the OpenStack "
"metadata service. Applications running inside of instances access the "
"OpenStack metadata service by making HTTP GET requests to a web server with "
"IP address 169.254.169.254. In an OpenStack deployment, there is no host "
"with this IP address. Instead, OpenStack uses DNAT to change the destination "
"IP of these packets so they reach the network interface that a metadata "
"service is listening on."
msgstr ""
"OpenStack は、インスタンスからのパケットを OpenStack メタデータサービスにルー"
"ティングするために、DNAT を使用します。インスタンス内で動作するアプリケーショ"
"ンは、 IP アドレス 169.254.169.254 のウェブサーバーに HTTP GET リクエストを行"
"うことで、 OpenStack メタデータサービスにアクセスします。 OpenStack 環境で"
"は、この IP アドレスを持つホストはありません。その代わり、 OpenStack は、 "
"DNAT を使ってこれらのパケットの宛先 IP アドレスを変更し、メタデータサービスが"
"リッスンしているネットワークインターフェースにパケットが届くようにします。"

msgid ""
"OpenStack uses SNAT to enable applications running inside of instances to "
"connect out to the public Internet."
msgstr ""
"OpenStack は SNAT を使うことで、インスタンス内で動作するアプリケーションがパ"
"ブリックなインターネットに出て行けるようにしています。"

msgid ""
"OpenStack uses a third-party program called `dnsmasq <http://www.thekelleys."
"org.uk/dnsmasq/doc.html>`_ to implement the DHCP server. Dnsmasq writes to "
"the syslog, where you can observe the DHCP request and replies::"
msgstr ""
"OpenStack は第三者製のプログラム `dnsmasq <http://www.thekelleys.org.uk/"
"dnsmasq/doc.html>`_ を使って DHCP サーバーを実装しています。 dnsmasq は "
"syslog に書き込みます。 DHCP 要求と応答を確認できます。::"

msgid "Operation"
msgstr "運用"

msgid "Operation with Distributed Virtual Routers (DVR)"
msgstr "分散仮想ルーター (DVR) 利用時の動作"

msgid "Operations"
msgstr "運用"

msgid "Operations impact"
msgstr "運用面での影響"

msgid ""
"Operators (and users with admin role) can get the auto-allocated topology "
"for a project by specifying the project ID:"
msgstr ""
"運用者 (や管理者ロールを持つユーザー) は、プロジェクト ID を指定することで、"
"プロジェクト用の自動割り当てされたネットワークトポロジーを取得することもでき"
"ます。"

msgid ""
"Optionally, create another subnet on the network with a different service "
"type. For example, the ``compute:foo`` arbitrary service type."
msgstr ""
"別のサービスタイプを指定して、同じネットワーク上に別のサブネットを作成するこ"
"ともできます。例えば、 ``compute:foo`` といった任意のサービスタイプを指定でき"
"ます。"

msgid ""
"Optionally, set the needed ``notification_drivers`` in the ``[qos]`` section "
"in ``/etc/neutron/neutron.conf`` (``message_queue`` is the default)."
msgstr ""
"必要であれば、 ``/etc/neutron/neutron.conf`` の ``[qos]`` セクションで必要な "
"``notification_drivers`` を設定してください (デフォルト値は "
"``message_queue`` です)。"

msgid "Or to run in headless mode:"
msgstr "もしくは headless モードで実行するには、以下のようにします。"

msgid "Other Configuration Flag = 0"
msgstr "Other Configuration Flag = 0"

msgid "Other Configuration Flag = 1"
msgstr "Other Configuration Flag = 1"

msgid ""
"Other networks including provider networks and flat or VLAN self-service "
"networks assume the value of the ``global_physnet_mtu`` option."
msgstr ""
"プロバイダーネットワークや flat/VLAN のセルフサービスネットワークなどの他の"
"ネットワークでは ``global_physnet_mtu`` オプションの値が使用されます。"

msgid "Otherwise if you are running OpenStack Mitaka, make this change:"
msgstr "OpenStack Mitaka を実行している場合には、以下の変更を行います。"

msgid "Overlay (tunnel) protocols"
msgstr "オーバーレイ (トンネル) プロトコル"

msgid "Overview"
msgstr "概要"

msgid ""
"PCI ``vendor_id`` and ``product_id`` as displayed by the Linux utility "
"``lspci``."
msgstr ""
"PCI ``vendor_id`` と ``product_id`` は Linux のユーティリティー ``lspci`` で"
"表示できます。"

msgid ""
"PCI address: The address uses the same syntax as in ``lspci`` and an "
"asterisk (*) can be used to match anything."
msgstr ""
"PCI アドレス: アドレスは ``lspci`` と同じ書式を使用します、アスタリスク (*) "
"は任意のものにマッチすることを示します。"

msgid ""
"PCI-SIG Single Root I/O Virtualization and Sharing (SR-IOV) functionality is "
"available in OpenStack since the Juno release. The SR-IOV specification "
"defines a standardized mechanism to virtualize PCIe devices. This mechanism "
"can virtualize a single PCIe Ethernet controller to appear as multiple PCIe "
"devices. Each device can be directly assigned to an instance, bypassing the "
"hypervisor and virtual switch layer. As a result, users are able to achieve "
"low latency and near-line wire speed."
msgstr ""
"PCI-SGI の Single Root I/O Virtualization and Sharing (SR-IOV) 機能は Juno リ"
"リース以降の OpenStack で利用できます。 SR-IOV 規格は、PCIe デバイスを仮想化"
"する標準化された仕組みを定義しています。この仕組みを使うと、 1 つの PCIe "
"Ethernet コントローラーを仮想化して、複数の PCIe デバイスのように見せることが"
"できます。各仮想デバイスは、ハイパーバイザーと仮想スイッチの層を経由せずに、"
"直接インスタンスに割り当てることができます。その結果、ユーザーは低遅延とライ"
"ンレートに近い通信速度を得ることができます。"

msgid "PF"
msgstr "PF"

msgid "Performance considerations"
msgstr "性能面の考慮事項"

msgid "Performance impact"
msgstr "性能面での影響"

msgid "Persist created VFs on reboot:"
msgstr "再起動時にも作成 VF が保持されるようにします。"

msgid ""
"Physical Function. The physical Ethernet controller that supports SR-IOV."
msgstr ""
"Physical Function (物理機能)。SR-IOV に対応した物理 Ethernet コントローラーで"
"す。"

msgid "Plug-ins"
msgstr "プラグイン"

msgid ""
"Plugs and unplugs ports, creates networks or subnets, and provides IP "
"addressing. The chosen plug-in and agents differ depending on the vendor and "
"technologies used in the particular cloud. It is important to mention that "
"only one plug-in can be used at a time."
msgstr ""
"ポートの接続と抜去、ネットワークとサブネットの作成、IP アドレスの割り当てを行"
"います。選択したプラグインは、そのクラウドで使用されるベンダーや技術により異"
"なります。大事なのは、同時には 1 つのプラグインしか使用できないことです。"

msgid "Pool"
msgstr "プール"

msgid "Port chain"
msgstr "ポートチェイン (port chain)"

msgid "Port pair"
msgstr "ポートペア (port_pair)"

msgid "Port pair group"
msgstr "ポートペアグループ (port pair group)"

msgid "Port pair: [p1, p2]"
msgstr "ポートペア: [p1, p2]"

msgid "Port pair: [p3, p4]"
msgstr "ポートペア: [p3, p4]"

msgid "Port pair: [p5, p6]"
msgstr "ポートペア: [p5, p6]"

msgid "Ports"
msgstr "ポート"

msgid "Ports can be created with a policy attached to them too."
msgstr "ポート作成時に QoS ポリシーを関連付けることもできます。"

msgid ""
"Pre-Mitaka address scopes are not visible through the API. You cannot list "
"address scopes or show details. Scopes exist implicitly as a catch-all for "
"addresses that are not explicitly scoped."
msgstr ""
"Mitaka リリース以前用のアドレススコープは API 経由では見えません。このスコー"
"プはアドレススコープの一覧には出て来ませんし、詳細を見ることもできません。こ"
"のスコープは、明示的にスコープが指定されていないすべてのアドレスを暗黙のうち"
"に収容するためだけに存在します。"

msgid "Prefix advertisement"
msgstr "プレフィックス広告"

msgid "Prefix delegation"
msgstr "Prefix delegation (プレフィックス移譲)"

msgid ""
"Prefix delegation became available in the Liberty release, it is not "
"available in the Kilo release. HA and DVR routers are not currently "
"supported by this feature."
msgstr ""
"prefix delegation が利用できるようになったのは Liberty リリースです。Kilo リ"
"リースでは利用できません。 HA ルーターと DVR ルーターは現時点ではこの機能に対"
"応していません。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Prerequisites"
msgstr "前提"

msgid "Prerequisites for demonstration"
msgstr "デモの前提条件"

msgid "Preventing regular users from sharing objects with each other"
msgstr "通常ユーザー同士のオブジェクトの共有をさせたくない場合"

msgid ""
"Project network configurations are made in the ``/etc/neutron/plugins/ml2/"
"ml2_conf.ini`` configuration file on the neutron server:"
msgstr ""
"プロジェクトネットワークの設定は、 neutron サーバーの ``/etc/neutron/plugins/"
"ml2/ml2_conf.ini`` ファイルで行われます。"

msgid "Project network types"
msgstr "プロジェクトネットワーク種別"

msgid "Project resources created by auto-allocation"
msgstr "自動割り当てで作成されるプロジェクトのリソース"

msgid "Proprietary (vendor)"
msgstr "プロプライエタリティ (ベンダー)"

msgid "Provider network (VLAN)"
msgstr "プロバイダーネットワーク (VLAN)"

msgid "Provider network 1 (VLAN)"
msgstr "プロバイダーネットワーク 1 (VLAN)"

msgid "Provider network 2 (VLAN)"
msgstr "プロバイダーネットワーク 2 (VLAN)"

msgid "Provider network types"
msgstr "プロバイダーネットワーク種別"

msgid "Provider networks"
msgstr "プロバイダーネットワーク"

msgid "Provides API, manages database, etc."
msgstr "API を提供する、データベースを管理する、など"

msgid "Provides layer 2/3 connectivity to instances"
msgstr "レイヤー 2/3 の接続性をインスタンスに提供する"

msgid "QEMU 2.1.0"
msgstr "QEMU 2.1.0"

msgid "QEMU 2.5"
msgstr "QEMU 2.5"

msgid "QLogic"
msgstr "QLogic"

msgid ""
"QoS currently works with ml2 only (SR-IOV, Open vSwitch, and linuxbridge are "
"drivers that are enabled for QoS in Mitaka release)."
msgstr ""
"現時点では QoS は ML2 でのみ動作します (Mitaka リリースでは QoS が有効なドラ"
"イバーは SR-IOV、 Open vSwitch、 Linux ブリッジです)。"

msgid ""
"QoS is an advanced service plug-in. QoS is decoupled from the rest of the "
"OpenStack Networking code on multiple levels and it is available through the "
"ml2 extension driver."
msgstr ""
"QoS はサービスプラグインです。 QoS は OpenStack Networking の他のコードから"
"様々なレベルで疎結合になっており、ML2 extension ドライバー経由で利用可能に"
"なっています。"

msgid ""
"QoS is defined as the ability to guarantee certain network requirements like "
"bandwidth, latency, jitter, and reliability in order to satisfy a Service "
"Level Agreement (SLA) between an application provider and end users."
msgstr ""
"QoS は、帯域、遅延、ジッター、信頼性などのある種のネットワーク要件を保証する"
"機能で、アプリケーションプロバイダーとユーザー間のサービスレベル合意 (SLA) を"
"満たすために使用されます。"

msgid "Quality of Service (QoS)"
msgstr "QoS (Quality of Service)"

msgid "Quotas"
msgstr "クォータ"

msgid ""
"Quotas are available for limiting the number of load balancers and load "
"balancer pools. By default, both quotas are set to 10."
msgstr ""
"クォータを使って、ロードバランサー数とロードバランサープール数を制限すること"
"ができます。デフォルトでは、どちらのクォータも 10 に設定されます。"

msgid "RO"
msgstr "RO"

msgid "RW(POST only)"
msgstr "RW (POST のみ)"

msgid "Re-enable the hypervisor."
msgstr "ハイパーバイザーを有効に戻します。"

msgid ""
"Reboot the hypervisor (or run \"smart\" live transition tool if available)."
msgstr ""
"ハイパーバイザーを再起動します (もしくは「賢い」動かしたまま移行できるツール"
"があればそれを実行します)。"

msgid "Reference Implementation"
msgstr "参照実装"

msgid "Reference implementations"
msgstr "参照実装"

msgid "Reference implementations and other agents"
msgstr "参照実装のそれ以外のエージェント"

msgid "References"
msgstr "参考資料"

msgid "Referencing a subnet pool during subnet creation"
msgstr "サブネット作成時にサブネットプールを指定する"

msgid ""
"Regardless of address scopes, the floating IPs can be pinged from the "
"external network:"
msgstr ""
"アドレススコープに関係なく、 Floating IP には外部ネットワークから ping が可能"
"です。"

msgid "Regular port creation permissions on networks (since Liberty)."
msgstr "ネットワークに通常のポートを作成する許可 (Liberty 以降)"

msgid "Remove a network from a specified DHCP agent."
msgstr "ネットワークを指定した DHCP エージェントから削除します。"

msgid "Remove a tag from a resource:"
msgstr "リソースからタグを削除します。"

msgid ""
"Replace ``DNS_RESOLVER`` with the IP address of a DNS resolver reachable "
"from all virtual networks. For example:"
msgstr ""
"``DNS_RESOLVER`` は、すべての仮想ネットワークから到達可能な DNS レゾルバーの "
"IP アドレスで置き換えてください。例:"

msgid ""
"Replace ``DNS_RESOLVER`` with the IP address of a DNS resolver reachable "
"from the virtual network and ``SUBNET_ID_OR_NAME`` with the UUID or name of "
"the subnet. For example, using the ``selfservice`` subnet:"
msgstr ""
"``DNS_RESOLVER`` は仮想ネットワークから到達可能な DNS レゾルバーの IP アドレ"
"スで、 ``SUBNET_ID_OR_NAME`` はサブネットの UUID か名前で置き換えてください。"
"例えば、 ``selfservice`` サブネットを使用する場合:"

msgid ""
"Replace ``DNS_RESOLVER`` with the IP address of a DNS resolver reachable "
"from the virtual network. For example:"
msgstr ""
"``DNS_RESOLVER`` は仮想ネットワークから到達可能な DNS レゾルバーの IP アドレ"
"スで置き換えてください。例:"

msgid ""
"Replace ``INTERFACE_DRIVER`` with the interface driver that the layer-2 "
"agent in your environment uses. For example, ``openvswitch`` for Open "
"vSwitch or ``linuxbridge`` for Linux bridge."
msgstr ""
"``INTERFACE_DRIVER`` は、お使いの環境のレイヤー 2 エージェントが使用するイン"
"ターフェースドライバーに置き換えます。例えば、 Open vSwitch の場合は "
"``openvswitch`` 、 Linux ブリッジの場合は ``linuxbridge`` です。"

msgid ""
"Replace ``LOCAL_AS`` with an appropriate local autonomous system number. The "
"example configuration uses AS 1234."
msgstr ""
"``LOCAL_AS`` は、適切なローカル AS 番号 (autonomous system number) に置き換え"
"てください。設定例では AS 1234 を使っています。"

msgid ""
"Replace ``MIN_VXLAN_ID`` and ``MAX_VXLAN_ID`` with  VXLAN ID minimum and "
"maximum values suitable for your environment."
msgstr ""
"``MIN_VXLAN_ID``, ``MAX_VXLAN_ID`` は、お使いの環境に応じた VXLAN ID の最小"
"値、最大値に置き換えてください。"

msgid ""
"Replace ``P1_ID``, ``P2_ID``, ``P3_ID``, ``P4_ID``, ``P5_ID``, and ``P6_ID`` "
"with the UUIDs of the respective ports."
msgstr ""
"``P1_ID``, ``P2_ID``, ``P3_ID``, ``P4_ID``, ``P5_ID``, ``P6_ID`` は、それぞれ"
"のポートの UUID に置き換えてください。"

msgid ""
"Replace ``PROVIDER_INTERFACE`` with the name of the underlying interface "
"that handles provider networks. For example, ``eth1``."
msgstr ""
"``PROVIDER_INTERFACE`` は、 プロバイダーネットワークを処理するインターフェー"
"ス名で置き換えます。例えば、 ``eth1`` など。"

msgid ""
"Replace ``REMOTE_AS`` with an appropriate remote autonomous system number. "
"The example configuration uses AS 4321 which triggers EBGP peering."
msgstr ""
"``REMOTE_AS`` は、適切なリモート AS 番号 (autonomous system number) に置き換"
"えてください。設定例では AS 4321 を使用し、 EBGP ピアリングで接続されます。"

msgid ""
"Replace ``ROUTER_ID`` with a suitable unique 32-bit number, typically an "
"IPv4 address on the host running the agent. For example, 192.0.2.2."
msgstr ""
"``ROUTER_ID`` は、適切な一意な 32 ビットの数字に置き換えます。通常は、エー"
"ジェントが動作しているホストの IPv4 アドレスを使います。例: 192.0.2.2。"

msgid ""
"Replace ``TUNNEL_INTERFACE_IP_ADDRESS`` with the IP address of the interface "
"that handles VXLAN project networks."
msgstr ""
"``TUNNEL_INTERFACE_IP_ADDRESS`` は、VXLAN プロジェクトネットワークを扱うイン"
"ターフェースの IP アドレスに置き換えます。"

msgid "Replace all tags on the resource:"
msgstr "リソースのタグをすべて置き換えます。"

msgid "Required"
msgstr "必須"

msgid "Required extensions"
msgstr "必要な拡張機能"

msgid "Requirements"
msgstr "要件"

msgid "Resource"
msgstr "リソース"

msgid "Resource purge"
msgstr "リソースの一括削除"

msgid "Resource tags"
msgstr "リソースタグ"

msgid "Resources"
msgstr "リソース"

msgid "Restart Apache to activate the new panel:"
msgstr "Apache を再起動して、新しいパネルを有効にします。"

msgid ""
"Restart the Network service to activate the new configuration. You are now "
"ready to create and manage load balancers with Octavia."
msgstr ""
"新しい設定を有効にするために Network サービスを再起動してください。この時点"
"で Octavia でロードバランサーを作成できるようになります。"

msgid ""
"Restart the Network service to activate the new configuration. You are now "
"ready to create load balancers with the LBaaS v2 agent."
msgstr ""
"新しい設定を有効にするために Network サービスを再起動してください。この時点"
"で LBaaS v2 エージェントでロードバランサーを作成できるようになります。"

msgid "Restart the ``neutron-server`` service."
msgstr "``neutron-server`` サービスを再起動します。"

msgid "Restart the ``nova-compute`` service for the changes to go into effect."
msgstr "``nova-compute`` サービスを再起動し、変更を反映します。"

msgid "Restart the ``nova-scheduler`` service."
msgstr "``nova-scheduler`` サービスを再起動します。"

msgid "Restart the following services:"
msgstr "以下のサービスを再起動します。"

msgid "Result"
msgstr "結果"

msgid "Retrieving load balancer statistics"
msgstr "ロードバランサーの統計情報の取得"

msgid "Return traffic follows similar steps in reverse."
msgstr "戻りのトラフィックは、同様の手順の逆順で処理されます。"

msgid "Role-Based Access Control (RBAC)"
msgstr "ロールベースアクセス制御 (RBAC)"

msgid "Router 1 contains IP addresses 203.0.113.11 and 10.0.1.1."
msgstr "ルーター 1 は IP アドレス 203.0.113.11 と 10.0.1.1 を持ちます。"

msgid "Router 2 contains IP addresses 203.0.113.12 and 10.0.2.1."
msgstr "ルーター 2 は IP アドレス 203.0.113.12 と 10.0.2.1 を持ちます。"

msgid "Router 3 contains IP addresses 203.0.113.13 and 10.0.3.1."
msgstr "ルーター 3 は IP アドレス 203.0.113.13 と 10.0.3.1 を持ちます。"

msgid "Router advertisements"
msgstr "ルーター広告 (Router Advertisements)"

msgid "Router interfaces"
msgstr "ルーターインターフェース"

msgid "Router scheduler"
msgstr "ルータースケジューラー"

msgid "Router support"
msgstr "ルーターのサポート"

# #-#-#-#-#  intro_networking_components.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_overview.pot (Networking Guide 0.9)
# #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Routers"
msgstr "ルーター"

msgid ""
"Routers are special devices that enable packets to travel from one layer-3 "
"network to another. Routers enable communication between two nodes on "
"different layer-3 networks that are not directly connected to each other. "
"Routers operate at layer-3 in the networking model. They route the traffic "
"based on the destination IP address in the packet header."
msgstr ""
"ルーターは、パケットをあるレイヤー 3 ネットワークから別のレイヤー 3 ネット"
"ワークへ転送できる特別なデバイスです。ルーターにより、互いに直接接続されてい"
"ない異なるレイヤー 3 ネットワーク上の 2 ノード間での通信が可能になります。"
"ルーターはネットワークモデルの第 3 層として動作します。トラフィックは、パケッ"
"トヘッダーの宛先 IP アドレスに基いてルーティングされます。"

msgid "Routing directly to a project network from an external network."
msgstr "外部ネットワークからプロジェクトネットワークへの直接のルーティング。"

msgid "Routing services"
msgstr "ルーティングサービス"

msgid "Routing with address scopes for non-privileged users"
msgstr "非特権ユーザーでのアドレススコープによるルーティング"

msgid "Rule modification"
msgstr "ルールの変更"

msgid "Run InfiniBand subnet managers to enable InfiniBand fabric."
msgstr ""
"InfiniBand サブネットマネージャーを実行し、 InfiniBand ファブリックを有効にし"
"ます。"

msgid "Run ``udhcpc`` in the VM; it cannot get the wanted IP."
msgstr "VM 内で ``udhcpc`` を実行します。 VM は所望の IP を取得できません。"

msgid ""
"Run a DB dump/restore tool that creates Networking data structures "
"representing current legacy networking config."
msgstr ""
"DB のダンプ/リストアツールを使って、現在のレガシーネットワークの設定に対応す"
"る Networking のデータ構造を作成します。"

msgid "Run a DHCP client in VM to see if it can get the wanted IP."
msgstr ""
"VM で DHCP クライアントを実行し、所望の IP が取得できるかを確認します。"

msgid "Run the ``neutron-lbaas`` database migration:"
msgstr "``neutron-lbaas`` のデータベース移行スクリプトを実行します。"

msgid "Runs ``nova-compute``, the Neutron L2 agent and DHCP agent"
msgstr ""
"`nova-compute` と Neutron L2 エージェント、 DHCP エージェントが動作します。"

msgid ""
"Runs the Networking, Identity, and Compute services that are required to "
"deploy VMs. The node must have at least one network interface that is "
"connected to the Management Network. Note that ``nova-network`` should not "
"be running because it is replaced by Neutron."
msgstr ""
"VM をデプロイするのに必要な Networking, Identity, Compute サービスが動作しま"
"す。このノードにはネットワークインターフェースが 少なくとも 1 つ必要で、管理"
"ネットワークに接続します。   ``nova-network`` は Neutron で置き換えられるの"
"で、このノードで ``nova-network`` は動作させないでください。"

msgid ""
"SFC performs load balancing/distribution over the additional service "
"functions in the port pair group."
msgstr ""
"SFC は、ポートペアグループに新たに追加されたサービス機能に負荷の分散を行いま"
"す。"

msgid ""
"SFC steers traffic matching the additional flow classifier to the port pair "
"groups in the port chain."
msgstr ""
"SFC は、追加された Flow Classifier に一致したトラフィックを、ポートチェインの"
"ポートペアグループに転送します。"

msgid "SLAAC"
msgstr "SLAAC"

msgid "SNAT"
msgstr "SNAT"

msgid ""
"SNAT solves this problem by modifying the source IP address to an IP address "
"that is routable on the public Internet. There are different variations of "
"SNAT; in the form that OpenStack deployments use, a NAT router on the path "
"between the sender and receiver replaces the packet's source IP address with "
"the router's public IP address. The router also modifies the source TCP or "
"UDP port to another value, and the router maintains a record of the sender's "
"true IP address and port, as well as the modified IP address and port."
msgstr ""
"SNAT は、送信元 IP アドレスをパブリックなインターネットから到達可能な IP アド"
"レスに変更することで、この問題を解決します。 SNAT にはいくつかの種類がありま"
"す。 OpenStack デプロイメントで使用されている形では、 送信者と受信者間の経路"
"上にある NAT ルーターが、パケットの送信元 IP アドレスをルーターのパブリック "
"IP アドレスに変更します。このルーターは送信元の TCP や UDP のポート番号も別の"
"値に変更し、ルーターは、送信元の実際の IP アドレスとポートと、変更後の IP ア"
"ドレスとポートの情報を管理します。"

msgid "SR-IOV"
msgstr "SR-IOV"

msgid "SR-IOV agent"
msgstr "SR-IOV エージェント"

msgid ""
"SR-IOV is not integrated into the OpenStack Dashboard (horizon). Users must "
"use the CLI or API to configure SR-IOV interfaces."
msgstr ""
"OpenStack Dashboard (horizon) は SR-IOV に対応していません。ユーザーは CLI "
"や API を使って SR-IOV インターフェースを設定する必要があります。"

msgid "SR-IOV with InfiniBand"
msgstr "InfiniBand を用いた SR-IOV"

msgid "SRIOV"
msgstr "SRIOV"

msgid "SRIOV & SRIOV nic switch agent"
msgstr "SRIOV & SRIOV NIC スイッチエージェント"

msgid "SRIOV Nic Switch agent"
msgstr "SRIOV NIC スイッチエージェント"

msgid "SRIOV mechanism driver and SRIOV NIC switch agent"
msgstr "SRIOV メカニズムドライバーと SRIOV NIC スイッチエージェント"

msgid "SRIOV nic switch agent"
msgstr "SRIOV NIC スイッチエージェント"

msgid "Same as HostA"
msgstr "HostA と同じ。"

msgid "Schedule BGP speaker to multiple agents."
msgstr "BGP スピーカーを複数のエージェントにスケジューリングします。"

msgid "Schedule the BGP speaker to an agent"
msgstr "BGP スピーカーのエージェントへのスケジューリング"

msgid ""
"Second, subnet pools can manage addresses across projects. The addresses are "
"guaranteed not to overlap. If the addresses come from an externally routable "
"pool then you know that all of the projects have addresses which are "
"*routable* and unique. This can be useful in the following scenarios."
msgstr ""
"2 つめとして、サブネットプールはプロジェクトにまたがってアドレスを管理できま"
"す。アドレスは重複しないことが保証されます。アドレスが外部から到達可能なプー"
"ルから割り当てられた場合、すべてのプロジェクトが *外部から到達可能* で一意な"
"アドレスを持つことになります。この機能は以下のシナリオで有用です。"

msgid "Security"
msgstr "セキュリティー"

msgid "Security Groups"
msgstr "セキュリティーグループ"

msgid "Security considerations"
msgstr "セキュリティーの考慮事項"

msgid "Security groups"
msgstr "セキュリティーグループ"

msgid ""
"Security groups are not supported when using SR-IOV, thus, the firewall "
"driver must be disabled. This can be done in the ``neutron.conf`` file."
msgstr ""
"SR-IOV を使用する場合、セキュリティーグループはサポートされていません。した"
"がって、ファイアウォールドライバーは無効にする必要があります。この設定は "
"``neutron.conf`` ファイルで行えます。"

msgid ""
"See :ref:`config-dns-int-ext-serv` for detailed instructions on how to "
"create the externally accessible network."
msgstr ""
"外部からアクセス可能なネットワークを作成する詳細な手順は :ref:`config-dns-"
"int-ext-serv` を参照してください。"

msgid ""
"See :ref:`config-dns-performance-considerations` for an explanation of the "
"potential performance impact associated with this use case."
msgstr ""
"このユースケースでの潜在的な性能面への影響については :ref:`config-dns-"
"performance-considerations` を参照してください。"

msgid "See :ref:`config-subnet-pools` for more information."
msgstr "詳しい情報は :ref:`config-subnet-pools` を参照してください。"

msgid ""
"Select the driver that manages virtual interfaces in ``/etc/neutron/"
"lbaas_agent.ini``:"
msgstr ""
"``/etc/neutron/lbaas_agent.ini`` で仮想インターフェースを管理するドライバーを"
"設定します。"

msgid "Self-service network 1 (VXLAN)"
msgstr "セルフサービスネットワーク1(VXLAN)"

msgid "Self-service network 2 (VXLAN)"
msgstr "セルフサービスネットワーク2(VXLAN)"

msgid ""
"Self-service network 3 uses a unique IP address range 10.0.3.0/24 to "
"demonstrate that the BGP speaker does not advertise prefixes outside of "
"address scopes."
msgstr ""
"セルフサービスネットワーク 3 は、独自の IP アドレス範囲 10.0.3.0/24 を使用し"
"ます。これを用いて、 BGP スピーカーがアドレススコープ外のプレフィックスを広告"
"しないことを確認します。"

msgid ""
"Self-service networks 1 and 2 use IP address ranges inside of the address "
"scope."
msgstr ""
"セルフサービスネットワーク 1 と 2 は、アドレススコープ内の IP アドレス範囲を"
"使用します。"

msgid "Self-service router"
msgstr "セルフサービスルーター"

# #-#-#-#-#  config_server.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_service.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Server"
msgstr "サーバー"

msgid "Service and component hierarchy"
msgstr "サービスとコンポーネントの構造"

msgid "Service function chaining"
msgstr "Service Function Chaining"

msgid "Service subnets"
msgstr "サービスサブネット"

msgid ""
"Service subnets enable operators to define valid port types for each subnet "
"on a network without limiting networks to one subnet or manually creating "
"ports with a specific subnet ID. Using this feature, operators can ensure "
"that ports for instances and router interfaces, for example, always use "
"different subnets."
msgstr ""
"サービスサブネットを使用すると、運用者がネットワーク上の各サブネットに対して"
"有効なポート種別を定義できるようになります。これにより、ネットワークに作成す"
"るサブネットを 1 つに限定したり、特定のサブネット ID を指定してポートを手動で"
"作成したりする必要がなくなります。この機能を使うと、運用者は、例えば、インス"
"タンス用のポートとルーターインターフェース用のポートが常に別のサブネットを使"
"用するようにできます。"

msgid "Services"
msgstr "サービス"

msgid ""
"Set ``AZAwareWeightScheduler`` to ``network_scheduler_driver`` in ``/etc/"
"neutron/neutron.conf`` so that the Networking service schedules a network "
"according to the availability zone:"
msgstr ""
"``/etc/neutron/neutron.conf`` で ``network_scheduler_driver`` に "
"``AZAwareWeightScheduler`` を設定すると、 Networking サービスはアベイラビリ"
"ティーゾーンに基いてネットワークの割り当てを行います。"

msgid ""
"Set ``AZLeastRoutersScheduler`` to ``router_scheduler_driver`` in file ``/"
"etc/neutron/neutron.conf`` so that the Networking service schedules a router "
"according to the availability zone:"
msgstr ""
"``/etc/neutron/neutron.conf`` で ``router_scheduler_driver`` に "
"``AZLeastRoutersScheduler`` を設定すると、 Networking サービスはアベイラビリ"
"ティーゾーンに基いてルーターの割り当てを行います。"

msgid ""
"Set the \"has_transitioned\" flag in the Compute hypervisor database/config."
msgstr ""
"Compute のハイパーバイザーデータベース/設定に \"has_transitioned\" フラグを"
"セットします。"

msgid "Set the ``ha`` attribute of the router to ``True``."
msgstr "ルーターの ``ha`` 属性を ``True`` に設定します。"

msgid ""
"Set the admin_state_up to ``False``. This will severe south-north "
"connections until admin_state_up is set to ``True`` again."
msgstr ""
"admin_state_up を ``False`` に設定します。これを行うと、もう一度 "
"admin_state_up を ``True`` に戻すまで、south-north コネクションは切断されま"
"す。"

msgid ""
"Set the admin_state_up to ``True``. After this, south-north connections can "
"start."
msgstr ""
"admin_state_up を ``True`` に設定します。これ以降は south-north コネクション"
"が開始できます。"

msgid ""
"Set the following configuration options in file ``/etc/neutron/neutron."
"conf`` so that you get DHCP high availability."
msgstr ""
"DHCP の高可用性を実現するには ``/etc/neutron/neutron.conf`` で以下のオプショ"
"ンを設定します。"

msgid ""
"Set the following configuration options in file ``/etc/neutron/neutron."
"conf`` so that you get L3 high availability."
msgstr ""
"L3 の高可用性を実現するには ``/etc/neutron/neutron.conf`` で以下のオプション"
"を設定します。"

msgid "Set up a default external network"
msgstr "デフォルトの外部ネットワークを用意します"

msgid ""
"Setting ``ipv6_ra_mode`` to ``slaac`` will result in OpenStack Networking "
"routers being configured to send RA packets, when they are created. This "
"results in the following values set for the address configuration flags in "
"the RA messages:"
msgstr ""
"``ipv6_ra_mode`` を ``slaac`` に設定すると、 OpenStack Networking のルーター"
"はルーター作成時に RA パケットを送信するように設定されます。 RA メッセージの"
"アドレス設定フラグは以下の値に設定されます。"

msgid "Setting quotas for LBaaS v2"
msgstr "LBaaS v2 のクォータの設定"

msgid ""
"Setting up an external network is described in `OpenStack Administrator "
"Guide <https://docs.openstack.org/admin-guide/networking-adv-features."
"html>`_. Assuming the external network to be used for the auto-allocation "
"feature is named ``public``, make it the default external network with the "
"following command:"
msgstr ""
"外部ネットワークの設定は `OpenStack Administrator Guide <https://docs."
"openstack.org/admin-guide/networking-adv-features.html>`_ で説明されていま"
"す。自動割り当て機能に使用される外部ネットワークの名前が ``public`` とする"
"と、以下のコマンドを実行し、このネットワークをデフォルトの外部ネットワークに"
"します。"

msgid "Sharing a QoS policy with specific projects"
msgstr "特定のプロジェクトとの QoS ポリシーの共有"

msgid "Sharing a network with specific projects"
msgstr "特定のプロジェクトとのネットワークの共有"

msgid ""
"Sharing an object with a specific project is accomplished by creating a "
"policy entry that permits the target project the ``access_as_shared`` action "
"on that object."
msgstr ""
"特定のプロジェクトとのオブジェクトを共有するには、アクセスを許可したいプロ"
"ジェクトに対してそのオブジェクトへの ``access_as_shared`` アクションを許可す"
"るポリシーエントリーを作成します。"

msgid "Sharing an object with specific projects"
msgstr "特定のプロジェクトとのオブジェクトの共有"

msgid "Show agent details."
msgstr "エージェントの詳細を表示します。"

msgid "Show available dynamic routing agents."
msgstr "利用可能な動的ルーティングエージェントを表示します。"

msgid ""
"Similar to legacy HA routers, DVR/SNAT HA routers provide a quick fail over "
"of the SNAT service to a backup DVR/SNAT router on an l3-agent running on a "
"different node."
msgstr ""
"従来の HA ルーターと同じく、 DVR/SNAT HA ルーターでは SNAT サービスが別のノー"
"ドで動作する L3 エージェントのバックアップ DVR/SNAT HA ルーターに迅速にフェー"
"ルオーバーされます。"

msgid ""
"Similar to the classic scenario, all network traffic on a project network "
"that requires routing actively traverses only one network node regardless of "
"the quantity of network nodes providing HA for the router. Therefore, this "
"high-availability implementation primarily addresses failure situations "
"instead of bandwidth constraints that limit performance. However, it "
"supports random distribution of routers on different network nodes to reduce "
"the chances of bandwidth constraints and to improve scaling."
msgstr ""
"基本構成と同様、ルーターに HA を提供するネットワークノードの数に関わらず、"
"ルーティングが必要なプロジェクトネットワークのすべてのネットワークトラフィッ"
"クは 1 台のネットワークノードを通ります。したがって、この高可用性シナリオは、"
"主として、性能限界となる帯域制約ではなく、障害状況への対策になります。しかし"
"ながら、別のネットワークノードにルーターをランダムに分散させることができるの"
"で、帯域制約が発生する可能性は減少し、スケーラビリティーが向上することでしょ"
"う。"

msgid ""
"Similarly, when the ``l3_ha = True`` flag is configured, routers created by "
"all users default to HA."
msgstr ""
"同様に、 ``l3_ha = True`` フラグが設定されると、すべてのユーザーが作成する"
"ルーターがデフォルトで HA ルーターになります。"

msgid ""
"Since Liberty, Networking maintains two parallel Alembic migration branches."
msgstr ""
"Liberty 以降、 Networking サービスでは 2 つの独立した Alembic の移行ブランチ"
"を持っています。"

msgid ""
"Some underlying physical network architectures contain a unique layer-2 "
"network for overlay networks using protocols such as VXLAN and GRE."
msgstr ""
"アンダーレイ物理ネットワークアーキテクチャーによっては、VXLAN や GRE などのプ"
"ロトコルを使うオーバーレイネットワーク用に専用のレイヤー 2 ネットワークを持つ"
"場合があります。"

msgid ""
"Some underlying physical network architectures contain multiple layer-2 "
"networks with different MTU values. You can configure each flat or VLAN "
"provider network in the bridge or interface mapping options of the layer-2 "
"agent to reference a unique MTU value."
msgstr ""
"物理ネットワークアーキテクチャーによっては、アンダーレイ物理ネットワークが "
"MTU が異なる複数のレイヤー 2 ネットワークで構成される場合があります。レイ"
"ヤー 2 エージェントのブリッジマッピングやインターフェースマッピングのオプショ"
"ンで flat/VLAN プロバイダーネットワーク毎に独自の MTU 値を使うように設定でき"
"ます。"

msgid ""
"Sometimes we want to refer to a subnet, but not any particular IP address on "
"the subnet. A common convention is to set the host identifier to all zeros "
"to make reference to a subnet. For example, if a host's IP address is "
"``10.10.53.24/16``, then we would say the subnet is ``10.10.0.0/16``."
msgstr ""
"サブネットを参照したいが、サブネット内の特定の IP アドレスを参照したくはない"
"場合もあります。広く使われている方法は、ホスト識別子を全部 0 にセットして、サ"
"ブネットを参照する方法です。例えば、ホストの IP アドレスが "
"``10.10.53.24/16`` の場合、サブネットは ``10.10.0.0/16`` になります。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Source the administrative project credentials."
msgstr "管理プロジェクトのクレデンシャルを読み込みます。"

msgid "Source the credentials of the project that owns the ``net1`` network."
msgstr "ネットワーク ``net1`` を所有するプロジェクトの認証情報を読み込みます。"

msgid ""
"Source the necessary project credentials. The administrative project can "
"delete resources for all other projects. A regular project can delete its "
"own network resources and those belonging to other projects for which it has "
"sufficient access."
msgstr ""
"必要なプロジェクトの認証情報を読み込みます。管理プロジェクトは、任意の他のプ"
"ロジェクトのリソースを削除できます。通常プロジェクトは、自分自身のネットワー"
"クリソースと、必要なアクセス権を持つ他のプロジェクトのリソースを削除できま"
"す。"

msgid "Specialized"
msgstr "個別事項"

msgid "Start DHCP agent on HostB. The VM gets the wanted IP again."
msgstr ""
"HostB で DHCP エージェントを開始します。 VM は所望の IP アドレスを再び取得で"
"きます。"

msgid ""
"Start by creating a listener, attaching a pool, and then adding members:"
msgstr "リスナーを作成し、プールを接続し、メンバーを追加します。"

msgid ""
"Start by creating a load balancer on a network. In this example, the "
"``private`` network is an isolated network with two web server instances:"
msgstr ""
"まず、ネットワークにロードバランサーを作成します。この例では、 ``private`` "
"ネットワークは分離されたネットワークで、このネットワークには 2 つのサーバーイ"
"ンスタンスがあります。"

msgid ""
"Start neutron-server in intended final config, except with REST API "
"restricted to read-write only by nova-api."
msgstr ""
"neutron-server を最終的な設定内容で開始します。例外は、 REST API が nova-api "
"による読み書きに限定されるという点だけです。"

msgid "Start the LBaaS v2 agent:"
msgstr "LBaaS v2 エージェントを起動します。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Start the following services:"
msgstr "以下のサービスを実行します。"

msgid ""
"Starting with the Liberty release, OpenStack Networking includes a pluggable "
"interface for the IP Address Management (IPAM) function. This interface "
"creates a driver framework for the allocation and de-allocation of subnets "
"and IP addresses, enabling the integration of alternate IPAM implementations "
"or third-party IP Address Management systems."
msgstr ""
"Liberty 以降では、 OpenStack Networking では、IP アドレス管理 (IPAM) 機能に取"
"り換え可能なインターフェースが導入されています。このインターフェースを使っ"
"て、サブネットと IP アドレスの割り当て、解放におけるドライバーフレームワーク"
"が作成されており、別の IPAM 実装や third-party 製の IP アドレス管理システムと"
"統合することが可能です。"

msgid "Stateless Address Auto Configuration (SLAAC)"
msgstr ""
"ステートレスアドレス自動設定 (SLAAC; Stateless Address Auto Configuration)"

msgid ""
"Stop the DHCP agent on HostA. Besides stopping the ``neutron-dhcp-agent`` "
"binary, you must stop the ``dnsmasq`` processes."
msgstr ""
"HostA の DHCP エージェントを停止します。 ``neutron-dhcp-agent`` バイナリーを"
"停止するだけでなく、 ``dnsmasq`` プロセスも停止する必要があります。"

msgid "Stop the DHCP agent on HostB too."
msgstr "HostB の DHCP エージェントも停止します。"

msgid "Subnet pools"
msgstr "サブネットプール"

msgid ""
"Subnet pools have a quota system which is a little bit different than other "
"quotas in Neutron. Other quotas in Neutron count discrete instances of an "
"object against a quota. Each time you create something like a router, "
"network, or a port, it uses one from your total quota."
msgstr ""
"サブネットプールには、 Neutron の他のクォータとは少し違ったクォータ機構があり"
"ます。 Neutron の他のクォータは、あるオブジェクトの個々のインスタンス数を数"
"え、クォータと比較します。ルーター、ネットワーク、ポートなどを作成する度に、"
"自分のクォータから 1 つ消費されます。"

msgid ""
"Subnet pools have been made available since the Kilo release. It is a simple "
"feature that has the potential to improve your workflow considerably. It "
"also provides a building block from which other new features will be built "
"in to OpenStack Networking."
msgstr ""
"サブネットプールは Kilo リリース以降で利用可能です。これは簡単な機能ですが、"
"Networking サービス利用時のワークフローが大きくよくなる可能性があります。ま"
"た、 OpenStack Networking に新しい他の機能を作り込む際の基本的な部品としても"
"使われます。"

msgid "Subnets"
msgstr "サブネット"

msgid "Subnets and ARP"
msgstr "サブネットと ARP"

msgid "Supported Ethernet controllers"
msgstr "対応している Ethernet コントローラー"

msgid "Supported QoS rule types"
msgstr "サポートされている QoS ルール種別"

msgid "Supported objects for sharing with specific projects"
msgstr "特定のプロジェクトとの共有に対応しているオブジェクト"

msgid "Switches"
msgstr "スイッチ"

msgid ""
"Switches are Multi-Input Multi-Output (MIMO) devices that enable packets to "
"travel from one node to another. Switches connect hosts that belong to the "
"same layer-2 network. Switches enable forwarding of the packet received on "
"one port (input) to another port (output) so that they reach the desired "
"destination node. Switches operate at layer-2 in the networking model. They "
"forward the traffic based on the destination Ethernet address in the packet "
"header."
msgstr ""
"スイッチは、複数入力、複数出力 (MIMO; Multi-Input Multi-Output) のデバイス"
"で、スイッチを使うとパケットをあるノードから別のノードに転送できます。スイッ"
"チは同じレイヤー 2 ネットワークに属するホストどうしを接続詞ます。スイッチは、"
"あるポート (入力) で受信したパケットを別のポート (出力) に転送し、所望の宛先"
"ノードにパケットを届けることができます。スイッチはネットワークモデルの第 2 層"
"として動作します。スイッチはパケットヘッダーの宛先 Ethernet アドレスに基いて"
"トラフィックを転送します。"

msgid "TCP/UDP/ICMP"
msgstr "TCP/UDP/ICMP"

msgid "TODO"
msgstr "TODO"

msgid "Term"
msgstr "用語"

msgid ""
"The *Internet Control Message Protocol* (ICMP) is a protocol used for "
"sending control messages over an IP network. For example, a router that "
"receives an IP packet may send an ICMP packet back to the source if there is "
"no route in the router's routing table that corresponds to the destination "
"address (ICMP code 1, destination host unreachable) or if the IP packet is "
"too large for the router to handle (ICMP code 4, fragmentation required and "
"\"don't fragment\" flag is set)."
msgstr ""
"*Internet Control Message Protocol* (ICMP) は、 IP ネットワーク上で制御メッ"
"セージを送信するのに使用されるプロトコルです。例えば、IP パケットを受信した"
"ルーターは、宛先アドレスに対応する経路がルーターのルーティングテーブルにない"
"場合は、ICMP パケットを送信元に送ります (ICMP コード 1、宛先ホスト到達不能)。"
"また、 IP パケットが大きすぎて、そのルーターでは処理できない場合にも、ICMP パ"
"ケットを送信元に送ります (ICMP コード 4、フラグメンテーションが必要だが "
"\"don't fragment\" (フラグメント禁止) フラグがセットされている)。"

msgid ""
"The *Transmission Control Protocol* (TCP) is the most commonly used layer 4 "
"protocol in networked applications. TCP is a *connection-oriented* protocol: "
"it uses a client-server model where a client connects to a server, where "
"*server* refers to the application that receives connections. The typical "
"interaction in a TCP-based application proceeds as follows:"
msgstr ""
"*Transmission Control Protocol* (TCP) は、ネットワークアプリケーションで最も"
"広く使用されているレイヤー 4 プロトコルです。 TCP は *接続志向* (connection-"
"oriented) のプロトコルで、クライアントがサーバーに接続するクライアント～サー"
"バーモデルを使用します。ここで、 *サーバー* というのは接続を受信するアプリ"
"ケーションのことです。 TCP を使うアプリケーションでの一般的なやり取りは次の通"
"りです。"

msgid ""
"The *User Datagram Protocol* (UDP) is another layer 4 protocol that is the "
"basis of several well-known networking protocols. UDP is a *connectionless* "
"protocol: two applications that communicate over UDP do not need to "
"establish a connection before exchanging data. UDP is also an *unreliable* "
"protocol. The operating system does not attempt to retransmit or even detect "
"lost UDP packets. The operating system also does not provide any guarantee "
"that the receiving application sees the UDP packets in the same order that "
"they were sent in."
msgstr ""
"*User Datagram Protocol* (UDP) は、いくつかの有名なネットワークプロトコルで使"
"われている別のレイヤー 4 プロトコルです。 UDP は *コネクションレス* プロトコ"
"ルです。 UDP を使って通信する  2 つのアプリケーションは、データのやり取りを行"
"う前にコネクションを確立する必要がありません。オペレーティングシステムは、失"
"われた UDP パケットの再送を行いませんし、検出さえ行いません。オペレーティング"
"システムは、UDP パケットが送信されたときと同じ順序で受信側のアプリケーション"
"に見えるという保証も行いません。"

msgid ""
"The :command:`ping` and :command:`mtr` Linux command-line tools are two "
"examples of network utilities that use ICMP."
msgstr ""
"Linux のコマンドラインツール :command:`ping` や :command:`mtr` は、 ICMP を使"
"うネットワークユーティリティーの例です。"

msgid ""
"The API allows searching/filtering of the ``GET /v2.0/networks`` API. The "
"following query parameters are supported:"
msgstr ""
"この API では、 ``GET /v2.0/networks`` API で検索やフィルタリングが可能です。"
"以下の問い合わせパラメーターが使用できます。"

msgid ""
"The BGP speaker advertises the next-hop IP address for eligible self-service "
"networks and floating IP addresses for instances using those networks."
msgstr ""
"BGP スピーカーは、要件を満たすセルフサービスネットワークおよびそれらのネット"
"ワークに接続されたインスタンスの Floating IP アドレスに対するネクストホップを"
"広告します。"

msgid ""
"The BGP speaker associates with the external network that provides a gateway "
"on the router."
msgstr ""
"BGP スピーカーが、ルーターのゲートウェイを提供する外部ネットワークに関連付け"
"られている。"

msgid ""
"The BGP speaker has the ``advertise_floating_ip_host_routes`` attribute set "
"to ``True``."
msgstr ""
"BGP スピーカーの ``advertise_floating_ip_host_routes`` が ``True`` に設定され"
"ている。"

msgid ""
"The BGP speaker has the ``advertise_tenant_networks`` attribute set to "
"``True``."
msgstr ""
"BGP スピーカーの ``advertise_tenant_networks`` 属性が ``True`` に設定されてい"
"る。"

msgid ""
"The Compute REST API is available throughout the entire process, although "
"there is a brief period where it is made read-only during a database "
"migration. The Networking REST API will need to expose (to nova-api) all "
"details necessary for reconstructing the information previously held in the "
"legacy networking database."
msgstr ""
"Compute REST API は移行中全体を通じて利用できますが、データベースの移行中の短"
"い期間だけは読み出し専用になります。 Networking REST API は、レガシーネット"
"ワークの DB に格納されていた情報を再構築するのに必要な前情報を (nova-api に) "
"公開する必要があります。"

msgid ""
"The DHCP agent is responsible for :term:`DHCP <Dynamic Host Configuration "
"Protocol (DHCP)>` and RADVD (Router Advertisement Daemon) services. It "
"requires a running L2 agent on the same node."
msgstr ""
"DHCP エージェントは、 :term:`DHCP <Dynamic Host Configuration Protocol "
"(DHCP)>` と RADVD (Router Advertisement Daemon) サービスを担当します。 L2 "
"エージェントもあわせて動作させる必要があります。"

msgid ""
"The Dashboard panels for managing LBaaS v2 are available starting with the "
"Mitaka release."
msgstr ""
"Mitaka リリース以降では、 LBaaSv2 を管理するためのダッシュボードパネルが利用"
"できます。"

msgid ""
"The DevStack documentation offers a `simple method to deploy Octavia "
"<https://docs.openstack.org/developer/devstack/guides/devstack-with-lbaas-v2."
"html>`_ and test the service with redundant load balancer instances. If you "
"already have Octavia installed and configured within your environment, you "
"can configure the Network service to use Octavia:"
msgstr ""
"DevStack のドキュメントには、 `Octavia をデプロイする簡単な方法 <https://"
"docs.openstack.org/developer/devstack/guides/devstack-with-lbaas-v2.html>`_ "
"と冗長化したロードバランサーインスタンスを使ったサービスのテストについて書か"
"れています。 Octavia をお使いの環境にすでにインストールして設定している場合"
"は、 Octavia を使うように Network サービスを設定できます。"

msgid ""
"The Firewall-as-a-Service (FWaaS) API is an experimental API that enables "
"early adopters and vendors to test their networking implementations."
msgstr ""
"Firewall-as-a-Service (FWaaS) API は実験的な API で、新しい機能を使う人やベン"
"ダーがネットワーク実装の評価に使っています。"

msgid ""
"The ID returned by this command is a network which can be used for booting a "
"VM."
msgstr "このコマンドが返す ID はネットワークで、VM 起動時に指定できます。"

msgid ""
"The IP address allocation pool starting at ``.11`` improves clarity of the "
"diagrams. You can safely omit it."
msgstr ""
"IP アドレスの割り当てプールが ``.11`` で始まっているのは、説明を分かりやすく"
"するためです。省略しても問題ありません。"

msgid ""
"The Internet Protocol (IP) specifies how to route packets between hosts that "
"are connected to different local networks. IP relies on special network "
"hosts called *routers* or *gateways*. A router is a host that is connected "
"to at least two local networks and can forward IP packets from one local "
"network to another. A router has multiple IP addresses: one for each of the "
"networks it is connected to."
msgstr ""
"インターネットプロトコル (IP) は、異なるローカルネットワークに接続されたホス"
"ト間でパケットをどのようにルーティングするかを規程しています。 IP は*ルーター"
"* や *ゲートウェイ* と呼ばれる特別なネットワークホストを利用します。ルーター"
"は、少なくとも 2 つのローカルネットワークに接続されたホストで、 IP パケットを"
"あるローカルネットワークからもう 1 つのローカルネットワークに転送します。ルー"
"ターは複数の IP アドレスを持ち、それぞれが各々のネットワークに接続されていま"
"す。"

msgid ""
"The L3 agent offers advanced layer 3 services, like virtual Routers and "
"Floating IPs. It requires an L2 agent running in parallel."
msgstr ""
"L3 エージェントは、仮想ルーターや Floating IP などの高度な L3 サービスを提供"
"します。 L2 エージェントもあわせて動作させる必要があります。"

msgid ""
"The L3 metering agent enables layer3 traffic metering. It requires a running "
"L3 agent on the same node."
msgstr ""
"L3 メータリングエージェントは L3 トラフィック計測を可能にします。同じノード"
"で L3 エージェントを実行する必要があります。"

msgid ""
"The Linux bridge agent configures Linux bridges to realize L2 networks for "
"OpenStack resources."
msgstr ""
"Linux ブリッジエージェントは Linux ブリッジの設定を行い、OpenStack リソース用"
"の L2 ネットワークを実現します。"

msgid ""
"The Load-Balancer-as-a-Service (LBaaS) API provisions and configures load "
"balancers. The reference implementation is based on the HAProxy software "
"load balancer."
msgstr ""
"負荷分散サービス (LBaaS) API は、ロードバランサーの払い出しと設定を行います。"
"参照実装は HAProxy ソフトウェアロードバランサーをベースとしています。"

msgid ""
"The MacVTap agent uses kernel MacVTap devices for realizing L2 networks for "
"OpenStack instances. Network attachments for other resources like routers, "
"DHCP, and so on are not supported."
msgstr ""
"macvtap エージェントは、 OpenStack インスタンス用の L2 ネットワークを実現する"
"ために、カーネルの macvtap デバイスを使用します。ルーター、DHCP などのその他"
"のリソースのネットワーク接続には対応していません。"

msgid ""
"The Metadata agent allows instances to access cloud-init meta data and user "
"data via the network. It requires a running L2 agent on the same node."
msgstr ""
"メタデータエージェントは、 cloud-init メタデータやユーザーデータにインスタン"
"スがネットワーク経由でアクセスできるようにします。同じノードで L2 エージェン"
"トを実行する必要があります。"

msgid ""
"The Modular Layer 2 (ML2) neutron plug-in is a framework allowing OpenStack "
"Networking to simultaneously use the variety of layer 2 networking "
"technologies found in complex real-world data centers. The ML2 framework "
"distinguishes between the two kinds of drivers that can be configured:"
msgstr ""
"Modular Layer 2 (ML2) プラグインは、 OpenStack Networking で、複雑な実世界の"
"データセンターで使われている様々な L2 ネットワーク技術を同時に利用できるよう"
"にするフレームワークです。 ML2 フレームワークでは 2 種類のドライバーが区別さ"
"れています。"

msgid ""
"The Networking REST API is publicly read-only until after the migration is "
"complete. During the migration, Networking REST API is read-write only to "
"nova-api, and changes to Networking are only allowed via nova-api."
msgstr ""
"移行が完了するまでは、Networking REST API は公開 API としては読み出し専用にな"
"ります。移行中は、Networking REST API を読み書きできるのは nova-api だけで、"
"Networking への変更ができるのは nova-api 経由だけとなります。"

msgid ""
"The Networking service enables users to control the name assigned to ports "
"by the internal DNS. To enable this functionality, do the following:"
msgstr ""
"Networking サービスでは、内部 DNS によりポートに割り当てられる名前をユーザー"
"が制御できます。この機能を有効にするには、以下のようにします。"

msgid "The Networking service internal DNS resolution"
msgstr "Networking サービス内部の DNS 解決"

msgid ""
"The Networking service offers a load balancer feature called \"LBaaS v2\" "
"through the ``neutron-lbaas`` service plug-in."
msgstr ""
"Networking サービスは、 ``neutron-lbaas`` サービスプラグインとして 、LBaaS "
"v2 と呼ばれるロードバランサー機能を提供しています。"

msgid ""
"The Networking service offers several methods to configure name resolution "
"(DNS) for instances. Most deployments should implement case 1 or 2. Case 3 "
"requires security considerations to prevent leaking internal DNS information "
"to instances."
msgstr ""
"Networking サービスでは、インスタンス用の名前解決を設定する方法が複数ありま"
"す。ほとんどのデプロイメントではケース 1 か 2 が使用されることでしょう。ケー"
"ス 3 を使用する場合は、内部の DNS 情報がインスタンスにもれないようセキュリ"
"ティー面の考慮が必要です。"

msgid ""
"The Networking service only references the underlying physical network MTU. "
"Changing the underlying physical network device MTU requires configuration "
"of physical network devices such as switches and routers."
msgstr ""
"Networking サービスはアンダーレイの物理ネットワークの MTU のみを参照します。"
"アンダーレイの物理ネットワークデバイスの MTU を変更するには、スイッチやルー"
"ターなどの物理ネットワークデバイスの設定が必要です。"

msgid ""
"The Networking service schedules a network to one of the agents within the "
"selected zone as with ``WeightScheduler``. In this case, scheduler refers to "
"``dhcp_load_type`` as well."
msgstr ""
"Networking サービスは、選択されたゾーン内のいずれかのエージェントに "
"``WeightScheduler`` によりネットワークの割り当てを行います。"

msgid ""
"The Networking service schedules a router to one of the agents within the "
"selected zone as with ``LeastRouterScheduler``."
msgstr ""
"Networking サービスは、選択されたゾーン内のいずれかのエージェントに "
"``LeastRouterScheduler`` によりルーターの割り当てを行います。"

msgid ""
"The Networking service supports the following underlying physical network "
"architectures. Case 1 refers to the most common architecture. In general, "
"architectures should avoid cases 2 and 3."
msgstr ""
"Networking サービスは以下のアンダーレイの物理ネットワークアーキテクチャーに対"
"応しています。ケース 1 が最も一般的なアーキテクチャーです。一般には、ケース "
"2 や 3 のアーキテクチャーは避けるべきでしょう。"

msgid ""
"The Networking service supports underlying physical networks using jumbo "
"frames and also enables instances to use jumbo frames minus any overlay "
"protocol overhead. For example, an underlying physical network with a 9000-"
"byte MTU yields a 8950-byte MTU for instances using a VXLAN network with "
"IPv4 endpoints. Using IPv6 endpoints for overlay networks adds 20 bytes of "
"overhead for any protocol."
msgstr ""
"Networking サービスは、アンダーレイの物理ネットワークでのジャンボフレームの使"
"用に対応しており、インスタンスでもオーバーレイプロトコルのオーバーヘッド分を"
"引いたサイズのジャンボフレームを使用できます。例えば、アンダーレイの物理ネッ"
"トワークが 9000 バイトの MTU の場合、 IPv4 エンドポイントの VXLAN ネットワー"
"クではインスタンスは 8950 バイトの MTU を使用できます。 IPv6 エンドポイントの"
"オーバーレイネットワークでは、どのプロトコルの場合でもさらに 20 バイトほど"
"オーバーヘッドが増えます。"

msgid ""
"The Networking service uses the MTU of the underlying physical network to "
"calculate the MTU for virtual network components including instance network "
"interfaces. By default, it assumes a standard 1500-byte MTU for the "
"underlying physical network."
msgstr ""
"Networking サービスは、アンダーレイの物理ネットワークの MTU に基いて、インス"
"タンスのネットワーク・インターフェースなどの仮想ネットワークコンポーネントの "
"MTU を計算します。デフォルトでは、アンダーレイの物理ネットワークの MTU を標準"
"の 1500 バイトと仮定します。"

msgid ""
"The Networking service, code-named neutron, provides an API that lets you "
"define network connectivity and addressing in the cloud. The Networking "
"service enables operators to leverage different networking technologies to "
"power their cloud networking. The Networking service also provides an API to "
"configure and manage a variety of network services ranging from L3 "
"forwarding and :term:`NAT <Network Address Translation (NAT)>` to load "
"balancing, perimeter firewalls, and virtual private networks."
msgstr ""
"Networking サービス、コード名 neutron、は、ユーザーがクラウドにおけるネット"
"ワーク接続性やアドレス割り当てを定義できる API を提供します。Networking サー"
"ビスを使うと、オペレーターはクラウドネットワークを支えるネットワーク技術とし"
"て様々な技術を活用できます。 Networking サービスは、 L3 転送や :term:`NAT "
"<Network Address Translation (NAT)>` から負荷分散、境界 ファイアウォール "
"(perimeter firewall)、 仮想プライベートネットワーク (VPN) などまで様々なネッ"
"トワークサービスを設定、管理するための API も提供しています。"

msgid ""
"The Open vSwitch agent configures the Open vSwitch to realize L2 networks "
"for OpenStack resources."
msgstr ""
"Open vSwitch エージェントは Open vSwitch の設定を行い、OpenStack リソース用"
"の L2 ネットワークを実現します。"

msgid ""
"The OpenStack :term:`Networking service <Networking service (neutron)>` "
"provides an API that allows users to set up and define network connectivity "
"and addressing in the cloud. The project code-name for Networking services "
"is neutron. OpenStack Networking handles the creation and management of a "
"virtual networking infrastructure, including networks, switches, subnets, "
"and routers for devices managed by the OpenStack Compute service (nova). "
"Advanced services such as firewalls or :term:`virtual private networks "
"(VPNs) <virtual private network (VPN)>` can also be used."
msgstr ""
"OpenStack :term:`Networking サービス <Networking service (neutron)>` は、ユー"
"ザーがクラウド内のネットワーク接続性やアドレス割り当てを定義できる API を提供"
"しています。 Networking サービスのプロジェクトコード名は neutron です。 "
"OpenStack Networking は、ネットワーク、スイッチ、サブネット、ルーターなどの仮"
"想ネットワーク基盤の作成、管理を行い、 OpenStack Compute (nova) が管理するデ"
"バイスに対して仮想ネットワーク基盤を提供します。ファイアウォールや :term:`仮"
"想プライベートネットワーク (VPN) <virtual private network (VPN)>` などの上位"
"サービスも使用できます。"

msgid ""
"The OpenStack Networking API includes support for Layer 2 networking and :"
"term:`IP address management (IPAM) <IP Address Management (IPAM)>`, as well "
"as an extension for a Layer 3 router construct that enables routing between "
"Layer 2 networks and gateways to external networks. OpenStack Networking "
"includes a growing list of plug-ins that enable interoperability with "
"various commercial and open source network technologies, including routers, "
"switches, virtual switches and software-defined networking (SDN) controllers."
msgstr ""
"OpenStack Networking API は、レイヤー 2 ネットワークと :term:`IP アドレス管"
"理 (IPAM) <IP Address Management (IPAM)>` をサポートしています。また、レイ"
"ヤー 3 ルーター用の API 拡張もサポートしており、これによりレイヤー 2 ネット"
"ワーク間のルーティング、および外部ネットワークへのゲートウェイが提供されま"
"す。 OpenStack Networking に対応するプラグインは増え続けており、ルーター、ス"
"イッチ、仮想スイッチ、SDN コントローラーなどの様々な製品やオープンソースの"
"ネットワーク技術で相互運用性が実現されています。"

msgid ""
"The OpenStack Networking service is extensible. Extensions serve two "
"purposes: they allow the introduction of new features in the API without "
"requiring a version change and they allow the introduction of vendor "
"specific niche functionality. Applications can programmatically list "
"available extensions by performing a GET on the :code:`/extensions` URI. "
"Note that this is a versioned request; that is, an extension available in "
"one API version might not be available in another."
msgstr ""
"OpenStack Networking サービスは拡張性があります。API 拡張は 2 つの目的で使用"
"されます。 API に新しい機能をバージョンの変更なしに追加できます。ベンダー固有"
"の特定の機能を追加できます。アプリケーションは、 URI :code:`/extensions` に "
"GET を行うことで、利用可能な API 拡張の一覧を取得できます。 API 拡張はバー"
"ジョン毎であることに注意してください。ある API バージョンで利用できた API 拡"
"張は別の API バージョンでは利用できないかもしれません。"

msgid ""
"The PTR records will be created in zones owned by a project with admin "
"privileges. See :ref:`config-dns-int-ext-serv` for more details."
msgstr ""
"PTR レコードは、管理者権限を持つプロジェクトが所有するゾーンに作成されます。"
"詳細は :ref:`config-dns-int-ext-serv` を参照してください。"

msgid ""
"The QoS implementation requires a burst value to ensure proper behavior of "
"bandwidth limit rules in the Open vSwitch and Linux bridge agents. If you do "
"not provide a value, it defaults to 80% of the bandwidth limit which works "
"for typical TCP traffic."
msgstr ""
"QoS 実装では、 Open vSwitch エージェントや Linux ブリッジエージェントで帯域制"
"限ルールが適切に動作するためには、適切なバースト値が必要です。値を指定しな"
"かった場合、デフォルト値は帯域制限の 80% になり、この値は通常の TCP トラ"
"フィックでは適切な値です。"

msgid ""
"The Role-Based Access Control (RBAC) policy framework enables both operators "
"and users to grant access to resources for specific projects."
msgstr ""
"ロールベースアクセス制御 (RBAC) ポリシーフレームワークにより、オペレーターと"
"ユーザーのどちらもがリソースへのアクセスを特定のプロジェクトに対して許可でき"
"るようになりました。"

msgid "The SNAT gateway resides on 203.0.113.11."
msgstr "SNAT ゲートウェイは IP アドレス 203.0.113.11 を持つ。"

msgid ""
"The SR-IOV agent allows you to set the admin state of ports, configure port "
"security (enable and disable spoof checking), and configure QoS rate "
"limiting. You must include the SR-IOV agent on each compute node using SR-"
"IOV ports."
msgstr ""
"SR-IOV エージェントは、ポートの admin state (管理状態) の設定、 port "
"security の設定 (なりすましチェックを有効にするかどうか)、 QoS レート制限を行"
"います。 SR-IOV ポートを使用する各コンピュートノードで SR-IOV エージェントを"
"動かす必要があります。"

msgid ""
"The SR-IOV agent was optional before Mitaka, and was not enabled by default "
"before Liberty."
msgstr ""
"Mitaka より前では SR-IOV エージェントはオプションで、 Liberty より前ではデ"
"フォルトでは有効ではありませんでした。"

msgid ""
"The Virtual Private Network-as-a-Service (VPNaaS) is a neutron extension "
"that introduces the VPN feature set."
msgstr ""
"仮想プライベートネットワークサービス (VPNaaS) は VPN 機能セットを実現する "
"neutron 機能拡張です。"

msgid ""
"The ``active_connections`` count is the total number of connections that "
"were active at the time the agent polled the load balancer. The other three "
"statistics are cumulative since the load balancer was last started. For "
"example, if the load balancer restarts due to a system error or a "
"configuration change, these statistics will be reset."
msgstr ""
"``active_connections`` カウントは、エージェントがロードバランサーの情報を収集"
"した時点でアクティブな接続の総数です。他の 3 つの統計情報は、ロードバランサー"
"が最後に起動してからの累積値です。例えば、ロードバランサーがシステムエラーや"
"設定変更で再起動されると、これらの統計情報はリセットされます。"

msgid ""
"The ``availability_zone`` attribute can be defined in ``dhcp-agent`` and "
"``l3-agent``. To define an availability zone for each agent, set the value "
"into ``[AGENT]`` section of ``/etc/neutron/dhcp_agent.ini`` or ``/etc/"
"neutron/l3_agent.ini``:"
msgstr ""
"``availability_zone`` 属性は ``dhcp-agent`` と ``l3-agent`` で定義できます。"
"各エージェントでアベイラビリティーゾーンを定義するには、 ``/etc/neutron/"
"dhcp_agent.ini`` や ``/etc/neutron/l3_agent.ini`` の ``[AGENT]`` セクションで"
"値を設定します。"

msgid ""
"The ``availability_zones`` attribute does not have a value until the "
"resource is scheduled. Once the Networking service schedules the resource to "
"zones according to ``availability_zone_hints``, ``availability_zones`` shows "
"in which zone the resource is hosted practically. The ``availability_zones`` "
"may not match ``availability_zone_hints``. For example, even if you specify "
"a zone with ``availability_zone_hints``, all agents of the zone may be dead "
"before the resource is scheduled. In general, they should match, unless "
"there are failures or there is no capacity left in the zone requested."
msgstr ""
"``availability_zones`` 属性は、そのリソースの割り当てが行われるまでは値を持ち"
"ません。 Networking サービスが ``availability_zone_hints`` に基いてリソースの"
"割り当てを行うと、そのリソースが配置されたゾーンが ``availability_zone`` に表"
"示されます。 ``availability_zones`` は ``availability_zone_hints`` と一致しな"
"い場合もあります。例えば、 ``availability_zone_hints`` にあるゾーンを指定した"
"としても、リソースの割り当てが行われる前の時点で、そのゾーンの全エージェント"
"が死んでいた場合などです。一般には、指定されたゾーンで障害が発生したり空き容"
"量がない場合を除き、両者の値は一致します。"

msgid ""
"The ``dns_assignment`` attribute also shows that the port's ``hostname`` in "
"the Networking service internal DNS is ``my-vm``."
msgstr ""
"``dns_assignment`` 属性を見ると、 Networking サービスの内部 DNS でのそのポー"
"トの ``hostname`` が ``my-vm`` であることが分かります。"

msgid ""
"The ``dns_name`` and ``dns_domain`` attributes of a floating IP must be "
"specified together on creation. They cannot be assigned to the floating IP "
"separately."
msgstr ""
"Floating IP の ``dns_name`` と ``dns_domain`` 属性は、作成時に両方一緒に指定"
"しなければいけません。別々に Floating IP に割り当てることはできません。"

msgid ""
"The ``dns_name`` and ``dns_domain`` of a floating IP have precedence, for "
"purposes of being published in the external DNS service, over the "
"``dns_name`` of its associated port and the ``dns_domain`` of the port's "
"network, whether they are specified or not. Only the ``dns_name`` and the "
"``dns_domain`` of the floating IP are published in the external DNS service."
msgstr ""
"外部 DNS サービスでの公開においては、 Floating IP の ``dns_name`` と "
"``dns_domain`` は、関連付けされたポートの ``dns_name`` とポートのネットワーク"
"の ``dns_domain`` が設定されているかに関わらず、必ず優先されます。 Floating "
"IP の ``dns_name`` と``dns_domain`` のみが外部 DNS サービスで公開されます。"

msgid ""
"The ``exclude_devices`` parameter is empty, therefore, all the VFs "
"associated with eth3 may be configured by the agent. To exclude specific "
"VFs, add them to the ``exclude_devices`` parameter as follows:"
msgstr ""
"``exclude_devices`` パラメーターは空なので、 eth3 に関連付けられたすべての "
"VF はエージェントが設定できます。特定の VF を除外するには、以下のようにその "
"VF を ``exclude_devices`` パラメーターに追加します。"

msgid "The ``external_network_bridge`` option intentionally contains no value."
msgstr ""
"``external_network_bridge`` オプションには意図的に値を指定していません。"

msgid ""
"The ``ipv6_address_mode`` attribute is used to control how addressing is "
"handled by OpenStack. There are a number of different ways that guest "
"instances can obtain an IPv6 address, and this attribute exposes these "
"choices to users of the Networking API."
msgstr ""
"``ipv6_address_mode`` 属性は、 OpenStack がどのようにアドレス割り当てを行うか"
"を制御するのに使用されます。 ゲストインスタンスが IPv6 アドレスを取得する方法"
"には様々なものがあり、この属性は Networking API のユーザーに選択肢を公開して"
"います。"

msgid ""
"The ``ipv6_ra_mode`` attribute is used to control router advertisements for "
"a subnet."
msgstr ""
"``ipv6_ra_mode`` 属性は、サブネットに対するルーター広告を制御するのに使用され"
"ます。"

msgid ""
"The ``physical_device_mappings`` parameter is not limited to be a 1-1 "
"mapping between physical networks and NICs. This enables you to map the same "
"physical network to more than one NIC. For example, if ``physnet2`` is "
"connected to ``eth3`` and ``eth4``, then ``physnet2:eth3,physnet2:eth4`` is "
"a valid option."
msgstr ""
"``physical_device_mapping`` パラメーターには、物理ネットワークと NIC の 1:1 "
"マッピング以外の設定も可能です。これにより、 1 つの物理ネットワークを複数の "
"NIC に割り当てることもできます。例えば、 ``physnet2`` が ``eth3`` と "
"``eth4`` に接続されている場合には、 ``physnet2:eth3,physnet2:eth4`` は有効な"
"設定となります。"

msgid ""
"The ``provider`` value in the ``network_vlan_ranges`` option lacks VLAN ID "
"ranges to support use of arbitrary VLAN IDs."
msgstr ""
"``network_vlan_ranges`` オプションの ``provider`` 値に VLAN ID を指定しなかっ"
"た場合、任意の VLAN ID を使用できます。"

msgid ""
"The ``service_function_parameters`` attribute includes one or more "
"parameters for the service function. Currently, it only supports a "
"correlation parameter that determines association of a packet with a chain. "
"This parameter defaults to ``none`` for legacy service functions that lack "
"support for correlation such as the NSH. If set to ``none``, the data plane "
"implementation must provide service function proxy functionality."
msgstr ""
"``service_function_parameters`` 属性は、サービス機能に関連するパラメーターが "
"1 つ以上含まれます。現時点では、パケットをチェインに関連付ける correlation "
"(関連付け) パラメーターのみがサポートされています。 NSH などのチェインへの関"
"連付けに対応していない従来のサービス機能では、このパラメーターのデフォルト値"
"は ``none`` になります。 ``none`` に設定する場合、データプレーンの実装でサー"
"ビス機能のプロキシー機能が提供されている必要があります。"

msgid ""
"The ``tags``, ``tags-any``, ``not-tags``, and ``not-tags-any`` arguments can "
"be combined to build more complex queries. Example::"
msgstr ""
"``tags``, ``tags-any``, ``not-tags``, ``not-tags-any`` 引数は組み合わせて、"
"もっと複雑な問い合わせを構成することもできます。例::"

msgid ""
"The ability to control port security and QoS rate limit settings was added "
"in Liberty."
msgstr ""
"port security の制御および QoS レート制限の設定の機能は Liberty で追加されま"
"した。"

msgid ""
"The above example returns any networks that have the \"red\" and \"blue\" "
"tags, plus at least one of \"green\" and \"orange\"."
msgstr ""
"上記の例では、 \"red\" と \"blue\" の両方のタグを持ち、かつ \"green\" と "
"\"orange\" のタグの少なくとも 1 つが設定されているネットワークの一覧を取得し"
"ています。"

msgid ""
"The administrator can configure the VXLAN multicast group that should be "
"used."
msgstr "管理者は、使用すべき VXLAN マルチキャストグループを設定できます。"

msgid "The agent currently only supports the Ryu BGP driver."
msgstr ""
"現在のところ、エージェントが対応しているのは Ryu BGP ドライバーのみです。"

msgid "The attributes can also be left unset."
msgstr "これらの属性に値を設定しないままにすることもできます。"

msgid ""
"The auto-allocation feature creates one network topology in every project "
"where it is used. The auto-allocated network topology for a project contains "
"the following resources:"
msgstr ""
"自動割り当て機能は、この機能を使うプロジェクト 1 つにつき 1 つのネットワーク"
"トポロジーを作成します。プロジェクトに自動割り当てされたネットワークトポロ"
"ジーには以下のリソースが含まれます。"

msgid ""
"The auto-allocation feature introduced in Mitaka simplifies the procedure of "
"setting up an external connectivity for end-users, and is also known as "
"**Get Me A Network**."
msgstr ""
"Mitaka で追加された自動割り当て (auto-allocation) 機能を使うと、エンドユー"
"ザーが外部へ接続できる構成をセットアップする手順を単純化できます。この機能は "
"**Get Me A Network (私にネットワークを)** とも呼ばれます。"

msgid ""
"The auto-allocation feature requires at least one default subnetpool. One "
"for IPv4, or one for IPv6, or one of each."
msgstr ""
"自動割り当て機能を使用するには、デフォルトサブネットプールが少なくとも 1 つ必"
"要です。 IPv4 が 1 つ、 IPv6 が 1 つ、IPv4/IPv6 それぞれが 1 つ、のいずれか。"

msgid ""
"The basic deployment model consists of one controller node, two or more "
"network nodes, and multiple computes nodes."
msgstr ""
"基本的なデプロイメントモデルは、 1 台のコントローラーノード、 2 台以上のネッ"
"トワークノード、複数台のコンピュートノードから構成されます。"

msgid "The basics"
msgstr "基本"

msgid ""
"The burst value is given in kilobits, not in kilobits per second as the name "
"of the parameter might suggest. This is an amount of data which can be sent "
"before the bandwidth limit applies."
msgstr ""
"バースト値はキロビットで指定します。パラメーターから連想されるようなキロビッ"
"ト/秒ではありません。この値は帯域制限が適用されるまでに送信できるデータ量で"
"す。"

msgid ""
"The client sends a discover (\"I’m a client at MAC address ``08:00:27:"
"b9:88:74``, I need an IP address\")"
msgstr ""
"クライアントは discover  を送信します (「自分は MAC アドレス ``08:00:27:"
"b9:88:74`` のクライアントです。 IP アドレスがほしいです」)"

msgid ""
"The client sends a request (\"Server ``10.10.0.131``, I would like to have "
"IP ``10.10.0.112``\")"
msgstr ""
"クライアントは request を送信します (「サーバー ``08:00:27:b9:88:74``、 IP "
"``10.10.0.112`` を使いたい」)"

msgid ""
"The cloud consumer can decide via the neutron APIs VNIC_TYPE attribute, if "
"an instance gets a normal OVS port or an SRIOV port."
msgstr ""
"クラウドの利用者は、インスタンスが通常の OVS ポートか SRIOV ポートのどちらを"
"使うかを、 neutron API の VNIC_TYPE 属性で指定できます。"

msgid "The command also indicates if a project lacks network resources."
msgstr "プロジェクトにネットワークリソースがない場合は、その旨が表示されます。"

msgid ""
"The command provides output that includes a completion percentage and the "
"quantity of successful or unsuccessful network resource deletions. An "
"unsuccessful deletion usually indicates sharing of a resource with one or "
"more additional projects."
msgstr ""
"このコマンドは、進捗率、およびネットワークリソース削除の成功数、失敗数を表示"
"します。削除の失敗が起こるのは、通常は別のプロジェクトとリソースが共有されて"
"いる場合です。"

msgid ""
"The core plug-in must support the ``availability_zone`` extension. The core "
"plug-in also must support the ``network_availability_zone`` extension to "
"schedule a network according to availability zones. The ``Ml2Plugin`` "
"supports it. The router service plug-in must support the "
"``router_availability_zone`` extension to schedule a router according to the "
"availability zones. The ``L3RouterPlugin`` supports it."
msgstr ""
"コアプラグインは ``availability_zone`` 拡張をサポートしている必要があります。"
"また、ネットワークをアベイラビリティーゾーンに基いて割り当てを行うには、コア"
"プラグインが ``network_availability_zone`` 拡張もサポートしている必要がありま"
"す。ルーターをアベイラビリティーゾーンに基いて割り当てを行うには、ルーター"
"サービスプラグインが ``router_availability_zone`` 拡張をサポートしている必要"
"があります。"

msgid ""
"The current process as designed is a minimally viable migration with the "
"goal of deprecating and then removing legacy networking. Both the Compute "
"and Networking teams agree that a one-button migration process from legacy "
"networking to OpenStack Networking (neutron) is not an essential requirement "
"for the deprecation and removal of the legacy networking at a future date. "
"This section includes a process and tools which are designed to solve a "
"simple use case migration."
msgstr ""
"現在の手順は、レガシーネットワークを廃止予定としその後削除するために、最小限"
"で必要な移行手順です。 Compute と Networking の両チームは、レガシーネットワー"
"クから OpenStack Networking (neutron) への「ボタン 1 つ押すだけ」の移行作業"
"は、レガシーネットワークを将来廃止予定に削除するにあたっての、必須の要件では"
"ないという点で合意しています。この節では、単純なユースケースで移行を可能にす"
"るために設計された手順とツールについて説明します。"

msgid ""
"The default ``policy.json`` file will not allow regular users to share "
"objects with every other project using a wildcard; however, it will allow "
"them to share objects with specific project IDs."
msgstr ""
"デフォルトの ``policy.json`` では、通常ユーザーがワイルドカードで他のすべての"
"プロジェクトとオブジェクトを共有することは許可されていませんが、通常ユーザー"
"が特定のプロジェクトとオブジェクトを共有することは許可されています。"

msgid ""
"The driver interface is designed to allow separate drivers for each subnet "
"pool. However, the current implementation allows only a single IPAM driver "
"system-wide."
msgstr ""
"ドライバーインターフェースは、サブネットプール毎に別のドライバーを利用できる"
"ように設計されていますが、現在の実装ではシステム全体で 1 つの IPAM ドライバー"
"しか利用できません。"

msgid ""
"The enablement of this functionality is prerequisite for the enablement of "
"the Networking service integration with an external DNS service, which is "
"described in detail in :ref:`config-dns-int-ext-serv`."
msgstr ""
"この機能を有効にするには、 Networking サービスの外部 DNS サービスとの連携が有"
"効になっている必要があります。詳細は :ref:`config-dns-int-ext-serv` で説明し"
"ています。"

msgid ""
"The example configuration assumes sufficient knowledge about the Networking "
"service, routing, and BGP. For basic deployment of the Networking service, "
"consult one of the :ref:`deploy`. For more information on BGP, see `RFC 4271 "
"<https://tools.ietf.org/html/rfc4271>`_."
msgstr ""
"この設定例では、 Networking サービスやルーティング、BGP についての十分な知識"
"があることを前提にしています。 Networking サービスの基本的なデプロイメントに"
"ついては、 :ref:`deploy` のいずれかを参考にしてください。 BGP についての詳し"
"い情報は `RFC 4271 <https://tools.ietf.org/html/rfc4271>`_ を参照してくださ"
"い。"

msgid "The example configuration involves the following components:"
msgstr "この設定例では、以下の構成要素が登場します。"

msgid "The example network ``net1`` must exist before creating ports on it."
msgstr ""
"サンプルのネットワーク ``net1`` は、そのネットワークにポートを作成する前に存"
"在している必要があります。"

msgid "The examples assume the OpenStack DNS service as the external DNS."
msgstr "ここの例では外部 DNS として OpenStack DNS サービスを前提とします。"

msgid "The external and self-service network reside in the same address scope."
msgstr ""
"外部ネットワークとセルフサービスネットワークが同じアドレススコープに属してい"
"る。"

msgid ""
"The first branch is called expand and is used to store expansion-only "
"migration rules. These rules are strictly additive and can be applied while "
"the Neutron server is running."
msgstr ""
"1 つめのブランチは expand (拡張) と呼ばれ、拡張のみの移行ルールを格納するのに"
"使用されます。これらのルールは追加処理のみであり、Neutron サーバーの実行中に"
"適用できます。"

msgid ""
"The first step to configure the integration with an external DNS service is "
"to enable the functionality described in :ref:`config-dns-int-dns-"
"resolution`. Once this is done, the user has to take the following steps and "
"restart ``neutron-server``."
msgstr ""
"外部 DNS サービスとの連携を設定する際に最初にすべきことは、 :ref:`config-dns-"
"int-dns-resolution` に書かれた機能を有効にすることです。これが終わったら、"
"ユーザーは以下の手順を実行し ``neutron-server`` を再起動する必要があります。"

msgid ""
"The first time host *A* attempts to communicate with host *B*, the "
"destination MAC address is not known. Host *A* makes an ARP request to the "
"local network. The request is a broadcast with a message like this:"
msgstr ""
"ホスト *A* が最初にホスト *B* と通信する際、宛先の MAC アドレスは不明です。ホ"
"スト *A* はローカルネットワークに ARP リクエストを行います。リクエストは以下"
"のようなメッセージが入ったブロードキャストです。"

msgid ""
"The first value in the ``tenant_network_types`` option becomes the default "
"project network type when a regular user creates a network."
msgstr ""
"`tenant_network_types`` オプションの最初の値は、一般ユーザーがネットワークを"
"作成した際のデフォルトのプロジェクトネットワーク種別になります。"

msgid ""
"The floating IP agent gateways (one per compute node) reside on "
"203.0.113.12, 203.0.113.13, and 203.0.113.14."
msgstr ""
"Floating IP エージェントゲートウェイ (各コンピュートノードに 1 つ置かれる) "
"は IP アドレス 203.0.113.12, 203.0.113.13, 203.0.113.14 を持つ。"

msgid "The following attributes are added into network and router:"
msgstr "以下の属性がネットワークとルーターに追加されます。"

msgid ""
"The following illustrates the creation of a port with ``my-port`` in its "
"``dns_name`` attribute."
msgstr ""
"以下では、 ``dns_name`` 属性の値が ``my-port`` でポートを作成しています。"

msgid ""
"The following is an example of an instance creation, showing how its "
"``hostname`` populates the ``dns_name`` attribute of the allocated port:"
msgstr ""
"以下は、インスタンスを作成し、割り当てられたポートの ``dns_name`` 属性に "
"``hostname`` がどのように設定されているかの例です。"

msgid "The following is an example:"
msgstr "以下は設定例です。"

msgid "The following manufacturers are known to work:"
msgstr "以下のベンダーの製品が動作するとされています。"

msgid ""
"The following shows the dnsmasq process that libvirt manages as it appears "
"in the output of :command:`ps`::"
msgstr ""
"以下は、出力  libvirt が管理する dnsmasq プロセスの  :command:`ps` の出力で"
"す。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "The following steps involve compute node 1."
msgstr "以下の手順は、コンピュートノード 1 で行われます。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "The following steps involve compute node 1:"
msgstr "以下の手順は、コンピュートノード 1 で行われます。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "The following steps involve compute node 2:"
msgstr "以下の手順は、コンピュートノード 2 で行われます。"

# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "The following steps involve the network node:"
msgstr "以下の手順は、ネットワークノードで行われます。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "The following steps involve the physical network infrastructure:"
msgstr "以下の手順は、物理ネットワーク環境で行われます。"

msgid ""
"The following tables shows which reference implementations support which non-"
"L2 neutron agents:"
msgstr ""
"以下の表に、どの参照実装でどの L2 以外の neutron エージェントが使用できるかを"
"示します。"

msgid "The following terms are used throughout this document:"
msgstr "以下の用語がこのページではたびたび登場します。"

msgid "The following type drivers are available"
msgstr "以下のタイプドライバーが利用できます。"

msgid ""
"The host containing the BGP agent must have layer-3 connectivity to the "
"provider router."
msgstr ""
"BGP エージェントが動作するホストは、プロバイダールーターへの L3 での接続性が"
"必要です。"

msgid ""
"The intent of separate branches is to allow invoking those safe migrations "
"from the expand branch while the Neutron server is running and therefore "
"reducing downtime needed to upgrade the service."
msgstr ""
"別々のブランチを持つ理由は、 Neutron サーバーの実行中に expand ブランチの安全"
"な移行ルールを適用し、サービスのアップグレードに必要な停止時間を減らすことに"
"あります。"

msgid ""
"The internal DNS functionality offered by the Networking service and its "
"interaction with the Compute service."
msgstr "Networking サービスが提供する内部 DNS 機能と Compute サービスとの連携"

msgid ""
"The list of supported rule types reported by core plug-in is not enforced "
"when accessing QoS rule resources. This is mostly because then we would not "
"be able to create any rules while at least one ml2 driver lacks support for "
"QoS (at the moment of writing, only macvtap is such a driver)."
msgstr ""
"コアプラグインが返すサポートされているルール種別のリストは、 QoS ルールリソー"
"スにアクセスする際には適用されません。このようになっているのは、ML2 ドライ"
"バーのうち 1 つでも QoS をサポートしていないものがあると、ルールを作れなく"
"なってしまうのが大きな理由です (執筆時点では macvtap ドライバーだけが QoS を"
"サポートしていません)。"

msgid "The load balancer now handles traffic on ports 80 and 443."
msgstr ""
"この時点で、ロードバランサーはポート 80 と 443 のトラフィックを処理します。"

msgid ""
"The load balancer occupies a neutron network port and has an IP address "
"assigned from a subnet."
msgstr ""
"ロードバランサーは neutron のネットワークポートを所有し、サブネットから割り当"
"てられた IP アドレスを持ちます。"

msgid ""
"The mechanism driver is responsible for taking the information established "
"by the type driver and ensuring that it is properly applied given the "
"specific networking mechanisms that have been enabled."
msgstr ""
"メカニズムドライバーは、タイプドライバーが設定した情報を受け取り、有効化に"
"なっているそれぞれのネットワーク機構にその情報を適切に適用する役割を持ちま"
"す。"

msgid ""
"The migration may be paused, even for an extended period of time (for "
"example, while testing or investigating issues) with some hypervisors on "
"legacy networking and some on Networking, and Compute API remains fully "
"functional. Individual hypervisors may be rolled back to legacy networking "
"during this stage of the migration, although this requires an additional "
"restart."
msgstr ""
"移行作業を途中で止めることもできます。一部のハイパーバイザーはレガシーネット"
"ワークで、一部ハイパーバイザーは Networking を使っているという状況で、(例え"
"ば、テストや問題の調査などで) 長い時間止めることもでき、その間も Compute API "
"は完全に機能し続けます。個々のハイパーバイザーは、移行のこの段階であれば、も"
"う一度再起動を行う必要はありますが、レガシーネットワークに切り戻すこともでき"
"ます。"

msgid ""
"The migration process from the legacy nova-network networking service to "
"OpenStack Networking (neutron) has some limitations and impacts on the "
"operational state of the cloud. It is critical to understand them in order "
"to decide whether or not this process is acceptable for your cloud and all "
"users."
msgstr ""
"レガシーネットワークの nova-network サービスから OpenStack Networking "
"(neutron) への移行手順には、いくつか制限があり、クラウドの運用状態への影響が"
"あります。あなたのクラウドとユーザーにとって、この手順が受け入れ可能なものか"
"を判断する上で、この内容を理解するのは不可欠です。"

msgid ""
"The migration process is quite simple, it involves turning down the router "
"by setting the router's ``admin_state_up`` attribute to ``False``, upgrading "
"the router to L3 HA and then setting the router's ``admin_state_up`` "
"attribute back to ``True``."
msgstr ""
"移行手順はかなり簡単です。ルーターの ``admin_state_up`` 属性を ``False`` に設"
"定してルーターを停止してから、ルーターを L3 HA にアップグレードし、最後にルー"
"ターの ``admin_state_up`` 属性を ``True`` に戻します。"

msgid ""
"The most common application programming interface (API) for writing TCP-"
"based applications is called *Berkeley sockets*, also known as *BSD sockets* "
"or, simply, *sockets*. The sockets API exposes a *stream oriented* interface "
"for writing TCP applications. From the perspective of a programmer, sending "
"data over a TCP connection is similar to writing a stream of bytes to a "
"file. It is the responsibility of the operating system's TCP/IP "
"implementation to break up the stream of data into IP packets. The operating "
"system is also responsible for automatically retransmitting dropped packets, "
"and for handling flow control to ensure that transmitted data does not "
"overrun the sender's data buffers, receiver's data buffers, and network "
"capacity. Finally, the operating system is responsible for re-assembling the "
"packets in the correct order into a stream of data on the receiver's side. "
"Because TCP detects and retransmits lost packets, it is said to be a "
"*reliable* protocol."
msgstr ""
"TCP を使ったアプリケーションを書く際に最も広く使われるアプリケーションプログ"
"ラミングインターフェース (API) は *Berkeley ソケット* と呼ばれています。 "
"*BSD ソケット* とか、単に *ソケット* と呼ばれることもあります。ソケット API "
"は TCP アプリケーションを書くための *ストリーム志向* のインターフェースを公開"
"しています。プログラマーの視点では、 TCP コネクションにデータを送信するのは、"
"ファイルにバイトストリームを書き込むのに似ています。データストリームを IP パ"
"ケットに分解するのはオペレーティングシステムの TCP/IP 実装の仕事です。失われ"
"たパケットを自動的に再送したり、送信したデータが送信側のデータバッファーや受"
"信側のデータバッファー、ネットワーク容量を超えてしまわないようにフロー制御を"
"行うのも、オペレーティングシステムの仕事です。最後に、受信側でパケットを正し"
"い順番で再組み立てしてデータストリームに戻すのも、オペレーティングシステムの"
"しごとです。 TCP はパケットロスを検知して再送を行うので、 *信頼性がある* プロ"
"トコルだと言われます。"

msgid ""
"The name assigned to the port by the Networking service internal DNS is now "
"visible in the response in the ``dns_assignment`` attribute."
msgstr ""
"Networking サービスの内部 DNS によってこのポートに割り当てられる名前が、レス"
"ポンスの ``dns_assignment`` 属性に入っています。"

msgid ""
"The name given to the instance by the user, ``my_vm``, is sanitized by the "
"Compute service and becomes ``my-vm`` as the port's ``dns_name``."
msgstr ""
"ユーザーがインスタンスに渡した名前 ``my_vm`` は Compute サービスにより使用で"
"きない文字が取り除かれ、ポートの ``dns_name`` では ``my-vm`` になっています。"

msgid ""
"The native OVS firewall implementation requires kernel and user space "
"support for *conntrack*, thus requiring minimum versions of the Linux kernel "
"and Open vSwitch. All cases require Open vSwitch version 2.5 or newer."
msgstr ""
"ネイティブ OVS ファイアウォール実装は、カーネル空間とユーザー空間の両方の "
"*conntrack* サポートを必要とします。そのため、 Linux カーネルと Open vSwitch "
"の必要な最小バージョンがあります。すべてのケースで Open vSwitch のバージョン "
"2.5 以降が必要です。"

msgid "The network cannot have attribute ``router:external`` set to ``True``."
msgstr ""
"ネットワークの ``router:external`` 属性は ``True`` であってはいけません。"

msgid "The network type can be FLAT, VLAN, GRE, VXLAN or GENEVE."
msgstr ""
"ネットワーク種別は FLAT,  VLAN, GRE, VXLAN, GENEVE のいずれかにできます。"

msgid ""
"The operating system of the TCP client application automatically assigns a "
"port number to the client. The client owns this port number until the TCP "
"connection is terminated, after which the operating system reclaims the port "
"number. These types of ports are referred to as *ephemeral ports*."
msgstr ""
"TCP クライアントアプリケーションのオペレーティングシステムは、自動的にクライ"
"アントにポート番号を割り当てます。クライアントはそのポート番号を TCP コネク"
"ションが終了するまで所有します。一定時間後にオペレーティングシステムはポート"
"番号を回収します。このようなポートは *ephemeral ポート (一時的なポート)* と呼"
"ばれます。"

msgid "The options used in the configuration file above are:"
msgstr "上記の設定ファイルで使用されているオプションは以下の通りです::"

msgid ""
"The output of the :command:`route -n` and :command:`netstat -rn` commands "
"are formatted in a slightly different way. This example shows how the same "
"routes would be formatted using these commands:"
msgstr ""
"コマンド :command:`route -n` と :command:`netstat -rn` の出力は、少し違った形"
"で整形されます。以下の例は、これらのコマンドを使って同じ経路を表示したもので"
"す。"

msgid ""
"The output shows ``bridge-mapping`` and the number of virtual network "
"devices on this L2 agent."
msgstr ""
"出力には ``bridge-mapping`` とこの L2 エージェント上の仮想ネットワークデバイ"
"ス数が表示されています。"

msgid ""
"The output shows information for four agents. The ``alive`` field shows "
"``:-)`` if the agent reported its state within the period defined by the "
"``agent_down_time`` option in the ``neutron.conf`` file. Otherwise the "
"``alive`` is ``xxx``."
msgstr ""
"この出力では 4 つのエージェントの情報が表示されています。 ``neutron.conf`` "
"ファイルの ``agent_down_time`` オプションで定義された時間内にエージェントが自"
"分の状態を報告した場合に、 ``alive`` フィールドに ``:-)`` が表示されます。そ"
"うでない場合 ``alive`` が ``xxx`` になります。"

msgid ""
"The port chain plug-in supports backing service providers including the OVS "
"driver and a variety of SDN controller drivers. The common driver API "
"enables different drivers to provide different implementations for the "
"service chain path rendering."
msgstr ""
"ポートチェインプラグインは、OVS ドライバーや各種 SDN コントローラードライバー"
"など、さまざまなサービスプロバイダーに対応しています。共通ドライバー API によ"
"り、それぞれのドライバーがサービスチェインパスの異なる方法で実装できるように"
"なっています。"

msgid ""
"The port's ``dns_assignment`` attribute shows that its FQDN is ``my-vm."
"example.org.`` in the Networking service internal DNS, which is the result "
"of concatenating the port's ``dns_name`` with the value configured in the "
"``dns_domain`` parameter in ``neutron.conf``, as explained previously."
msgstr ""
"ポートの ``dns_assignment`` 属性では、 Networking サービスの内部 DNS での "
"FQDN が ``my-vm.example.org`` であることが分かります。この FQDN は、ポートの "
"``dna_name`` と ``neutron.conf`` の ``dns_domain`` パラメーターに設定された値"
"を結合したものです。"

msgid ""
"The port's data was visible in the DNS service as soon as it was created."
msgstr ""
"ポートが作成された直後から DNS サービスでポートのデータが見えています。"

msgid ""
"The prefix delegation mechanism then sends a request via the external "
"network to your prefix delegation server, which replies with the delegated "
"prefix. The subnet is then updated with the new prefix, including issuing "
"new IP addresses to all ports:"
msgstr ""
"prefix delegation 機構により、外部ネットワーク経由で prefix delegation サー"
"バーに要求が送信され、 prefix delegation サーバーは移譲するプレフィックスを返"
"します。サブネットは新しいプレフィックスを持つように更新され、新しい IP アド"
"レスがすべてのポートに発行されます。"

msgid ""
"The router contains an interface on the self-service subnet and a gateway on "
"the external network."
msgstr ""
"ルーターが、セルフサービスサブネットに接続されたインターフェースと、外部ネッ"
"トワークに接続されたゲートウェイを持つ。"

msgid ""
"The router with the floating IP address binding contains a gateway on an "
"external network with the BGP speaker association."
msgstr ""
"Floating IP アドレスが関連付けられたルーターのゲートウェイが、 BGP スピーカー"
"の関連付けがある外部ネットワーク上にある。"

msgid ""
"The same can explicitly be accomplished by a user with administrative "
"credentials setting the flags in the :command:`neutron router-create` "
"command:"
msgstr ""
"管理者権限を持つユーザーがこれらのフラグを :command:`neutron router-create` "
"コマンドで指定して、同じことを明示的に行うこともできます。"

msgid ""
"The same neutron commands are used for LBaaS v2 with an agent or with "
"Octavia."
msgstr ""
"エージェントを用いた LBaaS v2 でも Octavia を用いた LBaaS v2 でも同じ "
"neutron コマンドを使用します。"

msgid ""
"The second branch is called contract and is used to store those migration "
"rules that are not safe to apply while Neutron server is running."
msgstr ""
"2 つめのブランチは contract (縮小) と呼ばれ、 Neutron サーバーの実行中には安"
"全に適用できない移行ルールが格納されます。"

msgid ""
"The server sends an acknowledgement (\"OK ``08:00:27:b9:88:74``, IP "
"``10.10.0.112`` is yours\")"
msgstr ""
"サーバーは acknowledgement を送信します (「``08:00:27:b9:88:74``よ、OK だ。 "
"``10.10.0.112`` は君のものだ」)"

msgid ""
"The server sends an offer (\"OK ``08:00:27:b9:88:74``, I’m offering IP "
"address ``10.10.0.112``\")"
msgstr ""
"サーバーは offer を送信します (「``08:00:27:b9:88:74``よ、OK だ。IP アドレス "
"``10.10.0.112`` を提供するよ」)"

msgid ""
"The sriov nic switch agent configures PCI virtual functions to realize L2 "
"networks for OpenStack instances. Network attachments for other resources "
"like routers, DHCP, and so on are not supported."
msgstr ""
"SRIOV NIC スイッチエージェントは、 OpenStack インスタンス用の L2 ネットワーク"
"を実現するための PCI 仮想ファンクション (VF) の設定を行います。ルーター、"
"DHCP などのその他のリソースのネットワーク接続には対応していません。"

msgid ""
"The subnet is initially created with a temporary CIDR before one can be "
"assigned by prefix delegation. Any number of subnets with this temporary "
"CIDR can exist without raising an overlap error. The subnetpool_id is "
"automatically set to ``prefix_delegation``."
msgstr ""
"サブネットは、 prefix delegation でアドレスが割り当てられるまでは、仮の CIDR "
"で作成されます。重複エラーが発生しないかぎりは、仮の CIDR を持つサブネットは"
"何個でも存在できます。 subnetpool_id は自動的に ``prefix_delegation`` に設定"
"されます。"

msgid ""
"The suggested way of making PCI SYS settings persistent is through the "
"``sysfsutils`` tool. However, this is not available by default on many major "
"distributions."
msgstr ""
"PCI SYS 設定を永続化させる推奨の方法は ``sysfsutils`` ツールを使用する方法で"
"す。しかしながら、多くの主要なディストリビューションではこの方法はデフォルト"
"では利用できません。"

msgid ""
"The support for SR-IOV with InfiniBand allows a Virtual PCI device (VF) to "
"be directly mapped to the guest, allowing higher performance and advanced "
"features such as RDMA (remote direct memory access). To use this feature, "
"you must:"
msgstr ""
"InfiniBand を使った SR-IOV 対応では、 仮想 PCI デバイス (VF) をゲストに直接"
"マッピングでき、高い性能が得られ、 RDMA (remote direct memory access) などの"
"高度な機能が利用できます。この機能を使用するには、以下を行う必要があります。"

msgid ""
"The tool needs to access the database connection string, which is provided "
"in the ``neutron.conf`` configuration file in an installation. The tool "
"automatically reads from ``/etc/neutron/neutron.conf`` if it is present. If "
"the configuration is in a different location, use the following command:"
msgstr ""
"このツールでは、 OpenStack 環境の設定ファイル ``neutron.conf`` で指定される"
"データベース接続の文字列オプションが必要です。 ``/etc/neutron/neutron.conf`` "
"が存在する場合は、自動的にこのファイルから設定を読み込みます。設定ファイルが"
"別の場所にある場合は、以下のコマンドを使用します。"

msgid "The tool takes some options followed by some commands:"
msgstr "このツールでは、オプションの後にコマンドが続きます。"

msgid ""
"The tool usage examples below do not show the options. It is assumed that "
"you use the options that you need for your environment."
msgstr ""
"以下のツールの実行例ではオプションは記載していません。必要な場合はオプション"
"を指定してください。"

msgid ""
"The upgrade of the Networking service database is implemented with Alembic "
"migration chains. The migrations in the ``alembic/versions`` contain the "
"changes needed to migrate from older Networking service releases to newer "
"ones."
msgstr ""
"Networking サービスのデータベースのアップグレードは、一連の Alembic の移行"
"ルールとして実装されています。 ``alembic/versions`` の移行ルール (migration) "
"には、Networking サービスの古いリリースから新しいリリースへの移行に必要な変更"
"が入っています。"

msgid ""
"The upstream router can send an RA and the neutron router will automatically "
"learn the next-hop LLA, provided again that no subnet is assigned and the "
"``ipv6_gateway`` flag is not set."
msgstr ""
"上流ルーターが RA を送信できる場合は、サブネットが割り当てられておらず、 "
"``ipv6_gateway`` フラグが設定されていない場合、 neutron ルーターはネクスト"
"ホップの LLA を自動的に学習します。"

msgid "The variables used in the script file above are:"
msgstr "上記のスクリプトで使用されている変数は以下の通りです。"

msgid ""
"There are certain scenarios where l2pop and distributed HA routers do not "
"interact in an expected manner. These situations are the same that affect HA "
"only routers and l2pop."
msgstr ""
"L2 population と分散 HA ルーターが期待通りに連携しない場面がいくつかありま"
"す。これらの場面は、 HA のみのルーターと L2 population がうまく連携できない場"
"面と同じです。"

msgid ""
"There are multiple variations of NAT, and here we describe three kinds "
"commonly found in OpenStack deployments."
msgstr ""
"NAT にはいくつかの種類があります。ここでは、OpenStack デプロイメントでよく使"
"われている 3 種類について説明します。"

msgid "There are two IPv6 attributes:"
msgstr "2 つの IPv6 関連の属性があります。"

msgid ""
"There are two reference implementations of LBaaS v2. The one is an agent "
"based implementation with HAProxy. The agents handle the HAProxy "
"configuration and manage the HAProxy daemon. Another LBaaS v2 "
"implementation, `Octavia <https://docs.openstack.org/developer/octavia/>`_, "
"has a separate API and separate worker processes that build load balancers "
"within virtual machines on hypervisors that are managed by the Compute "
"service. You do not need an agent for Octavia."
msgstr ""
"LBaaS v2 は 2 つのリファレンス実装があります。1 つは、HAProxy を用いたエー"
"ジェントベースの実装です。エージェントが HAProxy 設定を処理し、HAProxy デーモ"
"ンを管理します。もう 1 つの LBaaS v2 の実装である `Octavia <http://docs."
"openstack.org/developer/octavia/>`_ は、独立した API とワーカープロセスを持"
"ち、 Compute サービスが管理するハイパーバイザー上の仮想マシンにロードバラン"
"サーを作成します。 Octavia 用のエージェントは必要ありません。"

msgid "There are two syntaxes for expressing a netmask:"
msgstr "ネットマスクを表現する書式は 2 つあります。"

msgid ""
"There is no need to specify any value if you wish to use the reference "
"driver, though specifying ``internal`` will explicitly choose the reference "
"driver. The documentation for any alternate drivers will include the value "
"to use when specifying that driver."
msgstr ""
"参照実装ドライバーを使用する場合には、値を設定する必要はありませんが、 "
"``internal`` を指定して参照実装ドライバーを明示的に指定することもできます。こ"
"れ以外のドライバーを指定する場合、指定すべき値についてはドライバーのドキュメ"
"ントを参照してください。"

msgid "There will be three hosts in the setup."
msgstr "この構成では 3 つのホストがあります。"

msgid ""
"These IP addresses are not publicly routable, meaning that a host on the "
"public Internet can not send an IP packet to any of these addresses. Private "
"IP addresses are widely used in both residential and corporate environments."
msgstr ""
"これらの IP アドレスは、グローバルにはルーティングできないアドレスです。つま"
"り、パブリックなインターネット上のホストはこれらのアドレスを持つ IP パケット"
"を送信できません。プライベート IP アドレスは家庭や企業の環境では広く使われて"
"います。"

msgid "These attributes can be set to the following values:"
msgstr "これらの属性には以下の値を設定できます。"

msgid ""
"Third-party drivers must provide their own migration mechanisms to convert "
"existing OpenStack installations to their IPAM."
msgstr ""
"third-party 製のドライバーは、既存の OpenStack 環境を third-party 製の IPAM "
"に変換する仕組みを自分で提供する必要があります。"

msgid ""
"This command is the sibling command for the previous one. Remove ``net2`` "
"from the DHCP agent for HostA:"
msgstr ""
"このコマンドは上記のコマンドの対となるコマンドです。 HostA の DHCP から "
"``net2`` を削除します。"

msgid "This command is to show which networks a given dhcp agent is managing."
msgstr ""
"このコマンドは、指定した DHCP エージェントが管理しているネットワーク一覧を表"
"示します。"

msgid "This command provides no output."
msgstr "このコマンドは何も出力しません。"

msgid "This command requires other options outside the scope of this content."
msgstr ""
"このコマンドには、ここで議論している以外のオプションも指定する必要がありま"
"す。"

msgid ""
"This example shows how to check the connectivity between networks with "
"address scopes."
msgstr ""
"この例では、アドレススコープに所属するネットワーク間での接続性を確認します。"

msgid ""
"This feature is only supported when using the libvirt compute driver, and "
"the KVM/QEMU hypervisor."
msgstr ""
"この機能がサポートされるのは、 libvirt コンピュートドライバーと KVM/QEMU ハイ"
"パーバイザーを使う場合のみです。"

msgid ""
"This guide assumes that you are running a Dibbler server on the network node "
"where the external network bridge exists. If you already have a prefix "
"delegation capable DHCPv6 server in place, then you can skip the following "
"section."
msgstr ""
"このガイドでは、外部ネットワークブリッジが存在するネットワークノード上で "
"Dibbler サーバーが動いていることを前提にします。すでに prefix delegation に対"
"応した DHCPv6 サーバーがそこで動いている場合には、次のセクションはスキップで"
"きます。"

msgid ""
"This guide characterizes the L2 reference implementations that currently "
"exist."
msgstr "ここでは、現在存在する L2 参照実装の特徴を説明します。"

msgid ""
"This guide targets OpenStack administrators seeking to deploy and manage "
"OpenStack Networking (neutron)."
msgstr ""
"このガイドは、OpenStack Networking (neutron) を導入して管理しようとしている、"
"OpenStack 管理者を対象にしています。"

msgid ""
"This page serves as a guide for how to use the DNS integration functionality "
"of the Networking service. The functionality described covers DNS from two "
"points of view:"
msgstr ""
"このページでは、 Networking サービスの DNS 関連の機能の使用方法を説明します。"
"ここでは以下の 2 種類の DNS 関連機能を説明します。"

msgid ""
"This process can be repeated any number of times to make a network available "
"as external to an arbitrary number of projects."
msgstr ""
"この手順を繰り返して、任意の数のプロジェクトに対して、あるネットワークを外部"
"ネットワークとして利用可能にできます。"

msgid ""
"This process can be repeated any number of times to share a network with an "
"arbitrary number of projects."
msgstr ""
"この手順を繰り返して、任意の数のプロジェクトとネットワークを共有できます。"

msgid ""
"This process can be repeated any number of times to share a qos-policy with "
"an arbitrary number of projects."
msgstr ""
"この手順を繰り返して、任意の数のプロジェクトと QoS ポリシーを共有できます。"

msgid ""
"This section describes how to use the agent management (alias agent) and "
"scheduler (alias agent_scheduler) extensions for DHCP agents scalability and "
"HA."
msgstr ""
"このセクションでは、エージェント管理 API 拡張 (別名 agent) とスケジューラー "
"API 拡張 (別名 agent_scheduler) を使って DHCP エージェントのスケーラビリ"
"ティーと HA (高可用性) を行う方法を説明します。"

msgid ""
"This section describes the process of migrating clouds based on the legacy "
"networking model to the OpenStack Networking model. This process requires "
"additional changes to both compute and networking to support the migration. "
"This document describes the overall process and the features required in "
"both Networking and Compute."
msgstr ""
"この節では、レガシーネットワークモデルのクラウドを OpenStack Networking モデ"
"ルに移行する手順を説明します。この手順では、移行に対応するために compute と "
"networking の両方に追加の変更が必要です。ここでは、全体の手順と、Networking "
"と Compute の両方に必要となる機能について説明します。"

msgid ""
"This section describes the process of migrating from a classic router to an "
"L3 HA router, which is available starting from the Mitaka release."
msgstr ""
"この節では、従来のルーター (クラシックルーター) を L3 HA ルーターに移行する手"
"順を説明します。この機能は Mitaka リリースから利用可能です。"

msgid ""
"This section explains how to get high availability with the availability "
"zone for L3 and DHCP. You should naturally set above configuration options "
"for the availability zone."
msgstr ""
"このセクションでは、L3 と DHCP に対するアベイラビリティーゾーンと組み合わせて"
"高可用性を実現する方法を説明します。アベイラビリティーゾーンについては上記の"
"オプションを設定しているものとします。"

msgid ""
"This section illustrates how you can get the Network IP address availability "
"through the command-line interface."
msgstr ""
"このセクションでは、コマンドラインインターフェースを使ってネットワークの IP "
"アドレス利用状況を取得する方法を説明します。"

msgid ""
"This section shows how non-privileged users can use address scopes to route "
"straight to an external network without NAT."
msgstr ""
"このセクションでは、非特権ユーザーがアドレススコープを使って、外部ネットワー"
"クと NAT なしでそのままルーティングする方法を説明します。"

msgid ""
"This section shows how to set up shared address scopes to allow simple "
"routing for project networks with the same subnet pools."
msgstr ""
"このセクションでは、共有アドレススコープを用意し、同じサブネットプールのプロ"
"ジェクトネットワーク間では通常のルーティングが行うようにする方法を説明しま"
"す。"

msgid ""
"This step ensures that Dashboard can find the plug-in when it enumerates all "
"of its available panels."
msgstr ""
"この手順を行うことで、ダッシュボードが利用可能なパネルを探す際に LBaaSv2 プラ"
"グインを認識するようになります。"

msgid ""
"This tells OpenStack Networking to use the prefix delegation mechanism for "
"subnet allocation when the user does not provide a CIDR or subnet pool id "
"when creating a subnet."
msgstr ""
"これにより、ユーザーが CIDR またはサブネットプール ID をサブネット作成時に指"
"定しなかった場合、 OpenStack Networking は prefix delegation 機構を使ってサブ"
"ネット割り当てを行うようになります。"

msgid ""
"This tells the Compute service that all VFs belonging to ``eth3`` are "
"allowed to be passed through to instances and belong to the provider network "
"``physnet2``."
msgstr ""
"この設定では、 ``eth3`` に属するすべての VF をインスタンスにパススルーでき、"
"これらの VF はプロバイダーネットワーク ``physnet2`` に所属することを Compute "
"サービスに指示しています。"

msgid "Three instances, one per compute node, each with a floating IP address."
msgstr ""
"3 つのインスタンスが、各コンピュートノードに 1 つずつあり、それぞれ Floating "
"IP アドレスを持つ。"

msgid ""
"Three routers. Each router connects one self-service network to the provider "
"network."
msgstr ""
"3 個のルーター。各ルーターはそれぞれ 1 個のセルフサービスネットワークをプロバ"
"イダーネットワークに接続します。"

msgid "Three self-service networks."
msgstr "3 個のセルフサービスネットワーク。"

msgid ""
"Throughout this guide, ``eth3`` is used as the PF and ``physnet2`` is used "
"as the provider network configured as a VLAN range. These ports may vary in "
"different environments."
msgstr ""
"このページでは、、 PF として ``eth3`` を、 VLAN の範囲が設定されたプロバイ"
"ダーネットワークとして ``physnet2`` を使用します。これらの値は環境によって変"
"わります。"

msgid "To activate the network after it has been deactivated:"
msgstr ""
"非活性化した後に、このネットワークをアクティブにするには以下のようにします。"

msgid "To add another DHCP agent to host the network, run this command:"
msgstr ""
"ネットワークを別の DHCP エージェントに追加するには、以下のコマンドを実行しま"
"す。"

msgid ""
"To allow the neutron-pd-agent to communicate with prefix delegation servers, "
"you must set which network interface to use for external communication. In "
"DevStack the default for this is ``br-ex``:"
msgstr ""
"neutron-pd-agent が prefix delegation サーバーと通信できるように、外部通信に"
"使うネットワークインターフェースを設定しなければいけません。 DevStack では、"
"デフォルト値として ``br-ex`` が設定されます。"

msgid "To apply the expansion migration rules, use the following command:"
msgstr "拡張の移行ルールを適用するには、以下のコマンドを使用します。"

msgid "To apply the non-expansive migration rules, use the following command:"
msgstr "拡張以外の移行ルールを適用するには、以下のコマンドを使用します。"

msgid ""
"To calculate the network number of an IP address, you must know the "
"*netmask* associated with the address. A netmask indicates how many of the "
"bits in the 32-bit IP address make up the network number."
msgstr ""
"IP アドレスのネットワーク番号を計算するには、そのアドレスに関連付けられた *"
"ネットマスク* を知る必要があります。ネットマスクは 32 ビット IP アドレスのう"
"ち何ビットがネットワーク番号であるかを示します。"

msgid ""
"To check if any contract migrations are pending and therefore if offline "
"migration is required, use the following command:"
msgstr ""
"適用待ちの contract (縮小) 移行ルールがあり、オフラインでの移行が必要かを確認"
"するには、以下のコマンドを実行します。"

msgid ""
"To configure a driver other than the reference driver, specify it in the "
"``neutron.conf`` file. Do this after the migration is complete. There is no "
"need to specify any value if you wish to use the reference driver."
msgstr ""
"参照実装ドライバー以外のドライバーを設定するには、 ``neutron.conf`` ファイル"
"でそのドライバーを指定します。この作業は移行処理が完了してから行ってくださ"
"い。参照実装ドライバーを使用する場合、値を設定する必要はありません。"

msgid "To confirm the agent's availability zone:"
msgstr ""
"エージェントのアベイラビリティーゾーンを確認するには、以下のようにします。"

msgid "To confirm the availability zone defined by the system:"
msgstr ""
"システムで定義されているアベイラビリティーゾーンを確認するには、以下のように"
"します。"

msgid "To deactivate the libvirt network named ``default``:"
msgstr "``default`` という名前の libvirt ネットワークを非活性化します。"

msgid "To enable DSCP marking rule:"
msgstr "DSCP マーキングを有効にする場合:"

msgid ""
"To enable advertising IPv6 prefixes, create an address scope with "
"``ip_version=6`` and a BGP speaker with ``ip_version=6``."
msgstr ""
"IPv6 プレフィックスの広告を行うには、 ``ip_version=6`` でアドレススコープを作"
"成し、 ``ip_version=6`` で BGP スピーカーを作成します。"

msgid "To enable bandwidth limit rule:"
msgstr "帯域制限ルールを有効にする場合:"

msgid ""
"To enable mechanism drivers in the ML2 plug-in, edit the ``/etc/neutron/"
"plugins/ml2/ml2_conf.ini`` file on the neutron server:"
msgstr ""
"ML2 プラグインでメカニズムドライバーを有効にするには、 neutron サーバーの ``/"
"etc/neutron/plugins/ml2/ml2_conf.ini`` ファイルを編集します。"

msgid ""
"To enable peering via IPv6, create a BGP peer and use an IPv6 address for "
"``peer_ip``."
msgstr ""
"IPv6 経由のピアリングを有効にするには、 BGP ピアを作成する際に ``peer_ip`` "
"に IPv6 アドレスを使用します。"

msgid ""
"To enable prefix delegation, edit the ``/etc/neutron/neutron.conf`` file. If "
"you are running OpenStack Liberty, make the following change:"
msgstr ""
"prefix delegation を有効にするには、 ``/etc/neutron/neutron.conf`` ファイルを"
"編集します。 OpenStack Liberty を実行している場合には、以下の変更を行います。"

msgid ""
"To enable the driver for the dhcpv6_pd_agent, set pd_dhcp_driver to this in "
"``/etc/neutron/neutron.conf``:"
msgstr ""
"dhcpv6_pd_agent 用のドライバーを有効にするには、 ``/etc/neutron/neutron."
"conf``: で pd_dhcp_driver に dhcpv6_pd_agent を指定します。"

msgid "To enable the service, follow the steps below:"
msgstr "このサービスを有効にするには、以下の手順を行います。"

msgid ""
"To enable type drivers in the ML2 plug-in. Edit the ``/etc/neutron/plugins/"
"ml2/ml2_conf.ini`` file:"
msgstr ""
"ML2 プラグインでタイプドライバーを有効にするには、 ``/etc/neutron/plugins/"
"ml2/ml2_conf.ini`` ファイルを編集します。"

msgid "To experiment, you need VMs and a neutron network:"
msgstr "以下を試すには、VM と neutron ネットワークが必要です。"

msgid ""
"To find the panel, click on :guilabel:`Project` in Dashboard, then click "
"the :guilabel:`Network` drop-down menu and select :guilabel:`Load Balancers`."
msgstr ""
"このパネルを開くには、 ダッシュボードの :guilabel:`プロジェクト` 、 :"
"guilabel:`ネットワーク` ドロップダウンメニューをクリックし、 :guilabel:`ロー"
"ドバランサー` を選択します。"

msgid ""
"To generate a script of the command instead of operating immediately on the "
"database, use the following command:"
msgstr ""
"データベースを直接操作せず、代わりにコマンドスクリプトを生成するには、以下の"
"コマンドを実行します。"

msgid ""
"To make a network available as an external network for specific projects "
"rather than all projects, use the ``access_as_external`` action."
msgstr ""
"あるネットワークの外部ネットワークとしての利用を、すべてのプロジェクトではな"
"く特定のプロジェクトに対してだけ許可するには、 ``access_as_external`` アク"
"ションを使用します。"

msgid ""
"To migrate between specific migration versions, use the following command:"
msgstr "指定したバージョン間の移行を行うには、以下のコマンドを実行します。"

msgid "To prevent the network from automatically starting on boot:"
msgstr ""
"このネットワークがホスト起動時に自動的に開始しないようにするには以下のように"
"します。"

msgid ""
"To provide external network access to your instances, your Dibbler server "
"also needs to create new routes for each delegated prefix. This is done "
"using the script file named in the config file above. Edit the ``/var/lib/"
"dibbler/pd-server.sh`` file:"
msgstr ""
"インスタンスに外部ネットワークへのアクセスを提供する場合、 Dibbler サーバーは"
"移譲するプレフィックスそれぞれについて新しい経路を作成する必要があります。こ"
"れは、上記の設定ファイルで指定した名前のスクリプトにより行われます。 ファイ"
"ル  ``/var/lib/dibbler/pd-server.sh`` を編集します。"

msgid ""
"To reduce the number of ARP requests, operating systems maintain an ARP "
"cache that contains the mappings of IP addresses to MAC address. On a Linux "
"machine, you can view the contents of the ARP cache by using the :command:"
"`arp` command:"
msgstr ""
"ARP 要求の数を抑えるため、オペレーティングシステムは IP アドレスから MAC アド"
"レスへの対応表を保持する ARP キャッシュを管理します。 Linux マシンでは、 :"
"command:`arp` コマンドで ARP キャッシュの内容を表示できます。"

msgid ""
"To request the list of networks that do not have at least one of a list of "
"tags, the ``not-tags-any`` argument should be set to the list of tags, "
"separated by commas. In this case, only the networks that do not have at "
"least one of the given tags will be included in the query result. Example "
"that returns the networks that do not have the \"red\" tag, or do not have "
"the \"blue\" tag::"
msgstr ""
"指定されたタグのいずれも持たないネットワークの一覧を取得するには、 ``not-"
"tags-any`` 引数にタグのリストをコンマ区切りで指定します。この場合、指定された"
"タグのいずれも持たないネットワークだけが問い合わせの結果として返されます。 "
"\"red\" と \"blue\" のタグのどちらも持たないネットワーク一覧を取得する例::"

msgid ""
"To request the list of networks that do not have one or more tags, the ``not-"
"tags`` argument should be set to the list of tags, separated by commas. In "
"this case, only the networks that do not have any of the given tags will be "
"included in the query results. Example that returns the networks that do not "
"have either \"red\" or \"blue\" tag::"
msgstr ""
"指定された 1 つ以上のタグを持たないネットワークの一覧を取得するには、 ``not-"
"tags`` 引数にタグのリストをコンマ区切りで指定します。この場合、指定されたタグ"
"のいずれかを持たないネットワークだけが問い合わせの結果として返されます。 "
"\"red\" と \"blue\" のタグのどちらかを持たないネットワーク一覧を取得する例::"

msgid ""
"To request the list of networks that have a single tag, ``tags`` argument "
"should be set to the desired tag name. Example::"
msgstr ""
"あるタグを持つネットワークの一覧を取得するには、 ``tags`` 引数に所望のタグ名"
"を指定します。例::"

msgid ""
"To request the list of networks that have one or more of a list of given "
"tags, the ``tags-any`` argument should be set to the list of tags, separated "
"by commas. In this case, as long as one of the given tags is present, the "
"network will be included in the query result. Example that returns the "
"networks that have the \"red\" or the \"blue\" tag::"
msgstr ""
"指定されたタグのいずれかを持つネットワークの一覧を取得するには、 ``tags-"
"any`` 引数にタグのリストをコンマ区切りで指定します。この場合、指定されたタグ"
"が 1 つでもあれば、そのネットワークは問い合わせの結果として返されます。 \"red"
"\" か \"blue\" のタグを持つネットワーク一覧を取得する例::"

msgid ""
"To request the list of networks that have two or more tags, the ``tags`` "
"argument should be set to the list of tags, separated by commas. In this "
"case, the tags given must all be present for a network to be included in the "
"query result. Example that returns networks that have the \"red\" and \"blue"
"\" tags::"
msgstr ""
"2 つ以上のタグを持つネットワークの一覧を取得するには、 ``tags`` 引数にタグの"
"リストをコンマ区切りで指定します。この場合、指定されたすべてのタグを持つネッ"
"トワークが問い合わせの結果として返されます。 \"red\" と \"blue\" のタグを持つ"
"ネットワーク一覧を取得する例::"

msgid ""
"To return to classic mode, turn down the router again, turning off L3 HA and "
"starting the router again."
msgstr ""
"クラシックモードに戻すには、ルーターをもう一度停止し、 L3 HA をオフに変更し、"
"ルーターを再開します。"

msgid "To start your Dibbler server, run:"
msgstr "Dibbler サーバーを開始するには、以下を実行します。"

msgid "To test the HA of DHCP agent:"
msgstr "DHCP エージェントの HA を試験するには以下のようにします。"

msgid ""
"To trigger the prefix delegation process, create a router interface between "
"this subnet and a router with an active interface on the external network:"
msgstr ""
"prefix delegation 処理を行うには、ルーターインターフェースを作成し、このサブ"
"ネットと外部ネットワーク上にアクティブなインターフェースを持つルーターを接続"
"します。"

msgid ""
"To understand how ARP translates IP addresses to MAC addresses, consider the "
"following example. Assume host *A* has an IP address of ``192.168.1.5/24`` "
"and a MAC address of ``fc:99:47:49:d4:a0``, and wants to send a packet to "
"host *B* with an IP address of ``192.168.1.7``. Note that the network number "
"is the same for both hosts, so host *A* is able to send frames directly to "
"host *B*."
msgstr ""
"ARP がどのようにして IP アドレスを MAC アドレスに変換するかを理解するために、"
"次の例を考えてみましょう。ホスト *A* が IP アドレス ``192.168.1.5/24`` と "
"MAC アドレス ``fc:99:47:49:d4:a0`` を持っており、 IP アドレスが "
"``192.168.1.7`` のホスト *B* にパケットを送信したいものとします。ネットワーク"
"番号は両方のホストで同じで、ホスト *A* はホスト *B* に直接フレームを送信でき"
"るものとします。"

msgid ""
"To understand how VLANs work, let's consider VLAN applications in a "
"traditional IT environment, where physical hosts are attached to a physical "
"switch, and no virtualization is involved. Imagine a scenario where you want "
"three isolated networks but you only have a single physical switch. The "
"network administrator would choose three VLAN IDs, for example, 10, 11, and "
"12, and would configure the switch to associate switchports with VLAN IDs. "
"For example, switchport 2 might be associated with VLAN 10, switchport 3 "
"might be associated with VLAN 11, and so forth. When a switchport is "
"configured for a specific VLAN, it is called an *access port*. The switch is "
"responsible for ensuring that the network traffic is isolated across the "
"VLANs."
msgstr ""
"VLAN がどのように動作するかを理解するために、物理ホストが物理スイッチに接続さ"
"れ、仮想化が行われていない、従来の IT 環境で VLAN の利用を考えてみましょう。"
"ここで、 3 つの分離されたネットワークが必要だが、物理スイッチは 1 つしか持っ"
"ていないとしましょう。ネットワーク管理者は 3 つ VLAN ID (10, 11, 12 としま"
"す) を選んで、スイッチを設定してスイッチポートをこれらの VLAN ID に関連付けま"
"す。例えば、スイッチポート 2 は VLAN 10 に、スイッチポート 3 は VLAN 11 に関"
"連付け、他も同様とします。スイッチポートが特定の VLAN に設定された場合、その"
"ポートは *アクセスポート* と呼ばれます。ネットワークトラフィックが VLAN 間で"
"分離されることは、スイッチの責任で保証されます。"

msgid "To upgrade the database incrementally, use the following command:"
msgstr ""
"データベースのアップグレードを少しずつ行うには、以下のコマンドを使用します。"

msgid ""
"To use this feature, the neutron service must have the following extensions "
"enabled:"
msgstr ""
"この機能を使用するには、 neutron サービスで以下の拡張機能が有効になっている必"
"要があります。"

msgid "To view the defined libvirt networks and their state:"
msgstr "定義済みの libvirt ネットワークとその状態を表示します。"

msgid ""
"Trunking is used to connect between different switches. Each trunk uses a "
"tag to identify which VLAN is in use. This ensures that switches on the same "
"VLAN can communicate."
msgstr ""
"トランクポートは、別のスイッチ間を接続するのに使用されます。各トランクでは、"
"タグを使って、対象の VLAN を識別します。これにより、同じ VLAN のスイッチが通"
"信していることが保証されます。"

msgid ""
"Tunneling is a mechanism that makes transfer of payloads feasible over an "
"incompatible delivery network. It allows the network user to gain access to "
"denied or insecure networks. Data encryption may be employed to transport "
"the payload, ensuring that the encapsulated user network data appears as "
"public even though it is private and can easily pass the conflicting network."
msgstr ""
"トンネリングは、直接は転送できないネットワーク上でペイロードを転送するための"
"仕組みです。これにより、ネットワークユーザーは直接アクセスできないネットワー"
"クにアクセスできます。ペイロードを転送する際にデータ暗号化を行って、カプセル"
"化されたネットワークデータが実際には非公開であっても公開しても問題ない形に"
"し、そのまま転送できないネットワーク上を経由させることもできます。"

msgid "Type drivers"
msgstr "タイプドライバー"

msgid ""
"Typically, one uses this mechanism to delete networking resources for a "
"defunct project regardless of its existence in the Identity service."
msgstr ""
"通常は、存在しなくなったプロジェクトのネットワークリソースを削除するために、"
"この機能が使われます。 Identity サービスにプロジェクトが存在するかは関係あり"
"ません。"

msgid ""
"UDP has support for one-to-many communication: sending a single packet to "
"multiple hosts. An application can broadcast a UDP packet to all of the "
"network hosts on a local network by setting the receiver IP address as the "
"special IP broadcast address ``255.255.255.255``. An application can also "
"send a UDP packet to a set of receivers using *IP multicast*. The intended "
"receiver applications join a multicast group by binding a UDP socket to a "
"special IP address that is one of the valid multicast group addresses. The "
"receiving hosts do not have to be on the same local network as the sender, "
"but the intervening routers must be configured to support IP multicast "
"routing. VXLAN is an example of a UDP-based protocol that uses IP multicast."
msgstr ""
"UDP は 1対多通信に対応しており、1 つのパケットを複数のホストに送信できます。"
"アプリケーションは、受信者の IP アドレスを特別なブロードキャスト IP アドレス "
"``255.255.255.255`` に設定することで、ローカルネットワーク上のすべてのネット"
"ワークホストに UDP パケットをブロードキャストできます。また、アプリケーション"
"は *IP マルチキャスト* を使って UDP パケットを受信者の集合に送ることができま"
"す。パケットを受信したい受信側アプリケーションは、UDP ソケットを特別な IP ア"
"ドレス、つまり、有効なマルチキャストグループアドレスの 1 つにバインドすること"
"で、マルチキャストグループに参加します。受信者のホストは送信者と同じローカル"
"ネットワークにある必要はありませんが、途中のルーターが IP マルチキャストルー"
"ティングをサポートするように設定されている必要があります。 VXLAN は IP マルチ"
"キャストを使用する UDP ベースのプロトコルの 1 例です。"

msgid ""
"UDP, like TCP, uses the notion of ports to distinguish between different "
"applications running on the same system. Note, however, that operating "
"systems treat UDP ports separately from TCP ports. For example, it is "
"possible for one application to be associated with TCP port 16543 and a "
"separate application to be associated with UDP port 16543."
msgstr ""
"UDP も TCP と同じくポートという考え方で、同じシステム上で動作するアプリケー"
"ションを区別します。ただし、オペレーティングシステムは UDP ポートを TCP ポー"
"トとは別ものとして扱います。例えば、あるアプリケーションを TCP ポート 16543 "
"に関連付けて、別のアプリケーションを UDP ポート 16543 に関連付けることができ"
"ます。"

msgid ""
"Unlike most agents, BGP speakers require manual scheduling to an agent. BGP "
"speakers only form peering sessions and begin prefix advertisement after "
"scheduling to an agent. Schedule the BGP speaker to agent "
"``37729181-2224-48d8-89ef-16eca8e2f77e``."
msgstr ""
"多くのエージェントとは違い、 BGP スピーカーは手動でエージェントにスケジューリ"
"ングする必要があります。 BGP スピーカーがピアリングセッションを構成しプレ"
"フィックス広告を開始するのは、エージェントへのスケジューリング後だけです。 "
"BGP スピーカーをエージェント ``37729181-2224-48d8-89ef-16eca8e2f77e`` にスケ"
"ジューリングします。"

msgid "Unlimited address overlap is allowed."
msgstr "無制限のアドレス重複が許可されます。"

msgid "Update a port chain or port pair group"
msgstr "ポートチェインやポートペアグループの更新"

msgid "Update the DHCP configuration file ``/etc/neutron/dhcp_agent.ini``:"
msgstr "DHCP 設定ファイル ``/etc/neutron/dhcp_agent.ini`` を更新します。"

msgid "Update the nova configuration file ``/etc/nova/nova.conf``:"
msgstr "nova 設定ファイル ``/etc/nova/nova.conf`` を更新します。"

msgid ""
"Update the plug-in configuration file ``/etc/neutron/plugins/linuxbridge/"
"linuxbridge_conf.ini``:"
msgstr ""
"プラグイン設定ファイル ``/etc/neutron/plugins/linuxbridge/linuxbridge_conf."
"ini`` を更新します。"

msgid ""
"Update the security group to allow traffic to reach the new load balancer. "
"Create a new security group along with ingress rules to allow traffic into "
"the new load balancer. The neutron port for the load balancer is shown as "
"``vip_port_id`` above."
msgstr ""
"新しいロードバランサーにトラフィックが到達できるようにセキュリティーグループ"
"を更新します。新しいセキュリティーグループを作成し、新しいロードバランサーへ"
"のトラフィックを許可する受信ルールを追加します。ロードバランサーの neutron "
"ポートは上記では ``vip_port_id`` として表示されます。"

msgid "Usage"
msgstr "使用方法"

msgid "Use InfiniBand enabled network adapters."
msgstr "InfiniBand が有効になったネットワークアダプターを使用します。"

msgid ""
"Use ``availability_zone_hints`` to specify the zone in which the resource is "
"hosted:"
msgstr ""
"``availability_zone_hints`` を使って、そのリソースを配置するゾーンを指定しま"
"す。"

msgid "Use case"
msgstr "ユースケース"

msgid "Use case 1: Ports are published directly in the external DNS service"
msgstr "ユースケース 1: ポートを外部 DNS サービスで直接公開する"

msgid ""
"Use case 2: Floating IPs are published with associated port DNS attributes"
msgstr ""
"ユースケース 2: Floating IP を関連付けされたポートの DNS 属性で公開する"

msgid "Use case 3: Floating IPs are published in the external DNS service"
msgstr "ユースケース 3: Floating IP を外部 DNS サービスで公開する"

msgid "Use cases"
msgstr "ユースケース"

msgid ""
"Use the :command:`neutron ext-list` client command to check if these "
"extensions are enabled. Check ``agent`` and ``agent_scheduler`` are included "
"in the output."
msgstr ""
"これらの API 拡張が有効になっているかを確認するには :command:`neutron ext-"
"list` コマンドを使用します。出力に ``agent`` と ``agent_scheduler`` が含まれ"
"ていることを確認します。"

msgid "Use the previous commands to assign the network to agents."
msgstr "上述のコマンドを使って、ネットワークをエージェントに割り当てます。"

msgid "User workflow"
msgstr "ユーザーのワークフロー"

msgid ""
"Users are encouraged to take these tools, test them, provide feedback, and "
"then expand on the feature set to suit their own deployments; deployers that "
"refrain from participating in this process intending to wait for a path that "
"better suits their use case are likely to be disappointed."
msgstr ""
"ユーザーは、是非、これらのツールを使用し、テストし、フィードバックを行い、自"
"分の環境に適した機能を持つように機能追加を行ってください。こうした活動に参加"
"せずに、自分のユースケースにもっと適したものになるまで待っていると、できあ"
"がったものはあまり望ましいものにはなっていないことでしょう。"

msgid ""
"Users can also integrate the Networking and Compute services with an "
"external DNS. To accomplish this, the users have to:"
msgstr ""
"ユーザーは、Networking サービスと Compute サービスを外部 DNS と連携させること"
"もできます。これを行うには、ユーザーは以下を行う必要があります。"

msgid ""
"Users can control the behavior of the Networking service in regards to DNS "
"using two attributes associated with ports, networks, and floating IPs. The "
"following table shows the attributes available for each one of these "
"resources:"
msgstr ""
"ユーザーは、ポート、ネットワーク、Floating IP に関連付けられた 2 つの属性を"
"使って、 DNS に関する Networking サービスの動作を制御できます。下表に、これら"
"のリソースのそれぞれでどの属性が利用可能かを示します。"

msgid "Using DPDK in OVS requires the following minimum software versions:"
msgstr ""
"OVS で DPDK を使用するには、少なくとも以下のバージョンのソフトウェアが必要で"
"す。"

msgid "Using SLAAC for addressing"
msgstr "SLAAC を使ったアドレス割り当て"

msgid "Using SR-IOV interfaces"
msgstr "SR-IOV インターフェースを使用する"

msgid ""
"Using subnet pools constrains what addresses can be used by requiring that "
"every subnet be within the defined pool. It also prevents address reuse or "
"overlap by two subnets from the same pool."
msgstr ""
"サブネットプールを使うと、どのアドレスが使用できるかは、すべてのサブネットは"
"定義されたプール内になければいけないという制約により決まります。また、同じ"
"プールから割り当てた 2 つのサブネットでアドレスの再利用や重複はできません。"

msgid "Using vhost-user interfaces"
msgstr "vhost-user インターフェースを使用する"

msgid "VF"
msgstr "VF"

# #-#-#-#-#  config_ml2_plug_in.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_overview.pot (Networking Guide 0.9)
# #-#-#-#-#
msgid "VLAN"
msgstr "VLAN"

msgid "VLAN ID 101 (tagged)"
msgstr "VLAN ID 101 (タグ VLAN)"

msgid "VLAN ID 102 (tagged)"
msgstr "VLAN ID 102 (タグ VLAN)"

msgid "VLANs"
msgstr "VLAN"

# #-#-#-#-#  adv_config_ipv6.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  adv_config_VPNaaS.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  intro_os_networking_service.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "VPNaaS"
msgstr "VPNaaS"

msgid ""
"VPNaaS supports IPv6, but support in Kilo and prior releases will have some "
"bugs that may limit how it can be used. More thorough and complete testing "
"and bug fixing is being done as part of the Liberty release. IPv6-based VPN-"
"as-a-Service is configured similar to the IPv4 configuration. Either or both "
"the ``peer_address`` and the ``peer_cidr`` can specified as an IPv6 address. "
"The choice of addressing modes and router modes described above should not "
"impact support."
msgstr ""
"VPNaaS は IPv6 に対応していますが、 Kilo およびそれ以前のリリースでは、バグが"
"あり、使い方が制限されてしまう可能性があります。 Liberty リリースでより徹底的"
"にテストとバグ修正が行われ、 IPv6 ベースの VPNaaS は IPv4 の場合と同様に使え"
"るようになりました。 ``peer_address`` と ``peer_cidr`` の一方または両方に "
"IPv6 アドレスを指定できます。上で説明したアドレスモード属性とルーターモード属"
"性の組み合わせにより、IPv6 サポートのレベルが変わることはありません。"

msgid "VXLAN"
msgstr "VXLAN"

msgid "VXLAN ID (VNI) 101"
msgstr "VXLANID(VNI)101"

msgid "VXLAN ID (VNI) 102"
msgstr "VXLAN(VNI)102"

msgid ""
"VXLAN multicast group configuration is not applicable for the Open vSwitch "
"agent."
msgstr ""
"VXLAN マルチキャストグループの設定項目は Open vSwitch エージェントにはありま"
"せん。"

msgid "Validating the requirements for auto-allocation"
msgstr "自動割り当てに必要な要件の検証"

msgid ""
"Various virtual networking resources support tags for use by external "
"systems or any other clients of the Networking service API."
msgstr ""
"いくつかの仮想ネットワークリソースは、外部のシステムや Networking サービス "
"API のクライアントが使用できるタグをサポートしています。"

msgid "Verify addition of the BGP peer to the BGP speaker."
msgstr "BGP ピアが BGP スピーカーに関連付いていることを確認します。"

msgid "Verify association of the provider network with the BGP speaker."
msgstr ""
"プロバイダーネットワークが BGP スピーカーに関連付いていることを確認します。"

msgid "Verify network operation"
msgstr "ネットワーク動作の検証"

msgid "Verify presence and operation of each BGP dynamic routing agent."
msgstr "BGP 動的ルーティングエージェントが存在し機能していることを確認します。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Verify presence and operation of the agents:"
msgstr "エージェントが存在し、動作していることを確認します。"

msgid "Verify scheduling of the BGP speaker to the agent."
msgstr "BGP スピーカーのエージェントへのスケジューリングを確認します。"

# #-#-#-#-#  deploy_scenario4b.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_dvr_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_l3ha_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_lb.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_legacy_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
# #-#-#-#-#  scenario_provider_ovs.pot (Networking Guide 0.9)  #-#-#-#-#
msgid "Verify service operation"
msgstr "サービスの動作検証"

msgid "Verify that the VFs have been created and are in ``up`` state:"
msgstr "VF が作成され、状態が ``up`` になっていることを確認します。"

msgid ""
"Verify that the load balancer is responding to pings before moving further:"
msgstr "次に進む前にロードバランサーが ping に応答しているかを確認します。"

msgid ""
"Verify the prefixes and next-hop IP addresses that the BGP speaker "
"advertises."
msgstr ""
"BGP スピーカーが広告するプレフィックスとネクストホップ IP アドレスを確認しま"
"す。"

msgid ""
"Virtual Function. The virtual PCIe device created from a physical Ethernet "
"controller."
msgstr ""
"Virtual Function (仮想機能)。物理 Ethernet コントローラーから作成された仮想 "
"PCIe デバイスです。"

msgid "Virtual extensible local area network (VXLAN)"
msgstr "Virtual extensible local area network (VXLAN)"

msgid "Virtual routing and forwarding (VRF)"
msgstr "仮想ルーティング & フォワーディング (VRF)"

msgid ""
"Virtual routing and forwarding is an IP technology that allows multiple "
"instances of a routing table to coexist on the same router at the same time. "
"It is another name for the network namespace functionality described above."
msgstr ""
"仮想ルーティング & フォワーディングは、同時に同じルーターにルーティングテーブ"
"ルのインスタンスを複数保持できる IP 技術です。上で説明したネットワーク名前空"
"間機能の別名です。"

msgid ""
"We recommend using VLAN provider networks for segregation. This way you can "
"combine instances without SR-IOV ports and instances with SR-IOV ports on a "
"single network."
msgstr ""
"推奨のネットワーク分離方法はVLAN プロバイダーネットワークを使用することです。"
"こうすることで、 SR-IOV ポートを持たないインスタンスと SR-IOV ポートを持つイ"
"ンスタンスを 1 つの neutron ネットワークで共存させることができます。"

msgid ""
"When a NIC receives an Ethernet frame, by default the NIC checks to see if "
"the destination MAC address matches the address of the NIC (or the broadcast "
"address), and the Ethernet frame is discarded if the MAC address does not "
"match. For a compute host, this behavior is undesirable because the frame "
"may be intended for one of the instances. NICs can be configured for "
"*promiscuous mode*, where they pass all Ethernet frames to the operating "
"system, even if the MAC address does not match. Compute hosts should always "
"have the appropriate NICs configured for promiscuous mode."
msgstr ""
"NIC がEthernet フレームを受信すると、デフォルトでは NIC は宛先 MAC アドレス"
"が NIC のアドレス (またはブロードキャストアドレス) に一致するかを確認し、 "
"MAC アドレスが一致しない場合はその Ethernet フレームを廃棄します。コンピュー"
"トホストでは、この動作は期待されるものではありません。なぜなら、そのフレーム"
"はインスタンスの 1 つに宛てたものかもしれないからです。 NIC は *promiscuous "
"モード (無差別モード)* に設定することができ、このモードでは、 MAC アドレスが"
"一致しない場合であっても、すべての Ethernet フレームがオペレーティングシステ"
"ムに渡されます。 コンピュートホストでは、必要な NIC を常に promiscuous モード"
"に設定する必要があります。"

msgid ""
"When libvirt boots a virtual machine, it places the machine's VIF in the "
"bridge ``virbr0`` unless explicitly told not to."
msgstr ""
"libvirt は、仮想マシンを起動する際、明示的に指定されていない場合、その仮想マ"
"シンの VIF をブリッジ ``virbr0`` に接続します。"

msgid ""
"When the ``router_distributed = True`` flag is configured, routers created "
"by all users are distributed. Without it, only privileged users can create "
"distributed routers by using ``--distributed True``."
msgstr ""
"``router_distributed = True`` フラグが設定されると、すべてのユーザーが作成す"
"るルーターが分散ルーターになります。この設定をしない場合は、特権ユーザーだけ"
"が ``--distributed True`` を使って分散ルーターを作成できます。"

msgid ""
"When the router receives a packet with the matching IP address and port, it "
"translates these back to the private IP address and port, and forwards the "
"packet along."
msgstr ""
"ルーターが管理している IP アドレスとポートにマッチするパケットを受信すると、"
"プライベート Ip アドレスとポートに戻す変換を行い、引き続きパケットを転送しま"
"す。"

msgid ""
"When this functionality is enabled, it is leveraged by the Compute service "
"when creating instances. When allocating ports for an instance during boot, "
"the Compute service populates the ``dns_name`` attributes of these ports "
"with the ``hostname`` attribute of the instance, which is a DNS sanitized "
"version of its display name. As a consequence, at the end of the boot "
"process, the allocated ports will be known in the dnsmasq associated to "
"their networks by their instance ``hostname``."
msgstr ""
"この機能が有効になっている場合、 Compute サービスはインスタンス作成時にこの機"
"能を活用します。起動中にインスタンスにポートを割り当てる際に、 Compute サービ"
"スはこれらのポートの ``dns_name`` 属性にそのインスタンスの ``hostname`` 属性"
"を設定します。設定される値は、実際に見える値から DNS で使えない文字を除いたも"
"のになります。その結果、起動プロセスが終わった時には、割り当てられたポート"
"は、それぞれのネットワークに対応する dnsmasq ではインスタンスの ``hostname`` "
"で 参照できるようになっています。"

msgid ""
"When troubleshooting an instance that is not reachable over the network, it "
"can be helpful to examine this log to verify that all four steps of the DHCP "
"protocol were carried out for the instance in question."
msgstr ""
"インスタンスがネットワークに到達できないという問題を切り分ける際には、このロ"
"グを確認して、上記の DHCP プロトコルの 4 つのステップが問題のインスタンスに対"
"して実行されているかを検証するとよいでしょう。"

msgid ""
"When using DevStack, it is important to start your server after the ``stack."
"sh`` script has finished to ensure that the required network interfaces have "
"been created."
msgstr ""
"DevStack を使用する場合には、 ``stack.sh`` が完了した後にサーバーを開始するこ"
"とが重要です。必要なネットワークインターフェースが作成された状態でサーバーを"
"開始するためです。"

msgid ""
"When using Quality of Service (QoS), ``max_burst_kbps`` (burst over "
"``max_kbps``) is not supported. In addition, ``max_kbps`` is rounded to Mbps."
msgstr ""
"Quality of Service (QoS) を使用する場合、 ``max_burst_kbps`` (``max_kbps`` に"
"対するバーストサイズ) には対応していません。また、 ``max_kbps`` は Mbps に丸"
"められます。"

msgid ""
"When using SLAAC, the currently supported combinations for ``ipv6_ra_mode`` "
"and ``ipv6_address_mode`` are as follows."
msgstr ""
"SLAAC を使う場合、現在サポートされている ``ipv6_ra_mode`` と "
"``ipv6_address_mode`` の組み合わせは以下の通りです。"

msgid ""
"When using the reference implementation of the OpenStack Networking prefix "
"delegation driver, Dibbler must also be installed on your OpenStack "
"Networking node(s) to serve as a DHCPv6 client. Version 1.0.1 or higher is "
"required."
msgstr ""
"OpenStack Networking の prefix delegation ドライバーの参照実装を使う場合、 "
"Dibbler は、 DHCPv6 クライアントとなる OpenStack Networking ノード上にインス"
"トールする必要があります。バージョン 1.0.1 以上が必要です。"

msgid ""
"When you create a network with one port, the network will be scheduled to an "
"active DHCP agent. If many active DHCP agents are running, select one "
"randomly. You can design more sophisticated scheduling algorithms in the "
"same way as nova-schedule later on."
msgstr ""
"ネットワークにポートを 1 つ作成すると、そのネットワークは稼働中の DHCP エー"
"ジェントに割り当てられます。複数の稼働中のエージェントがある場合は、 1 つがラ"
"ンダムに選択されます。  nova-scheduler と同様、もっと洗練されたスケジューリン"
"グアルゴリズムを設計することもできるでしょう。"

msgid ""
"While NICs use MAC addresses to address network hosts, TCP/IP applications "
"use IP addresses. The Address Resolution Protocol (ARP) bridges the gap "
"between Ethernet and IP by translating IP addresses into MAC addresses."
msgstr ""
"NIC はネットワークホストを表すのに MAC アドレスを使用しますが、 TCP/IP アプリ"
"ケーションは IP アドレスを使用します。アドレス解決プロトコル (Address "
"Resolution Protocol; ARP) が、IP アドレスを MAC アドレスに変換して、Ethernet "
"と IP の違いを埋めます。"

msgid "Whitelist PCI devices in nova-compute (Compute)"
msgstr ""
"nova-compute での PCI デバイスのホワイトリストの設定 (コンピュートノード)"

msgid "Whitelist PCI devices nova-compute (Compute)"
msgstr ""
"nova-compute の PCI デバイスのホワイトリストを作成する (コンピュートノード)"

msgid "Why you need them"
msgstr "なぜ必要か？"

msgid ""
"With IPv4, the default_quota can be set to the number of absolute addresses "
"any given project is allowed to consume from the pool. For example, with a "
"quota of 128, I might get 203.0.113.128/26, 203.0.113.224/28, and still have "
"room to allocate 48 more addresses in the future."
msgstr ""
"IPv4 の場合、 default_quota を使って、あるプロジェクトがプールから取得できる"
"アドレスの絶対数を設定できます。例えば、クォータが 128 の場合、 "
"203.0.113.128/26 と 203.0.113.224/28 を確保し、将来さらに 48 個のアドレスを確"
"保することができます。"

msgid ""
"With IPv6 it is a little different. It is not practical to count individual "
"addresses. To avoid ridiculously large numbers, the quota is expressed in "
"the number of /64 subnets which can be allocated. For example, with a "
"default_quota of 3, I might get 2001:db8:c18e:c05a::/64, 2001:"
"db8:221c:8ef3::/64, and still have room to allocate one more prefix in the "
"future."
msgstr ""
"IPv6 の場合は少し違います。この場合、 1 つ 1 つのアドレスを数えるのは現実的で"
"はありません。途方もなく大きな数字になるのを避けるため、クォータは割り当て可"
"能な /64 サブネットの数で表現されます。例えば、 default_quota が 3 の場合、 "
"2001:db8:c18e:c05a::/64 と 2001:db8:221c:8ef3::/64 を確保し、将来さらにこ"
"の /64 のプレフィックスをもう 1 つ確保することができます。"

msgid ""
"With subnet pools, all addresses in use within the address scope are unique "
"from the point of view of the address scope owner. Therefore, add more than "
"one subnet pool to an address scope if the pools have different owners, "
"allowing for delegation of parts of the address scope. Delegation prevents "
"address overlap across the whole scope. Otherwise, you receive an error if "
"two pools have the same address ranges."
msgstr ""
"サブネットプールが複数ある場合、アドレス管理の観点では、そのアドレススコープ"
"内で使用されるすべてのアドレスは一意になります。したがって、プールに所有者が"
"複数おり、アドレススコープの一部の管理を委譲するには、アドレススコープに複数"
"のサブネットプールを追加します。この委譲では、アドレススコープ全体でアドレス"
"の重複は防止されます。 2 つのプールが同じアドレス範囲を持つ場合にはエラーが発"
"生します。"

msgid ""
"With subnets, the resource is the IP address space. Some subnets take more "
"of it than others. For example, 203.0.113.0/24 uses 256 addresses in one "
"subnet but 198.51.100.224/28 uses only 16. If address space is limited, the "
"quota system can encourage efficient use of the space."
msgstr ""
"サブネットの場合、リソースは IP アドレス空間です。あるサブネットが他のサブ"
"ネットよりも多くのアドレス空間を持つ場合もあります。例えば、 203.0.113.0/24 "
"は 1 つのサブネットで 256 個のアドレスを使用しますが、 198.51.100.224/28 は "
"16 個のアドレスしか使用しません。アドレス空間が限られている場合、クォータ機構"
"によりアドレス空間の効率的な利用が可能になります。"

msgid ""
"With the load balancer online, you can add a listener for plaintext HTTP "
"traffic on port 80:"
msgstr ""
"オンラインのロードバランサーに、平文の HTTP トラフィックに対するポート 80 の"
"リスナーを追加します。"

msgid "Yes"
msgstr "はい"

msgid ""
"You can add a health monitor so that unresponsive servers are removed from "
"the pool:"
msgstr ""
"ヘルスモニターを追加し、反応のないサーバーをプールから削除できるようにしま"
"す。"

msgid ""
"You can add another listener on port 443 for HTTPS traffic. LBaaS v2 offers "
"SSL/TLS termination at the load balancer, but this example takes a simpler "
"approach and allows encrypted connections to terminate at each member server."
msgstr ""
"HTTPS トラフィックに対するポート 443 のリスナーをさらに追加できます。 LBaaS "
"v2 ではロードバランサーでの SSL/TLS 終端が提供されていますが、この例では簡単"
"な方法を使用し、暗号化された接続は各メンバーサーバーで終端されます。"

msgid "You can also add a health monitor for the HTTPS pool:"
msgstr "HTTPS プールに対してもヘルスモニターを追加できます。"

msgid ""
"You can also identify floating IP agent gateways in your environment to "
"assist with verifying operation of the BGP speaker."
msgstr ""
"以下のように Floating IP エージェントゲートウェイを確認することも、BGP スピー"
"カーの動作確認の一助となるでしょう。"

msgid ""
"You can attach networks to a QoS policy. The meaning of this is that any "
"compute port connected to the network will use the network policy by default "
"unless the port has a specific policy attached to it. Network owned ports "
"like DHCP and router ports are excluded from network policy application."
msgstr ""
"ネットワークに QoS ポリシーを関連付けることもできます。これは、そのネットワー"
"クに接続されるすべてのコンピュートポートに、デフォルトでネットワークポリシー"
"が使用されることを意味します。ポートに特定のポリシーが付与された場合は、ポー"
"ト単位のポリシー設定が優先されます。 DHCP やルーターのポートのようにネット"
"ワーク用のポートはネットワークポリシーの適用先から除外されます。"

msgid ""
"You can control the default number of DHCP agents assigned to a network by "
"setting the following configuration option in the file ``/etc/neutron/"
"neutron.conf``."
msgstr ""
"``/etc/neutron/neutron.conf`` ファイルの以下の設定オプションで、1 つのネット"
"ワークに割り当てるデフォルトの DHCP エージェント数を制御できます。"

msgid ""
"You can create, update, list, delete, and show DSCP markings with the "
"neutron client:"
msgstr ""
"neutron クライアントを使って、 DSCP マーキングの作成、更新、一覧表示、詳細表"
"示ができます。"

msgid "You can determine the maximum number of VFs a PF can support:"
msgstr "PF がサポートしている VF の最大数は以下で確認できます。"

msgid ""
"You can initiate an ARP request manually using the :command:`arping` "
"command. For example, to send an ARP request to IP address ``10.30.0.132``:"
msgstr ""
":command:`argping` コマンドを使うと、自分で ARP 要求を始めることができます。"
"例えば、 IP アドレス ``10.30.0.132`` に ARP 要求を送信するには、"

msgid ""
"You can modify or delete this policy with the same constraints as any other "
"RBAC ``access_as_external`` policy."
msgstr ""
"他の ``access_as_external`` RBAC ポリシーと同じく、このポリシーも、同じ制約の"
"元、変更したり削除したりできます。"

msgid ""
"You can modify rules at runtime. Rule modifications will be propagated to "
"any attached port."
msgstr ""
"実行中にルールを変更できます。ルールの変更はすべての関連ポートに反映されま"
"す。"

msgid ""
"You can now ping ``instance2`` directly because ``instance2`` shares the "
"same address scope as the external network:"
msgstr ""
"``instance2`` は外部ネットワークと同じアドレススコープに属しているため、 "
"``instance2`` には直接 ping することもできます。"

msgid ""
"You can repeat the ``--flow-classifier`` option to specify multiple flow "
"classifiers for a port chain. Each flow classifier identifies a flow."
msgstr ""
"``--flow-classifier`` オプションを複数個指定することで、 1 つのポートチェイン"
"に複数の Flow Classifier を指定できます。各 Flow Classifier でフローが特定さ"
"れます。"

msgid ""
"You can repeat the ``--port-pair-group`` option to specify additional port "
"pair groups in the port chain. A port chain must contain at least one port "
"pair group."
msgstr ""
"``--port-pair-group`` オプションを複数個指定することで、ポートチェインに追加"
"のポートペアグループを指定できます。 1 つのポートチェインには、少なくとも 1 "
"つポートペアグループを含める必要があります。"

msgid ""
"You can repeat the ``--port-pair`` option for multiple port pairs of "
"functionally equivalent service functions."
msgstr ""
"``--port-pair`` オプションを複数指定することで、機能的に等価なサービス機能の"
"ポートペアを複数追加できます。"

msgid ""
"You can request a specific subnet from the pool. You need to specify a "
"subnet that falls within the pool's prefixes. If the subnet is not already "
"allocated, the request succeeds. You can leave off the IP version because it "
"is deduced from the subnet pool."
msgstr ""
"プールから特定のサブネットを割り当てることもできます。プールのプレフィックス"
"内に収まるサブネットを指定する必要があります。サブネットがまだ割り当てられて"
"いなければ、要求は成功します。サブネットプールから IP バージョンは推定できる"
"ので、 IP バージョンの指定は省略できます。"

msgid ""
"You can see that only the DHCP agent for HostB is hosting the ``net2`` "
"network."
msgstr ""
"HostB の DHCP エージェントだけが ``net2`` ネットワークを担当していることが分"
"かります。"

msgid ""
"You can use ``curl`` to verify connectivity through the load balancers to "
"your web servers:"
msgstr ""
"``curl`` を使って、ロードバランサー経由でのウェブサーバーへの接続性を検証しま"
"す。"

msgid ""
"You cannot ping ``instance1`` directly because the address scopes do not "
"match:"
msgstr ""
"アドレススコープが一致しないので、 ``instance1`` には ping が直接では届きませ"
"ん。"

msgid ""
"You must configure this option for all eligible DHCP agents and restart them "
"to activate the values."
msgstr ""
"すべての有効な DHCP エージェントでこのオプションを設定し、値を反映するために"
"エージェントを再起動する必要があります。"

msgid ""
"`Basic Load-Balancer-as-a-Service operations <https://docs.openstack.org/"
"admin-guide/networking-adv-features.html#basic-load-balancer-as-a-service-"
"operations>`__"
msgstr ""
"`Load-Balancer-as-a-Service の基本的な操作 <https://docs.openstack.org/admin-"
"guide/networking-adv-features.html#basic-load-balancer-as-a-service-"
"operations>`__"

msgid ""
"`Load-Balancer-as-a-Service (LBaaS) overview <https://docs.openstack.org/"
"admin-guide/networking-introduction.html#load-balancer-as-a-service-lbaas-"
"overview>`__"
msgstr ""
"`Load-Balancer-as-a-Service (LBaaS) 概要 <https://docs.openstack.org/admin-"
"guide/networking-introduction.html#load-balancer-as-a-service-lbaas-"
"overview>`__"

msgid ""
"`RFC 1918 <https://tools.ietf.org/html/rfc1918>`_ reserves the following "
"three subnets as private addresses:"
msgstr ""
"`RFC 1918 <https://tools.ietf.org/html/rfc1918>`_ は、以下の 3 つのサブネット"
"をプライベートアドレスとして予約しています。"

msgid "``$1`` The operation being performed."
msgstr "``$1``: 実行中の操作"

msgid "``$IFACE`` The network interface upon which the request was received."
msgstr "``$IFACE``: 要求を受信したネットワークインターフェース"

msgid "``$PREFIX1`` The prefix being added/deleted by the Dibbler server."
msgstr "``$PREFIX1``: Dibbler サーバーにより追加、削除されるプレフィックス"

msgid "``$REMOTE_ADDR`` The IP address of the requesting Dibbler client."
msgstr "``$REMOTE_ADDR``: 要求を行った Dibbler クライアントの IP アドレス"

msgid "``10.0.0.0/8``"
msgstr "``10.0.0.0/8``"

msgid "``172.16.0.0/12``"
msgstr "``172.16.0.0/12``"

msgid "``192.168.0.0/16``"
msgstr "``192.168.0.0/16``"

msgid "``None``"
msgstr "``None``"

msgid ""
"``admin_auth_url``: the Identity service admin authorization endpoint url. "
"This endpoint will be used by the Networking service to authenticate as an "
"admin user to create and update reverse lookup (PTR) zones."
msgstr ""
"``admin_auth_url``:Identity サービスの管理者認証エンドポイント URL。このエン"
"ドポイントは、 Networking サービスが逆引き (PTR) ゾーンの作成、更新用に管理"
"ユーザーとして認証する際に使用されます。"

msgid ""
"``admin_password``: the password of the admin user to be used by Networking "
"service to create and update reverse lookup (PTR) zones."
msgstr ""
"``admin_password``: Networking サービスが逆引き (PTR) ゾーンの作成、更新用に"
"使用する管理ユーザーのパスワード"

msgid ""
"``admin_tenant_name``: the project of the admin user to be used by the "
"Networking service to create and update reverse lookup (PTR) zones."
msgstr ""
"``admin_tenant_name``: Networking サービスが逆引き (PTR) ゾーンの作成、更新用"
"に使用する管理ユーザーのプロジェクト"

msgid ""
"``admin_username``: the admin user to be used by the Networking service to "
"create and update reverse lookup (PTR) zones."
msgstr ""
"``admin_username``: Networking サービスが逆引き (PTR) ゾーンの作成、更新用に"
"使用する管理ユーザー"

msgid ""
"``allow_reverse_dns_lookup``: a boolean value specifying whether to enable "
"or not the creation of reverse lookup (PTR) records."
msgstr ""
"``allow_reverse_dns_lookup``: 逆引き (PTR) レコードの作成を有効にするかを示す"
"ブール値"

msgid "``auto-allocated-topology``"
msgstr "``auto-allocated-topology``"

msgid "``auto_allocated_network``"
msgstr "``auto_allocated_network``"

msgid "``auto_allocated_router``"
msgstr "``auto_allocated_router``"

msgid "``auto_allocated_subnet_v4``"
msgstr "``auto_allocated_subnet_v4``"

msgid "``auto_allocated_subnet_v6``"
msgstr "``auto_allocated_subnet_v6``"

msgid "``chain_parameters`` - Dictionary of chain parameters"
msgstr "``chain_parameters`` - チェインパラメーターの dict"

msgid "``description`` - Readable description"
msgstr "``description`` - 分かりやすい説明"

msgid "``destination_ip_prefix`` - Destination IP address or prefix"
msgstr "``destination_ip_prefix`` - 宛先 IP アドレスもしくはプレフィックス"

msgid "``destination_port_range_max`` - Maximum destination protocol port"
msgstr "``destination_port_range_max`` - 宛先プロトコルポートの最大値"

msgid "``destination_port_range_min`` - Minimum destination protocol port"
msgstr "``destination_port_range_min`` - 宛先プロトコルポートの最小値"

msgid "``dhcpv6-stateful``"
msgstr "``dhcpv6-stateful``"

msgid "``dhcpv6-stateless``"
msgstr "``dhcpv6-stateless``"

msgid "``egress`` - Egress port"
msgstr "``egress`` - 出力ポート"

msgid "``ethertype`` - Ethertype (IPv4/IPv6)"
msgstr "``ethertype`` - Ethernet タイプ (IPv4/IPv6)"

msgid "``external-net``"
msgstr "``external-net``"

msgid "``flow_classifiers`` - List of flow classifier IDs"
msgstr "``flow_classifiers`` - flow classifier ID のリスト"

msgid "``id`` - Flow classifier ID"
msgstr "``id`` - Flow Classifier ID"

msgid "``id`` - Port chain ID"
msgstr "``id`` - ポートチェイン ID"

msgid "``id`` - Port pair ID"
msgstr "``id`` - ポートペア ID"

msgid "``id`` - Port pair group ID"
msgstr "``id`` - ポートペアグループ ID"

msgid ""
"``iface`` The name of the network interface on which to listen for prefix "
"delegation messages."
msgstr ""
"``iface``: prefix delegation メッセージを待ち受けるネットワークインターフェー"
"ス名。"

msgid "``ingress`` - Ingress port"
msgstr "``ingress`` - 入力ポート"

msgid ""
"``insecure``: Disable SSL certificate validation. By default, certificates "
"are validated."
msgstr ""
"``insecure``: SSL 証明書検証を無効化します。デフォルトでは、証明書が検証され"
"ます。"

msgid ""
"``ipv4_ptr_zone_prefix_size``: the size in bits of the prefix for the IPv4 "
"reverse lookup (PTR) zones."
msgstr ""
"``ipv4_ptr_zone_prefix_size``: IPv4 逆引き (PTR) ゾーン用のプレフィックスの"
"ビットサイズ"

msgid "``ipv6_address_mode``"
msgstr "``ipv6_address_mode``"

msgid ""
"``ipv6_address_mode``: Determines how instances obtain IPv6 address, default "
"gateway, or optional information."
msgstr ""
"``ipv6_address_mode``: インスタンスが IPv6 アドレス、デフォルトゲートウェイ、"
"追加の情報をどのように取得するかを決定します。"

msgid ""
"``ipv6_ptr_zone_prefix_size``: the size in bits of the prefix for the IPv6 "
"reverse lookup (PTR) zones."
msgstr ""
"``ipv6_ptr_zone_prefix_size``: IPv6 逆引き (PTR) ゾーン用のプレフィックスの"
"ビットサイズ"

msgid "``ipv6_ra_mode``"
msgstr "``ipv6_ra_mode``"

msgid "``ipv6_ra_mode``: Determines who sends RA."
msgstr "``ipv6_ra_mode``: RA を誰が送信するかを決定します。"

msgid "``l7_parameters`` - Dictionary of L7 parameters"
msgstr "``l7_parameters`` - L7 パラメーターの dict"

msgid "``logical_destination_port`` - Destination port"
msgstr "``logical_destination_port`` - 宛先ポート"

msgid "``logical_source_port`` - Source port"
msgstr "``logical_source_port`` - 送信元ポート"

msgid "``name`` - Readable name"
msgstr "``name`` - 分かりやすい名前"

msgid "``network:floatingip_agent_gateway``"
msgstr "``network:floatingip_agent_gateway``"

msgid "``not-tags-any``"
msgstr "``not-tags-any``"

msgid "``not-tags``"
msgstr "``not-tags``"

msgid ""
"``pd-length`` The length that delegated prefixes will be. This must be 64 to "
"work with the current OpenStack Networking reference implementation."
msgstr ""
"``pd-length``: 移譲されるプレフィックスの長さ。現在の OpenStack Networking の"
"参照実装で動作するためには、この値は 64 でなければいけません。"

msgid ""
"``pd-pool`` The larger prefix from which you want your delegated prefixes to "
"come. The example given is sufficient if you do not need external network "
"access, otherwise a unique globally routable prefix is necessary."
msgstr ""
"``pd-pool``: 移譲される prefix の取得元となるプレフィックス。外部ネットワーク"
"アクセスが不要の場合は設定例のままで十分です。アクセスが必要な場合は、一意で"
"グローバルに到達可能なプレフィックスを指定する必要があります。"

msgid "``port_pair_groups`` - List of port pair group IDs"
msgstr "``port_pair_groups`` - ポートペアグループ ID のリスト"

msgid "``port_pairs`` - List of service function port pairs"
msgstr "``port_pairs`` - サービス機能のポートペアのリスト"

msgid "``protocol`` - IP protocol"
msgstr "``protocol`` - IP プロトコル"

msgid "``router``"
msgstr "``router``"

msgid ""
"``script`` Points to a script to be run when a prefix is delegated or "
"released. This is only needed if you want instances on your subnets to have "
"external network access. More on this below."
msgstr ""
"``script``: プレフィックスの移譲、解放が行われた際に実行されるスクリプトを指"
"します。このスクリプトが必要なのは、サブネットのインスタンスが外部ネットワー"
"クへのアクセスが必要な場合だけです。詳しくは後述します。"

msgid ""
"``service_function_parameters`` - Dictionary of service function parameters"
msgstr "``service_function_parameters`` - サービス機能パラメーターの dict"

msgid "``slaac``"
msgstr "``slaac``"

msgid "``source_ip_prefix`` - Source IP address or prefix"
msgstr "``source_ip_prefix`` - 送信元 IP アドレスもしくはプレフィックス"

msgid "``source_port_range_max`` - Maximum source protocol port"
msgstr "``source_port_range_max`` - 送信元プロトコルポートの最大値"

msgid "``source_port_range_min`` - Minimum source protocol port"
msgstr "``source_port_range_min`` - 送信元プロトコルポートの最小値"

msgid "``subnet_allocation``"
msgstr "``subnet_allocation``"

msgid "``tags-any``"
msgstr "``tags-any``"

msgid "``tags``"
msgstr "``tags``"

msgid "``tenant_id`` - Project ID"
msgstr "``tenant_id`` - プロジェクト ID"

msgid "``url``: the OpenStack DNS service public endpoint URL."
msgstr "``url``: OpenStack DNS サービスのパブリックエンドポイント URL"

msgid ""
"``vhost-user`` requires file descriptor-backed shared memory. Currently, the "
"only way to request this is by requesting large pages. This is why instances "
"spawned on hosts with OVS-DPDK must request large pages. The aggregate "
"flavor affinity filter can be used to associate flavors with large page "
"support to hosts with OVS-DPDK support."
msgstr ""
"``vhost-user`` は、ファイルディスクリプターに関連付けられた共有メモリーを必要"
"とします。現在のところ、このような共有メモリーを要求する方法は、ラージページ"
"を要求する方法しかありません。このため、 OVS-DPDK を使うホストで起動するイン"
"スタンスは必ずラージページを要求する必要があります。 aggregate flavor "
"affinity フィルターを使用すると、 OVS-DPDK 対応を提供するホストに、ラージペー"
"ジ対応のフレーバーを関連付けることができます。"

msgid "a set of iptables rules"
msgstr "iptables のルールセット"

msgid "availability zone candidates for the resource"
msgstr "そのリソースのアベイラビリティーゾーン候補"

msgid "availability zones for the resource"
msgstr "そのリソースのアベイラビリティーゾーン"

msgid "availability_zone_hints"
msgstr "availability_zone_hints"

msgid "availability_zones"
msgstr "availability_zones"

msgid "classless inter-domain routing (CIDR)"
msgstr "classless inter-domain routing (CIDR)"

msgid "dhcpv6-stateful"
msgstr "dhcpv6-stateful"

msgid "dhcpv6-stateless"
msgstr "dhcpv6-stateless"

msgid "dns_domain"
msgstr "dns_domain"

msgid "dns_name"
msgstr "dns_name"

msgid "dnsmasq for providing IP addresses to virtual machines using DHCP"
msgstr "dnsmasq: DHCP を使って仮想マシンに IP アドレスを割り当てるため"

msgid "dotted quad"
msgstr "ドット区切りの 4 つの数字"

msgid ""
"iptables to implement SNAT so instances can connect out to the public "
"internet, and to ensure that virtual machines are permitted to communicate "
"with dnsmasq using DHCP"
msgstr ""
"iptables: インスタンスがパブリックインターネットに接続するための SNAT を実現"
"するため、仮想マシンの DHCP を使った dnsmasq との通信を許可するため"

msgid "ipv6 address mode"
msgstr "ipv6 address mode"

msgid "ipv6 ra mode"
msgstr "ipv6 ra mode"

msgid "ipv6_address_mode"
msgstr "ipv6_address_mode"

msgid "ipv6_ra_mode"
msgstr "ipv6_ra_mode"

msgid "ipv6_ra_mode and ipv6_address_mode combinations"
msgstr "ipv6_ra_mode と ipv6_address_mode の組み合わせ"

msgid "libvirt 1.2.13"
msgstr "libvirt 1.2.13"

msgid "libvirt 1.2.17"
msgstr "libvirt 1.2.17"

msgid "libvirt network implementation"
msgstr "libvirt ネットワーク実装"

msgid "list of string"
msgstr "文字列リスト"

msgid "network"
msgstr "ネットワーク"

msgid "no"
msgstr "いいえ"

msgid "radvd A,M,O"
msgstr "radvd A,M,O"

msgid "router"
msgstr "ルーター"

msgid "slaac"
msgstr "slaac"

msgid "subnet (IPv4)"
msgstr "サブネット (IPv4)"

msgid "subnet (IPv6)"
msgstr "サブネット (IPv6)"

msgid "type driver / mech driver"
msgstr "タイプドライバー / メカニズムドライバー"

msgid "yes"
msgstr "はい"
