<?xml version="1.0" encoding="UTF-8"?>
<section xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink"
  version="5.0"
  xml:id="technical-considerations-network-focus">
    <?dbhtml stop-chunking?>
    <title>Technical considerations</title>
    <para>When you design an OpenStack network architecture, you must
        consider layer-2 and layer-3 issues. Layer-2
        decisions involve those made at the data-link layer, such as
        the decision to use Ethernet versus Token Ring. Layer-3 decisions
        involve those made about the protocol layer and the point when
        IP comes into the picture. As an example, a completely
        internal OpenStack network can exist at layer 2 and ignore
        layer 3 however, in order for any traffic to go outside of
        that cloud, to another network, or to the Internet, a layer-3
        router or switch must be involved.</para>
    <para>
      The past few years have seen two competing trends in
      networking. One trend leans towards building data center network
      architectures based on layer-2 networking. Another trend treats
      the cloud environment essentially as a miniature version of the
      Internet. This approach is radically different from the network
      architecture approach that is used in the staging environment:
      the Internet is based entirely on layer-3 routing rather than
      layer-2 switching.
    </para>
    <para>
      A network designed on layer-2 protocols has advantages over one
      designed on layer-3 protocols. In spite of the difficulties of
      using a bridge to perform the network role of a router, many
      vendors, customers, and service providers choose to use Ethernet
      in as many parts of their networks as possible. The benefits of
      selecting a layer-2 design are:
    </para>
    <itemizedlist>
        <listitem>
            <para>Ethernet frames contain all the essentials for
                networking. These include, but are not limited to,
                globally unique source addresses, globally unique
                destination addresses, and error control.</para>
        </listitem>
        <listitem>
            <para>Ethernet frames can carry any kind of packet.
                Networking at layer 2 is independent of the layer-3
                protocol.</para>
        </listitem>
        <listitem>
            <para>More layers added to the Ethernet frame only slow
                the networking process down. This is known as 'nodal
                processing delay'.</para>
        </listitem>
        <listitem>
            <para>Adjunct networking features, for example class of
                service (CoS) or multicasting, can be added to
                Ethernet as readily as IP networks.</para>
        </listitem>
        <listitem>
            <para>VLANs are an easy mechanism for isolating
                networks.</para>
        </listitem>
    </itemizedlist>
    <para>Most information starts and ends inside Ethernet frames.
        Today this applies to data, voice (for example, VoIP) and
        video (for example, web cameras). The concept is that, if more
        of the end-to-end transfer of information from a source to a
        destination can be done in the form of Ethernet frames, more
        of the benefits of Ethernet can be realized on the network.
        Though it is not a substitute for IP networking, networking at
        layer 2 can be a powerful adjunct to IP networking.
    </para>
    <para>
      Layer-2 Ethernet usage has these advantages over layer-3 IP
      network usage:
    </para>
    <itemizedlist>
      <listitem>
        <para>
          Speed
        </para>
      </listitem>
      <listitem>
          <para>
            Reduced overhead of the IP hierarchy.
          </para>
      </listitem>
      <listitem>
        <para>
          No need to keep track of address configuration as systems
          are moved around. Whereas the simplicity of layer-2
          protocols might work well in a data center with hundreds
          of physical machines, cloud data centers have the
          additional burden of needing to keep track of all virtual
          machine addresses and networks. In these data centers, it
          is not uncommon for one physical node to support 30-40
          instances.
        </para>
      </listitem>
    </itemizedlist>
    <important>
      <para>
        Networking at the frame level says nothing
        about the presence or absence of IP addresses at the packet
        level. Almost all ports, links, and devices on a network of
        LAN switches still have IP addresses, as do all the source and
        destination hosts. There are many reasons for the continued
        need for IP addressing. The largest one is the need to manage
        the network. A device or link without an IP address is usually
        invisible to most management applications. Utilities including
        remote access for diagnostics, file transfer of configurations
        and software, and similar applications cannot run without IP
        addresses as well as MAC addresses.</para>
    </important>
    <section xml:id="layer-2-arch-limitations">
      <title>Layer-2 architecture limitations</title>
    <para>Outside of the traditional data center the limitations of
        layer-2 network architectures become more obvious.</para>
    <itemizedlist>
        <listitem>
            <para>Number of VLANs is limited to 4096.</para>
        </listitem>
        <listitem>
            <para>The number of MACs stored in switch tables is
                limited.</para>
        </listitem>
        <listitem>
            <para>The need to maintain a set of layer-4 devices to
                handle traffic control must be accommodated.</para>
        </listitem>
        <listitem>
            <para>MLAG, often used for switch redundancy, is a
                proprietary solution that does not scale beyond two
                devices and forces vendor lock-in.</para>
        </listitem>
        <listitem>
            <para>It can be difficult to troubleshoot a network
                without IP addresses and ICMP.</para>
        </listitem>
        <listitem>
            <para>
              Configuring <glossterm
              baseform="Address Resolution Protocol (ARP)">ARP</glossterm>
              is considered complicated on large layer-2 networks.</para>
        </listitem>
        <listitem>
            <para>All network devices need to be aware of all MACs,
                even instance MACs, so there is constant churn in MAC
                tables and network state changes as instances are
                started or stopped.</para>
        </listitem>
        <listitem>
            <para>Migrating MACs (instance migration) to different
                physical locations are a potential problem if ARP
                table timeouts are not set properly.</para>
        </listitem>
    </itemizedlist>
    <para>It is important to know that layer 2 has a very limited set
        of network management tools. It is very difficult to control
        traffic, as it does not have mechanisms to manage the network
        or shape the traffic, and network troubleshooting is very
        difficult. One reason for this difficulty is network devices
        have no IP addresses. As a result, there is no reasonable way
        to check network delay in a layer-2 network.</para>
    <para>On large layer-2 networks, configuring ARP learning can also
        be complicated. The setting for the MAC address timer on
        switches is critical and, if set incorrectly, can cause
        significant performance problems. As an example, the Cisco
        default MAC address timer is extremely long. Migrating MACs to
        different physical locations to support instance migration can
        be a significant problem. In this case, the network
        information maintained in the switches could be out of sync
        with the new location of the instance.</para>
    <para>In a layer-2 network, all devices are aware of all MACs,
        even those that belong to instances. The network state
        information in the backbone changes whenever an instance is
        started or stopped. As a result there is far too much churn in
        the MAC tables on the backbone switches.</para></section>
    <section xml:id="layer-3-arch-advantages">
      <title>Layer-3 architecture advantages</title>
    <para>In the layer 3 case, there is no churn in the routing tables
        due to instances starting and stopping. The only time there
        would be a routing state change would be in the case of a Top
        of Rack (ToR) switch failure or a link failure in the backbone
        itself. Other advantages of using a layer-3 architecture
        include:</para>
    <itemizedlist>
        <listitem>
            <para>Layer-3 networks provide the same level of
                resiliency and scalability as the Internet.</para>
        </listitem>
        <listitem>
            <para>Controlling traffic with routing metrics is
                straightforward.</para>
        </listitem>
        <listitem>
            <para>Layer 3 can be configured to use <glossterm
                baseform="Border Gateway Protocol (BGP)">BGP</glossterm>
                confederation for scalability so core routers have state
                proportional to the number of racks, not to the number of
                servers or instances.</para>
        </listitem>
        <listitem>
            <para>Routing ensures that instance MAC and IP addresses
                out of the network core reducing state churn. Routing
                state changes only occur in the case of a ToR switch
                failure or backbone link failure.</para>
        </listitem>
        <listitem>
            <para>There are a variety of well tested tools, for
                example ICMP, to monitor and manage traffic.</para>
        </listitem>
        <listitem>
            <para>Layer-3 architectures allow for the use of Quality
                of Service (QoS) to manage network performance.</para>
        </listitem>
    </itemizedlist>
    <section xml:id="layer-3-arch-limitations">
      <title>Layer-3 architecture limitations</title>
    <para>The main limitation of layer 3 is that there is no built-in
        isolation mechanism comparable to the VLANs in layer-2
        networks. Furthermore, the hierarchical nature of IP addresses
        means that an instance will also be on the same subnet as its
        physical host. This means that it cannot be migrated outside
        of the subnet easily. For these reasons, network
        virtualization needs to use IP <glossterm>encapsulation</glossterm>
        and software at
        the end hosts for both isolation, as well as for separation of
        the addressing in the virtual layer from addressing in the
        physical layer. Other potential disadvantages of layer 3
        include the need to design an IP addressing scheme rather than
        relying on the switches to automatically keep track of the MAC
        addresses and to configure the interior gateway routing
        protocol in the switches.</para>
    </section>
    </section>
    <section xml:id="network-recommendations-overview">
        <title>Network recommendations overview</title>
    <para>OpenStack has complex networking requirements for several
        reasons. Many components interact at different levels of the
        system stack that adds complexity. Data flows are complex.
        Data in an OpenStack cloud moves both between instances across
        the network (also known as East-West), as well as in and out
        of the system (also known as North-South). Physical server
        nodes have network requirements that are independent of those
        used by instances which need to be isolated from the core
        network to account for scalability. It is also recommended to
        functionally separate the networks for security purposes and
        tune performance through traffic shaping.</para>
    <para>A number of important general technical and business factors
        need to be taken into consideration when planning and
        designing an OpenStack network. They include:</para>
    <itemizedlist>
        <listitem>
            <para>A requirement for vendor independence. To avoid
                hardware or software vendor lock-in, the design should
                not rely on specific features of a vendorâ€™s router or
                switch.</para>
        </listitem>
        <listitem>
            <para>A requirement to massively scale the ecosystem to
                support millions of end users.</para>
        </listitem>
        <listitem>
            <para>A requirement to support indeterminate platforms and
                applications.</para>
        </listitem>
        <listitem>
            <para>A requirement to design for cost efficient
                operations to take advantage of massive scale.</para>
        </listitem>
        <listitem>
            <para>A requirement to ensure that there is no single
                point of failure in the cloud ecosystem.</para>
        </listitem>
        <listitem>
            <para>A requirement for high availability architecture to
                meet customer SLA requirements.</para>
        </listitem>
        <listitem>
            <para>A requirement to be tolerant of rack level
                failure.</para>
        </listitem>
        <listitem>
            <para>A requirement to maximize flexibility to architect
                future production environments.</para>
        </listitem>
    </itemizedlist>
    <para>Keeping all of these in mind, the following network design
        recommendations can be made:</para>
    <itemizedlist>
        <listitem>
            <para>Layer-3 designs are preferred over layer-2
                architectures.</para>
        </listitem>
        <listitem>
            <para>Design a dense multi-path network core to support
                multi-directional scaling and flexibility.</para>
        </listitem>
        <listitem>
            <para>Use hierarchical addressing because it is the only
                viable option to scale network ecosystem.</para>
        </listitem>
        <listitem>
            <para>Use virtual networking to isolate instance service
                network traffic from the management and internal
                network traffic.</para>
        </listitem>
        <listitem>
            <para>Isolate virtual networks using encapsulation
                technologies.</para>
        </listitem>
        <listitem>
            <para>Use traffic shaping for performance tuning.</para>
        </listitem>
        <listitem>
            <para>Use eBGP to connect to the Internet up-link.</para>
        </listitem>
        <listitem>
            <para>Use iBGP to flatten the internal traffic on the
                layer-3 mesh.</para>
        </listitem>
        <listitem>
            <para>Determine the most effective configuration for block
                storage network.</para>
        </listitem>
    </itemizedlist></section>
    <section xml:id="additional-considerations-network-focus">
      <title>Additional considerations</title>
    <para>There are numerous topics to consider when designing a
        network-focused OpenStack cloud.</para>
    <section xml:id="openstack-networking-versus-nova-network">
      <title>OpenStack Networking versus legacy networking (nova-network)
        considerations</title>
    <para>Selecting the type of networking technology to implement
        depends on many factors. OpenStack Networking (neutron) and
        legacy networking (nova-network) both have their advantages and disadvantages.
        They are both valid and supported options that fit different
        use cases as described in the following table.</para>
        <informaltable rules="all">
                <col width="40%" />
                <col width="60%" />
                <thead>
                    <tr><th>Legacy networking (nova-network)</th>
                        <th>OpenStack Networking</th></tr>
                </thead>
            <tbody>
                <tr>
                    <td>Simple, single agent</td>
                    <td>Complex, multiple agents</td>
                </tr>
                <tr>
                    <td>More mature, established</td>
                    <td>Newer, maturing</td>
                </tr>
                <tr>
                    <td>Flat or VLAN</td>
                    <td>Flat, VLAN, Overlays, L2-L3, SDN</td></tr>
                <tr>
                    <td>No plug-in support</td>
                    <td>Plug-in support for 3rd parties</td>
                </tr>
                <tr>
                    <td>Scales well</td>
                    <td>Scaling requires 3rd party plug-ins</td>
                </tr>
                <tr>
                    <td>No multi-tier topologies</td>
                    <td>Multi-tier topologies</td>
                </tr>
            </tbody>
        </informaltable>
    </section>
    <section xml:id="redundant-networking-tor-switch-ha">
      <title>Redundant networking: ToR switch high availability
        risk analysis</title>
    <para>A technical consideration of networking is the idea that
        switching gear in the data center that should be installed
        with backup switches in case of hardware failure.</para>
    <para>
      Research into the mean time between failures (MTBF) on switches
      is between 100,000 and 200,000 hours. This number is dependent
      on the ambient temperature of the switch in the data
      center. When properly cooled and maintained, this translates to
      between 11 and 22 years before failure. Even in the worst case
      of poor ventilation and high ambient temperatures in the data
      center, the MTBF is still 2-3 years. This is based on published
      research found at <link
      xlink:href="http://www.garrettcom.com/techsupport/papers/ethernet_switch_reliability.pdf">http://www.garrettcom.com/techsupport/papers/ethernet_switch_reliability.pdf</link>
      and <link
      xlink:href="http://www.n-tron.com/pdf/network_availability.pdf">http://www.n-tron.com/pdf/network_availability.pdf</link>.
    </para>
    <para>In most cases, it is much more economical to only use a
        single switch with a small pool of spare switches to replace
        failed units than it is to outfit an entire data center with
        redundant switches. Applications should also be able to
        tolerate rack level outages without affecting normal
        operations since network and compute resources are easily
        provisioned and plentiful.</para></section>
    <section xml:id="preparing-for-future-ipv6-support">
      <title>Preparing for the future: IPv6 support</title>
    <para>
      One of the most important networking topics today is the
      impending exhaustion of IPv4 addresses. In early 2014, ICANN
      announced that they started allocating the final IPv4 address
      blocks to the Regional Internet Registries (<link
      xlink:href="http://www.internetsociety.org/deploy360/blog/2014/05/goodbye-ipv4-iana-starts-allocating-final-address-blocks/">http://www.internetsociety.org/deploy360/blog/2014/05/goodbye-ipv4-iana-starts-allocating-final-address-blocks/</link>).
      This means the IPv4 address space is close to being fully
      allocated. As a result, it will soon become difficult to
      allocate more IPv4 addresses to an application that has
      experienced growth, or is expected to scale out, due to the lack
      of unallocated IPv4 address blocks.</para>
    <para>For network focused applications the future is the IPv6
        protocol. IPv6 increases the address space significantly,
        fixes long standing issues in the IPv4 protocol, and will
        become essential for network focused applications in the
        future.</para>
    <para>OpenStack Networking supports IPv6 when configured to take advantage of
        the feature. To enable it, simply create an IPv6 subnet in
        Networking and use IPv6 prefixes when creating security
        groups.</para></section>
    <section xml:id="asymmetric-links">
      <title>Asymmetric links</title>
    <para>When designing a network architecture, the traffic patterns
        of an application will heavily influence the allocation of
        total bandwidth and the number of links that are used to send
        and receive traffic. Applications that provide file storage
        for customers will allocate bandwidth and links to favor
        incoming traffic, whereas video streaming applications will
        allocate bandwidth and links to favor outgoing traffic.</para></section>
    <section xml:id="performance-network-focus">
      <title>Performance</title>
    <para>It is important to analyze the applications' tolerance for
        latency and jitter when designing an environment to support
        network focused applications. Certain applications, for
        example VoIP, are less tolerant of latency and jitter. Where
        latency and jitter are concerned, certain applications may
        require tuning of QoS parameters and network device queues to
        ensure that they are queued for transmit immediately or
        guaranteed minimum bandwidth. Since OpenStack currently does
        not support these functions, some considerations may need to
        be made for the network plug-in selected.</para>
    <para>The location of a service may also impact the application or
        consumer experience. If an application is designed to serve
        differing content to differing users it will need to be
        designed to properly direct connections to those specific
        locations. Use a multi-site installation for these situations,
        where appropriate.</para>
    <para>Networking can be implemented in two separate
        ways. The legacy networking (nova-network) provides a flat DHCP network
        with a single broadcast domain. This implementation does not
        support tenant isolation networks or advanced plug-ins, but it
        is currently the only way to implement a distributed layer-3
        agent using the multi_host configuration.
        OpenStack Networking (neutron) is the official networking implementation
        and provides a pluggable architecture that supports a large
        variety of network methods. Some of these include a layer-2
        only provider network model, external device plug-ins, or even
        OpenFlow controllers.</para>
    <para>Networking at large scales becomes a set of boundary
        questions. The determination of how large a layer-2 domain
        needs to be is based on the amount of nodes within the domain
        and the amount of broadcast traffic that passes between
        instances. Breaking layer-2 boundaries may require the
        implementation of overlay networks and tunnels. This decision
        is a balancing act between the need for a smaller overhead or
        a need for a smaller domain.</para>
    <para>When selecting network devices, be aware that making this
        decision based on the greatest port density often comes with a
        drawback. Aggregation switches and routers have not all kept
        pace with Top of Rack switches and may induce bottlenecks on
        north-south traffic. As a result, it may be possible for
        massive amounts of downstream network utilization to impact
        upstream network devices, impacting service to the cloud.
        Since OpenStack does not currently provide a mechanism for
        traffic shaping or rate limiting, it is necessary to implement
        these features at the network hardware level.</para>
      </section>
    </section>
</section>
